{"documents": [{"url": "https://en.wikipedia.org/wiki/Automated_machine_learning", "content": "Process of automating the application of machine learning\n\nPart of a series onMachine learningand data mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\n\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\n\nSupervised learning(classification\u00a0\u2022 regression) \nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\n\nClustering\nBIRCH\nCURE\nHierarchical\nk-means\nFuzzy\nExpectation\u2013maximization (EM)\nDBSCAN\nOPTICS\nMean shift\n\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\n\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\n\nAnomaly detection\nRANSAC\nk-NN\nLocal outlier factor\nIsolation forest\n\nArtificial neural network\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural radiance field\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM (ECRAM)\n\nReinforcement learning\nQ-learning\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\n\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nRLHF\n\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\n\nMathematical foundations\nKernel machines\nBias\u2013variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\n\nJournals and conferences\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\n\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nvte\nAutomated machine learning (AutoML) is the process of automating the tasks of applying machine learning to real-world problems. It is the combination of automation and ML.[1]\nAutoML potentially includes every stage from beginning with a raw dataset to building a machine learning model ready for deployment. AutoML was proposed as an artificial intelligence-based solution to the growing challenge of applying machine learning.[2][3] The high degree of automation in AutoML aims to allow non-experts to make use of machine learning models and techniques without requiring them to become experts in machine learning. Automating the process of applying machine learning end-to-end additionally offers the advantages of producing simpler solutions, faster creation of those solutions, and models that often outperform hand-designed models.[4]\nCommon techniques used in AutoML include hyperparameter optimization, meta-learning and neural architecture search.\n\n\nComparison to the standard approach[edit]\nIn a typical machine learning application, practitioners have a set of input data points to be used for training. The raw data may not be in a form that all algorithms can be applied to. To make the data amenable for machine learning, an expert may have to apply appropriate data pre-processing, feature engineering, feature extraction, and feature selection methods. After these steps, practitioners must then perform algorithm selection and hyperparameter optimization to maximize the predictive performance of their model. If deep learning is used, the architecture of the neural network must also be chosen manually by the machine learning expert. \nEach of these steps may be challenging, resulting in significant hurdles to using machine learning. AutoML aims to simplify these steps for non-experts, and to make it easier for them to use machine learning techniques correctly and effectively.\nAutoML plays an important role within the broader approach of automating data science, which also includes challenging tasks such as data engineering, data exploration and model interpretation and prediction.[5]\n\nTargets of automation[edit]\nAutomated machine learning can target various stages of the machine learning process.[3]  Steps to automate are:\n\nData preparation and ingestion (from raw data and miscellaneous formats)\nColumn type detection; e.g., Boolean, discrete numerical, continuous numerical, or text\nColumn intent detection; e.g., target/label, stratification field, numerical feature, categorical text feature, or free text feature\nTask detection; e.g., binary classification, regression, clustering, or ranking\nFeature engineering\nFeature selection\nFeature extraction\nMeta-learning and transfer learning\nDetection and handling of skewed data and/or missing values\nModel selection - choosing which machine learning algorithm to use, often including multiple competing software implementations\nEnsembling - a form of consensus where using multiple models often gives better results than any single model[6]\nHyperparameter optimization of the learning algorithm and featurization\nNeural architecture search\nPipeline selection under time, memory, and complexity constraints\nSelection of evaluation metrics and validation procedures\nProblem checking\nLeakage detection\nMisconfiguration detection\nAnalysis of obtained results\nCreating user interfaces and visualizations\nChallenges and Limitations[edit]\nThere are a number of key challenges being tackled around automated machine learning. A big issue surrounding the field is referred to as \"development as a cottage industry\".[7] This phrase refers to the issue in machine learning where development relies on manual decisions and biases of experts. This is contrasted to the goal of machine learning which is to create systems that can learn and improve from their own usage and analysis of the data. Basically, it's the struggle between how much experts should get involved in the learning of the systems versus how much freedom they should be giving the machines. However, experts and developers must help create and guide these machines to prepare them for their own learning. To create this system, it requires labor intensive work with knowledge of machine learning algorithms and system design.[8]\nAdditionally, some other challenges include meta-learning challenges[9] and computational resource allocation.\n\nSee also[edit]\nNeural architecture search\nNeuroevolution\nSelf-tuning\nNeural Network Intelligence\nAutoAI\nModelOps\nHyperparameter optimization\nReferences[edit]\n\n\n^ Spears, Taylor; Bondo Hansen, Kristian (2023-12-18), \"The Use and Promises of Machine Learning in Financial Markets\", The Oxford Handbook of the Sociology of Machine Learning, Oxford University Press, doi:10.1093/oxfordhb/9780197653609.013.6, ISBN\u00a0978-0-19-765360-9, retrieved 2024-06-10\n\n^ Thornton C, Hutter F, Hoos HH, Leyton-Brown K (2013). Auto-WEKA: Combined Selection and Hyperparameter Optimization of Classification Algorithms. KDD '13 Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining. pp.\u00a0847\u2013855.\n\n^ a b Hutter F, Caruana R, Bardenet R, Bilenko M, Guyon I, Kegl B, and Larochelle H. \"AutoML 2014 @ ICML\". AutoML 2014 Workshop @ ICML. Retrieved 2018-03-28.[permanent dead link\u200d]\n\n^ Olson, R.S., Urbanowicz, R.J., Andrews, P.C., Lavender, N.A., Kidd, L.C., Moore, J.H. (2016).  Automating Biomedical Data Science Through Tree-Based Pipeline Optimization.                     In: Squillero, G., Burelli, P. (eds) Applications of Evolutionary Computation. EvoApplications 2016. Lecture Notes in Computer Science(), vol 9597. Springer, Cham. doi:10.1007/978-3-319-31204-0_9\n\n^ De Bie, Tijl; De Raedt, Luc; Hern\u00e1ndez-Orallo, Jos\u00e9; Hoos, Holger H.; Smyth, Padhraic; Williams, Christopher K. I. (March 2022). \"Automating Data Science\". Communications of the ACM. 65 (3): 76\u201387. doi:10.1145/3495256. hdl:10251/199907.\n\n^ Erickson, Nick; Mueller, Jonas; Shirkov, Alexander; Zhang, Hang; Larroy, Pedro; Li, Mu; Smola, Alexander (2020-03-13). \"AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data\". arXiv:2003.06505 [stat.ML].\n\n^ Hutter, Frank; Kotthoff, Lars; Vanschoren, Joaquin, eds. (2019). Automated Machine Learning: Methods, Systems, Challenges. The Springer Series on Challenges in Machine Learning. Springer Nature. doi:10.1007/978-3-030-05318-5. hdl:20.500.12657/23012. ISBN\u00a0978-3-030-05317-8.\n\n^ Glover, Ellen (2018). \"Machine Learning with Python: Clustering\". Built in. doi:10.4135/9781526466426.\n\n^ \"Meta Learning Challenges\". metalearning.chalearn.org. Retrieved 2023-12-03.\n\n\nFurther reading[edit]\n\"Open Source AutoML Tools: AutoGluon, TransmogrifAI, Auto-sklearn, and NNI\". Bizety. 2020-06-16.\nFerreira, Lu\u00eds, et al. \"A comparison of AutoML tools for machine learning, deep learning and XGBoost.\" 2021 International Joint Conference on Neural Networks (IJCNN). IEEE, 2021. https://repositorium.sdum.uminho.pt/bitstream/1822/74125/1/automl_ijcnn.pdf\nFeurer, M., Klein, A., Eggensperger, K., Springenberg, J., Blum, M., & Hutter, F. (2015). Efficient and robust automated machine learning. Advances in neural information processing systems, 28. https://proceedings.neurips.cc/paper_files/paper/2015/file/11d0e6287202fced83f79975ec59a3a6-Paper.pdf\nvteDifferentiable computingGeneral\nDifferentiable programming\nInformation geometry\nStatistical manifold\nAutomatic differentiation\nNeuromorphic engineering\nPattern recognition\nTensor calculus\nComputational learning theory\nInductive bias\nHardware\nIPU\nTPU\nVPU\nMemristor\nSpiNNaker\nSoftware libraries\nTensorFlow\nPyTorch\nKeras\nscikit-learn\nTheano\nJAX\nFlux.jl\nMindSpore\n\n Portals\nComputer programming\nTechnology\n\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Automated_machine_learning&oldid=1250233929\""}, {"url": "https://en.wikipedia.org/wiki/Machine_learning", "content": "Study of algorithms that improve automatically through experience\nFor the journal, see Machine Learning (journal).\n\"Statistical learning\" redirects here. For statistical learning in linguistics, see statistical learning in language acquisition.\n\nPart of a series onMachine learningand data mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\n\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\n\nSupervised learning(classification\u00a0\u2022 regression) \nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\n\nClustering\nBIRCH\nCURE\nHierarchical\nk-means\nFuzzy\nExpectation\u2013maximization (EM)\nDBSCAN\nOPTICS\nMean shift\n\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\n\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\n\nAnomaly detection\nRANSAC\nk-NN\nLocal outlier factor\nIsolation forest\n\nArtificial neural network\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural radiance field\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM (ECRAM)\n\nReinforcement learning\nQ-learning\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\n\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nRLHF\n\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\n\nMathematical foundations\nKernel machines\nBias\u2013variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\n\nJournals and conferences\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\n\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nvte\nPart of a series onArtificial intelligence\nMajor goals\nArtificial general intelligence\nIntelligent agent\nRecursive self-improvement\nPlanning\nComputer vision\nGeneral game playing\nKnowledge reasoning\nNatural language processing\nRobotics\nAI safety\n\nApproaches\nMachine learning\nSymbolic\nDeep learning\nBayesian networks\nEvolutionary algorithms\nHybrid intelligent systems\nSystems integration\n\nApplications\nBioinformatics\nDeepfake\nEarth sciences\n Finance \nGenerative AI\nArt\nAudio\nMusic\nGovernment\nHealthcare\nMental health\nIndustry\nTranslation\n Military \nPhysics\nProjects\n\nPhilosophy\nArtificial consciousness\nChinese room\nFriendly AI\nControl problem/Takeover\nEthics\nExistential risk\nRegulation\nTuring test\n\nHistory\nTimeline\nProgress\nAI winter\nAI boom\n\nGlossary\nGlossary\nvte\nMachine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions.[1] Advances in the field of deep learning have allowed neural networks to surpass many previous approaches in performance.[2]\nML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine.[3][4] The application of ML to business problems is known as predictive analytics.\nStatistics and mathematical optimization (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) via unsupervised learning.[6][7]\nFrom a theoretical viewpoint, probably approximately correct (PAC) learning provides a framework for describing machine learning.\n\n\nHistory[edit]\nSee also: Timeline of machine learning\nThe term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and pioneer in the field of computer gaming and artificial intelligence.[8][9] The synonym self-teaching computers was also used in this time period.[10][11]\nAlthough the earliest machine learning model was introduced in the 1950s when Arthur Samuel invented a program that calculated the winning chance in checkers for each side, the history of machine learning roots back to decades of human desire and effort to study human cognitive processes.[12] In 1949, Canadian psychologist Donald Hebb published the book The Organization of Behavior, in which he introduced a theoretical neural structure formed by certain interactions among nerve cells.[13] Hebb's model of neurons interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes, or artificial neurons used by computers to communicate data.[12] Other researchers who have studied human cognitive systems contributed to the modern machine learning technologies as well, including logician Walter Pitts and Warren McCulloch, who proposed the early mathematical models of neural networks to come up with algorithms that mirror human thought processes.[12]\nBy the early 1960s, an experimental \"learning machine\" with punched tape memory, called Cybertron, had been developed by Raytheon Company to analyze sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning. It was repetitively \"trained\" by a human operator/teacher to recognize patterns and equipped with a \"goof\" button to cause it to reevaluate incorrect decisions.[14] A representative book on research into machine learning during the 1960s was Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification.[15] Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973.[16] In 1981 a report was given on using teaching strategies so that an artificial neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.[17]\nTom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P,  improves with experience E.\"[18] This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper \"Computing Machinery and Intelligence\", in which the question \"Can machines think?\" is replaced with the question \"Can machines do what we (as thinking entities) can do?\".[19]\nModern-day machine learning has two objectives.  One is to classify data based on models which have been developed; the other purpose is to make predictions for future outcomes based on these models. A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles. A machine learning algorithm for stock trading may inform the trader of future potential predictions.[20]\n\nRelationships to other fields[edit]\nArtificial intelligence[edit]\nMachine learning as subfield of AI[21]\nAs a scientific endeavor, machine learning grew out of the quest for artificial intelligence (AI). In the early days of AI as an academic discipline, some researchers were interested in having machines learn from data. They attempted to approach the problem with various symbolic methods, as well as what were then termed \"neural networks\"; these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics.[22] Probabilistic reasoning was also employed, especially in automated medical diagnosis.[23]:\u200a488\u200a\nHowever, an increasing emphasis on the logical, knowledge-based approach caused a rift between AI and machine learning. Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation.[23]:\u200a488\u200a By 1980, expert systems had come to dominate AI, and statistics was out of favor.[24] Work on symbolic/knowledge-based learning did continue within AI, leading to inductive logic programming(ILP), but the more statistical line of research was now outside the field of AI proper, in pattern recognition and information retrieval.[23]:\u200a708\u2013710,\u200a755\u200a Neural networks research had been abandoned by AI and computer science around the same time. This line, too, was continued outside the AI/CS field, as \"connectionism\", by researchers from other disciplines including John Hopfield, David Rumelhart, and Geoffrey Hinton. Their main success came in the mid-1980s with the reinvention of backpropagation.[23]:\u200a25\u200a\nMachine learning (ML), reorganized and recognized as its own field, started to flourish in the 1990s. The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature. It shifted focus away from the symbolic approaches it had inherited from AI, and toward methods and models borrowed from statistics, fuzzy logic, and probability theory.[24]\n\nData compression[edit]\nThis section is an excerpt from Data compression \u00a7 Machine learning.[edit]\nThere is a close connection between machine learning and compression. A system that predicts the posterior probabilities of a sequence given its entire history can be used for optimal data compression (by using arithmetic coding on the output distribution). Conversely, an optimal compressor can be used for prediction (by finding the symbol that compresses best, given the previous history). This equivalence has been used as a justification for using data compression as a benchmark for \"general intelligence\".[25][26][27]\nAn alternative view can show compression algorithms implicitly map strings into implicit feature space vectors, and compression-based similarity measures compute similarity within these feature spaces. For each compressor C(.) we define an associated vector space \u2135, such that C(.) maps an input string x, corresponding to the vector norm ||~x||. An exhaustive examination of the feature spaces underlying all compression algorithms is precluded by space; instead, feature vectors chooses to examine three representative lossless compression methods, LZW, LZ77, and PPM.[28]\nAccording to AIXI theory, a connection more directly explained in Hutter Prize, the best possible compression of x is the smallest possible software that generates x. For example, in that model, a zip file's compressed size includes both the zip file and the unzipping software, since you can not unzip it without both, but there may be an even smaller combined form.\nExamples of AI-powered audio/video compression software include NVIDIA Maxine, AIVC.[29] Examples of software that can perform AI-powered image compression include OpenCV, TensorFlow, MATLAB's Image Processing Toolbox (IPT) and High-Fidelity Generative Image Compression.[30]\nIn unsupervised machine learning, k-means clustering can be utilized to compress data by grouping similar data points into clusters. This technique simplifies handling extensive datasets that lack predefined labels and finds widespread use in fields such as image compression.[31]\nData compression aims to reduce the size of data files, enhancing storage efficiency and speeding up data transmission. K-means clustering, an unsupervised machine learning algorithm, is employed to partition a dataset into a specified number of clusters, k, each represented by the centroid of its points. This process condenses extensive datasets into a more compact set of representative points. Particularly beneficial in image and signal processing, k-means clustering aids in data reduction by replacing groups of data points with their centroids, thereby preserving the core information of the original data while significantly decreasing the required storage space.[32]\n\nLarge language models (LLMs) are also capable of lossless data compression, as demonstrated by DeepMind's research with the Chinchilla 70B model. Developed by DeepMind, Chinchilla 70B effectively compressed data, outperforming conventional methods such as Portable Network Graphics (PNG) for images and Free Lossless Audio Codec (FLAC) for audio. It achieved compression of image and audio data to 43.4% and 16.4% of their original sizes, respectively.[33]\nData mining[edit]\nMachine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of (previously) unknown properties in the data (this is the analysis step of knowledge discovery in databases). Data mining uses many machine learning methods, but with different goals; on the other hand, machine learning also employs data mining methods as \"unsupervised learning\" or as a preprocessing step to improve learner accuracy. Much of the confusion between these two research communities (which do often have separate conferences and separate journals, ECML PKDD being a major exception) comes from the basic assumptions they work with: in machine learning, performance is usually evaluated with respect to the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD) the key task is the discovery of previously unknown knowledge. Evaluated with respect to known knowledge, an uninformed (unsupervised) method will easily be outperformed by other supervised methods, while in a typical KDD task, supervised methods cannot be used due to the unavailability of training data.\nMachine learning also has intimate ties to optimization: Many learning problems are formulated as minimization of some loss function on a training set of examples. Loss functions express the discrepancy between the predictions of the model being trained and the actual problem instances (for example, in classification, one wants to assign a label to instances, and models are trained to correctly predict the preassigned labels of a set of examples).[34]\n\nGeneralization[edit]\nCharacterizing the generalization of various learning algorithms is an active topic of current research, especially for deep learning algorithms.\n\nStatistics[edit]\nMachine learning and statistics are closely related fields in terms of methods, but distinct in their principal goal: statistics draws population inferences from a sample, while machine learning finds generalizable predictive patterns.[35] According to Michael I. Jordan, the ideas of machine learning, from methodological principles to theoretical tools, have had a long pre-history in statistics.[36] He also suggested the term data science as a placeholder to call the overall field.[36]\nConventional statistical analyses require the a priori selection of a model most suitable for the study data set. In addition, only significant or theoretically relevant variables based on previous experience are included for analysis. In contrast, machine learning is not built on a pre-structured model; rather, the data shape the model by detecting underlying patterns. The more variables (input) used to train the model, the more accurate the ultimate model will be.[37]\nLeo Breiman distinguished two statistical modeling paradigms: data model and algorithmic model,[38] wherein \"algorithmic model\" means more or less the machine learning algorithms like Random Forest.\nSome statisticians have adopted methods from machine learning, leading to a combined field that they call statistical learning.[39]\n\nStatistical physics[edit]\nAnalytical and computational techniques derived from deep-rooted physics of disordered systems can be extended to large-scale problems, including machine learning, e.g., to analyze the weight space of deep neural networks.[40] Statistical physics is thus finding applications in the area of medical diagnostics.[41]\n\n Theory[edit]\nMain articles: Computational learning theory and Statistical learning theory\nA core objective of a learner is to generalize from its experience.[5][42] Generalization in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set. The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases.\nThe computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory via the Probably Approximately Correct Learning (PAC) model. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic bounds on the performance are quite common. The bias\u2013variance decomposition is one way to quantify generalization error.\nFor the best performance in the context of generalization, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has under fitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting and generalization will be poorer.[43]\nIn addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in polynomial time. There are two kinds of time complexity results: Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time.\n\nApproaches[edit]\n\nMachine learning approaches are traditionally divided into three broad categories, which correspond to learning paradigms, depending on the nature of the \"signal\" or \"feedback\" available to the learning system:\n\nSupervised learning: The computer is presented with example inputs and their desired outputs, given by a \"teacher\", and the goal is to learn a general rule that maps inputs to outputs.\nUnsupervised learning: No labels are given to the learning algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (feature learning).\nReinforcement learning: A computer program interacts with a dynamic environment in which it must perform a certain goal (such as driving a vehicle or playing a game against an opponent). As it navigates its problem space, the program is provided feedback that's analogous to rewards, which it tries to maximize.[5]\nAlthough each algorithm has advantages and limitations, no single algorithm works for all problems.[44][45][46]\n\nSupervised learning[edit]\nMain article: Supervised learning\nA support-vector machine is a supervised learning model that divides the data into regions separated by a linear boundary. Here, the linear boundary divides the black circles from the white.\nSupervised learning algorithms build a mathematical model of a set of data that contains both the inputs and the desired outputs.[47] The data, known as training data, consists of a set of training examples. Each training example has one or more inputs and the desired output, also known as a supervisory signal. In the mathematical model, each training example is represented by an array or vector, sometimes called a feature vector, and the training data is represented by a matrix. Through iterative optimization of an objective function, supervised learning algorithms learn a function that can be used to predict the output associated with new inputs.[48] An optimal function allows the algorithm to correctly determine the output for inputs that were not a part of the training data. An algorithm that improves the accuracy of its outputs or predictions over time is said to have learned to perform that task.[18]\nTypes of supervised-learning algorithms include active learning, classification and regression.[49] Classification algorithms are used when the outputs are restricted to a limited set of values, and regression algorithms are used when the outputs may have any numerical value within a range. As an example, for a classification algorithm that filters emails, the input would be an incoming email, and the output would be the name of the folder in which to file the email. Examples of regression would be predicting the height of a person, or the future temperature. [50]\nSimilarity learning is an area of supervised machine learning closely related to regression and classification, but the goal is to learn from examples using a similarity function that measures how similar or related two objects are. It has applications in ranking, recommendation systems, visual identity tracking, face verification, and speaker verification.\n\nUnsupervised learning[edit]\nMain article: Unsupervised learningSee also: Cluster analysis\nUnsupervised learning algorithms find structures in data that has not been labeled, classified or categorized. Instead of responding to feedback, unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data. Central applications of unsupervised machine learning include clustering, dimensionality reduction,[7] and density estimation.[51] Unsupervised learning algorithms also streamlined the process of identifying large indel based haplotypes of a gene of interest from pan-genome.[52]\n\nClustering via Large Indel Permuted Slopes, CLIPS,[53] turns the alignment image into a learning regression problem. The varied slope (b) estimates between each pair of DNA segments enables to identify segments sharing the same set of indels.\nCluster analysis is the assignment of a set of observations into subsets (called clusters) so that observations within the same cluster are similar according to one or more predesignated criteria, while observations drawn from different clusters are dissimilar. Different clustering techniques make different assumptions on the structure of the data, often defined by some similarity metric and evaluated, for example, by internal compactness, or the similarity between members of the same cluster, and separation, the difference between clusters. Other methods are based on estimated density and graph connectivity.\nA special type of unsupervised learning called, self-supervised learning involves training a model by generating the supervisory signal from the data itself.[54][55]\n\nSemi-supervised learning[edit]\nMain article: Semi-supervised learning\nSemi-supervised learning falls between unsupervised learning (without any labeled training data) and supervised learning (with completely labeled training data). Some of the training examples are missing training labels, yet many machine-learning researchers have found that unlabeled data, when used in conjunction with a small amount of labeled data, can produce a considerable improvement in learning accuracy.\nIn weakly supervised learning, the training labels are noisy, limited, or imprecise; however, these labels are often cheaper to obtain, resulting in larger effective training sets.[56]\n\nReinforcement learning[edit]\nMain article: Reinforcement learning\nReinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward. Due to its generality, the field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics and genetic algorithms. In reinforcement learning, the environment is typically represented as a Markov decision process (MDP). Many reinforcements learning algorithms use dynamic programming techniques.[57] Reinforcement learning algorithms do not assume knowledge of an exact mathematical model of the MDP and are used when exact models are infeasible. Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent.\n\nDimensionality reduction[edit]\nDimensionality reduction is a process of reducing the number of random variables under consideration by obtaining a set of principal variables.[58] In other words, it is a process of reducing the dimension of the feature set, also called the \"number of features\". Most of the dimensionality reduction techniques can be considered as either feature elimination or extraction. One of the popular methods of dimensionality reduction is principal component analysis (PCA). PCA involves changing higher-dimensional data (e.g., 3D) to a smaller space (e.g., 2D).\nThe manifold hypothesis proposes that high-dimensional data sets lie along low-dimensional manifolds, and many dimensionality reduction techniques make this assumption, leading to the area of manifold learning and manifold regularization.\n\nOther types[edit]\nOther approaches have been developed which do not fit neatly into this three-fold categorization, and sometimes more than one is used by the same machine learning system. For example, topic modeling, meta-learning.[59]\n\nSelf-learning[edit]\nSelf-learning, as a machine learning paradigm was introduced in 1982 along with a neural network capable of self-learning, named crossbar adaptive array (CAA).[60] It is learning with no external rewards and no external teacher advice. The CAA self-learning algorithm computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about consequence situations. The system is driven by the interaction between cognition and emotion.[61]\nThe self-learning algorithm updates a memory matrix W =||w(a,s)|| such that in each iteration executes the following machine learning routine: \n\nin situation s perform action a\nreceive a consequence situation s'\ncompute emotion of being in the consequence situation v(s')\nupdate crossbar memory  w'(a,s) = w(a,s) + v(s')\nIt is a system with only one input, situation, and only one output, action (or behavior) a. There is neither a separate reinforcement input nor an advice input from the environment. The backpropagated value (secondary reinforcement) is the emotion toward the consequence situation. The CAA exists in two environments, one is the behavioral environment where it behaves, and the other is the genetic environment, wherefrom it initially and only once receives initial emotions about situations to be encountered in the behavioral environment. After receiving the genome (species) vector from the genetic environment, the CAA learns a goal-seeking behavior, in an environment that contains both desirable and undesirable situations.[62]\n\nFeature learning[edit]\nMain article: Feature learning\nSeveral learning algorithms aim at discovering better representations of the inputs provided during training.[63] Classic examples include principal component analysis and cluster analysis. Feature learning algorithms, also called representation learning algorithms, often attempt to preserve the information in their input but also transform it in a way that makes it useful, often as a pre-processing step before performing classification or predictions. This technique allows reconstruction of the inputs coming from the unknown data-generating distribution, while not being necessarily faithful to configurations that are implausible under that distribution. This replaces manual feature engineering, and allows a machine to both learn the features and use them to perform a specific task.\nFeature learning can be either supervised or unsupervised. In supervised feature learning, features are learned using labeled input data. Examples include artificial neural networks, multilayer perceptrons, and supervised dictionary learning. In unsupervised feature learning, features are learned with unlabeled input data.  Examples include dictionary learning, independent component analysis, autoencoders, matrix factorization[64] and various forms of clustering.[65][66][67]\nManifold learning algorithms attempt to do so under the constraint that the learned representation is low-dimensional. Sparse coding algorithms attempt to do so under the constraint that the learned representation is sparse, meaning that the mathematical model has many zeros. Multilinear subspace learning algorithms aim to learn low-dimensional representations directly from tensor representations for multidimensional data, without reshaping them into higher-dimensional vectors.[68] Deep learning algorithms discover multiple levels of representation, or a hierarchy of features, with higher-level, more abstract features defined in terms of (or generating) lower-level features. It has been argued that an intelligent machine is one that learns a representation that disentangles the underlying factors of variation that explain the observed data.[69]\nFeature learning is motivated by the fact that machine learning tasks such as classification often require input that is mathematically and computationally convenient to process. However, real-world data such as images, video, and sensory data has not yielded attempts to algorithmically define specific features. An alternative is to discover such features or representations through examination, without relying on explicit algorithms.\n\nSparse dictionary learning[edit]\nMain article: Sparse dictionary learning\nSparse dictionary learning is a feature learning method where a training example is represented as a linear combination of basis functions and assumed to be a sparse matrix. The method is strongly NP-hard and difficult to solve approximately.[70] A popular heuristic method for sparse dictionary learning is the k-SVD algorithm. Sparse dictionary learning has been applied in several contexts. In classification, the problem is to determine the class to which a previously unseen training example belongs. For a dictionary where each class has already been built, a new training example is associated with the class that is best sparsely represented by the corresponding dictionary. Sparse dictionary learning has also been applied in image de-noising. The key idea is that a clean image patch can be sparsely represented by an image dictionary, but the noise cannot.[71]\n\nAnomaly detection[edit]\nMain article: Anomaly detection\nIn data mining, anomaly detection, also known as outlier detection, is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data.[72] Typically, the anomalous items represent an issue such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies are referred to as outliers, novelties, noise, deviations and exceptions.[73]\nIn particular, in the context of abuse and network intrusion detection, the interesting objects are often not rare objects, but unexpected bursts of inactivity. This pattern does not adhere to the common statistical definition of an outlier as a rare object. Many outlier detection methods (in particular, unsupervised algorithms) will fail on such data unless aggregated appropriately. Instead, a cluster analysis algorithm may be able to detect the micro-clusters formed by these patterns.[74]\nThree broad categories of anomaly detection techniques exist.[75] Unsupervised anomaly detection techniques detect anomalies in an unlabeled test data set under the assumption that the majority of the instances in the data set are normal, by looking for instances that seem to fit the least to the remainder of the data set. Supervised anomaly detection techniques require a data set that has been labeled as \"normal\" and \"abnormal\" and involves training a classifier (the key difference from many other statistical classification problems is the inherently unbalanced nature of outlier detection). Semi-supervised anomaly detection techniques construct a model representing normal behavior from a given normal training data set and then test the likelihood of a test instance to be generated by the model.\n\nRobot learning[edit]\nRobot learning is inspired by a multitude of machine learning methods, starting from supervised learning, reinforcement learning,[76][77] and finally meta-learning (e.g. MAML).\n\nAssociation rules[edit]\nMain article: Association rule learningSee also: Inductive logic programming\nAssociation rule learning is a rule-based machine learning method for discovering relationships between variables in large databases. It is intended to identify strong rules discovered in databases using some measure of \"interestingness\".[78]\nRule-based machine learning is a general term for any machine learning method that identifies, learns, or evolves \"rules\" to store, manipulate or apply knowledge. The defining characteristic of a rule-based machine learning algorithm is the identification and utilization of a set of relational rules that collectively represent the knowledge captured by the system. This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction.[79] Rule-based machine learning approaches include learning classifier systems, association rule learning, and artificial immune systems.\nBased on the concept of strong rules, Rakesh Agrawal, Tomasz Imieli\u0144ski and Arun Swami introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (POS) systems in supermarkets.[80] For example, the rule \n\n\n\n{\n\no\nn\ni\no\nn\ns\n,\np\no\nt\na\nt\no\ne\ns\n\n}\n\u21d2\n{\n\nb\nu\nr\ng\ne\nr\n\n}\n\n\n{\\displaystyle \\{\\mathrm {onions,potatoes} \\}\\Rightarrow \\{\\mathrm {burger} \\}}\n\n found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat. Such information can be used as the basis for decisions about marketing activities such as promotional pricing or product placements. In addition to market basket analysis, association rules are employed today in application areas including Web usage mining, intrusion detection, continuous production, and bioinformatics. In contrast with sequence mining, association rule learning typically does not consider the order of items either within a transaction or across transactions.\nLearning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm, with a learning component, performing either supervised learning, reinforcement learning, or unsupervised learning. They seek to identify a set of context-dependent rules that collectively store and apply knowledge in a piecewise manner in order to make predictions.[81]\nInductive logic programming (ILP) is an approach to rule learning using logic programming as a uniform representation for input examples, background knowledge, and hypotheses. Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts, an ILP system will derive a hypothesized logic program that entails all positive and no negative examples. Inductive programming is a related field that considers any kind of programming language for representing hypotheses (and not only logic programming), such as functional programs.\nInductive logic programming is particularly useful in bioinformatics and natural language processing. Gordon Plotkin and Ehud Shapiro laid the initial theoretical foundation for inductive machine learning in a logical setting.[82][83][84] Shapiro built their first implementation (Model Inference System) in 1981: a Prolog program that inductively inferred logic programs from positive and negative examples.[85] The term inductive here refers to philosophical induction, suggesting a theory to explain observed facts, rather than mathematical induction, proving a property for all members of a well-ordered set.\n\nModels[edit]\nA machine learning model is a type of mathematical model that, after being \"trained\" on a given dataset, can be used to make predictions or classifications on new data. During training, a learning algorithm iteratively adjusts the model's internal parameters to minimize errors in its predictions.[86] By extension, the term \"model\" can refer to several levels of specificity, from a general class of models and their associated learning algorithms to a fully trained model with all its internal parameters tuned.[87]\nVarious types of models have been used and researched for machine learning systems, picking the best model for a task is called model selection.\n\nArtificial neural networks[edit]\nMain article: Artificial neural networkSee also: Deep learning\nAn artificial neural network is an interconnected group of nodes, akin to the vast network of neurons in a brain. Here, each circular node represents an artificial neuron and an arrow represents a connection from the output of one artificial neuron to the input of another.\nArtificial neural networks (ANNs), or connectionist systems, are computing systems vaguely inspired by the biological neural networks that constitute animal brains. Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with any task-specific rules.\nAn ANN is a model based on a collection of connected units or nodes called \"artificial neurons\", which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit information, a \"signal\", from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. In common ANN implementations, the signal at a connection between artificial neurons is a real number, and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called \"edges\". Artificial neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly after traversing the layers multiple times.\nThe original goal of the ANN approach was to solve problems in the same way that a human brain would. However, over time, attention moved to performing specific tasks, leading to deviations from biology. Artificial neural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.\nDeep learning consists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.[88]\n\nDecision trees[edit]\nMain article: Decision tree learning\nA decision tree showing survival probability of passengers on the Titanic\nDecision tree learning uses a decision tree as a predictive model to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modeling approaches used in statistics, data mining, and machine learning. Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures, leaves represent class labels, and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. In decision analysis, a decision tree can be used to visually and explicitly represent decisions and decision making. In data mining, a decision tree describes data, but the resulting classification tree can be an input for decision-making.\n\nSupport-vector machines[edit]\nMain article: Support-vector machine\nSupport-vector machines (SVMs), also known as support-vector networks, are a set of related supervised learning methods used for classification and regression. Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that predicts whether a new example falls into one category.[89] An SVM training algorithm is a non-probabilistic, binary, linear classifier, although methods such as Platt scaling exist to use SVM in a probabilistic classification setting. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.\n\nRegression analysis[edit]\nMain article: Regression analysis\nIllustration of linear regression on a data set\nRegression analysis encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features. Its most common form is linear regression, where a single line is drawn to best fit the given data according to a mathematical criterion such as ordinary least squares. The latter is often extended by regularization methods to mitigate overfitting and bias, as in ridge regression. When dealing with non-linear problems, go-to models include polynomial regression (for example, used for trendline fitting in Microsoft Excel[90]), logistic regression (often used in statistical classification) or even kernel regression, which introduces non-linearity by taking advantage of the kernel trick to implicitly map input variables to higher-dimensional space.\n\nBayesian networks[edit]\nMain article: Bayesian network\nA simple Bayesian network. Rain influences whether the sprinkler is activated, and both rain and the sprinkler influence whether the grass is wet.\nA Bayesian network, belief network, or directed acyclic graphical model is a probabilistic graphical model that represents a set of random variables and their conditional independence with a directed acyclic graph (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases. Efficient algorithms exist that perform inference and learning. Bayesian networks that model sequences of variables, like speech signals or protein sequences, are called dynamic Bayesian networks. Generalizations of Bayesian networks that can represent and solve decision problems under uncertainty are called influence diagrams.\n\nGaussian processes[edit]\nMain article: Gaussian processes\nAn example of Gaussian Process Regression (prediction) compared with other regression models[91]\nA Gaussian process is a stochastic process in which every finite collection of the random variables in the process has a multivariate normal distribution, and it relies on a pre-defined covariance function, or kernel, that models how pairs of points relate to each other depending on their locations.\nGiven a set of observed points, or input\u2013output examples, the distribution of the (unobserved) output of a new point as function of its input data can be directly computed by looking like the observed points and the covariances between those points and the new, unobserved point.\nGaussian processes are popular surrogate models in Bayesian optimization used to do hyperparameter optimization.\n\nGenetic algorithms[edit]\nMain article: Genetic algorithm\nA genetic algorithm (GA) is a search algorithm and heuristic technique that mimics the process of natural selection, using methods such as mutation and crossover to generate new genotypes in the hope of finding good solutions to a given problem. In machine learning, genetic algorithms were used in the 1980s and 1990s.[92][93] Conversely, machine learning techniques have been used to improve the performance of genetic and evolutionary algorithms.[94]\n\nBelief functions[edit]\nMain article: Dempster\u2013Shafer theory\nThe theory of belief functions, also referred to as evidence theory or Dempster\u2013Shafer theory, is a general framework for reasoning with uncertainty, with understood connections to other frameworks such as probability, possibility and  imprecise probability theories. These theoretical frameworks can be thought of as a kind of learner and have some analogous properties of how evidence is combined (e.g.,  Dempster's rule of combination), just like how in a pmf-based Bayesian approach[clarification needed] would combine probabilities. However, there are many caveats to these beliefs functions when compared to Bayesian approaches in order to incorporate ignorance and uncertainty quantification. These belief function approaches that are implemented within the machine learning domain typically leverage a fusion approach of various ensemble methods to better handle the learner's decision boundary, low samples, and ambiguous class issues that standard machine learning approach tend to have difficulty resolving.[4][9] However, the computational complexity of these algorithms are dependent on the number of propositions (classes), and can lead to a much higher computation time when compared to other machine learning approaches.\n\nTraining models[edit]\nTypically, machine learning models require a high quantity of reliable data to perform accurate predictions. When training a machine learning model, machine learning engineers need to target and collect a large and representative sample of data. Data from the training set can be as varied as a corpus of text, a collection of images, sensor data, and data collected from individual users of a service. Overfitting is something to watch out for when training a machine learning model. Trained models derived from biased or non-evaluated data can result in skewed or undesired predictions. Biased models may result in detrimental outcomes, thereby furthering the negative impacts on society or objectives. Algorithmic bias is a potential result of data not being fully prepared for training. Machine learning ethics is becoming a field of study and notably, becoming integrated within machine learning engineering teams.\n\nFederated learning[edit]\nMain article: Federated learning\nFederated learning is an adapted form of distributed artificial intelligence to training machine learning models that decentralizes the training process, allowing for users' privacy to be maintained by not needing to send their data to a centralized server. This also increases efficiency by decentralizing the training process to many devices. For example, Gboard uses federated machine learning to train search query prediction models on users' mobile phones without having to send individual searches back to Google.[95]\n\nApplications[edit]\nThere are many applications for machine learning, including:\n\n\nAgriculture\nAnatomy\nAdaptive website\nAffective computing\nAstronomy\nAutomated decision-making\nBanking\nBehaviorism\nBioinformatics\nBrain\u2013machine interfaces\nCheminformatics\nCitizen Science\nClimate Science\nComputer networks\nComputer vision\nCredit-card fraud detection\nData quality\nDNA sequence classification\nEconomics\nFinancial market analysis[96]\nGeneral game playing\nHandwriting recognition\nHealthcare\nInformation retrieval\nInsurance\nInternet fraud detection\nKnowledge graph embedding\nLinguistics\nMachine learning control\nMachine perception\nMachine translation\nMarketing\nMedical diagnosis\nNatural language processing\nNatural language understanding\nOnline advertising\nOptimization\nRecommender systems\nRobot locomotion\nSearch engines\nSentiment analysis\nSequence mining\nSoftware engineering\nSpeech recognition\nStructural health monitoring\nSyntactic pattern recognition\nTelecommunications\nTheorem proving\nTime-series forecasting\nTomographic reconstruction[97]\nUser behavior analytics\n\nIn 2006, the media-services provider Netflix held the first \"Netflix Prize\" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10%. A joint team made up of researchers from AT&T Labs-Research in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to win the Grand Prize in 2009 for $1 million.[98] Shortly after the prize was awarded, Netflix realized that viewers' ratings were not the best indicators of their viewing patterns (\"everything is a recommendation\") and they changed their recommendation engine accordingly.[99] In 2010 The Wall Street Journal wrote about the firm Rebellion Research and their use of machine learning to predict the financial crisis.[100] In 2012, co-founder of Sun Microsystems, Vinod Khosla, predicted that 80% of medical doctors jobs would be lost in the next two decades to automated machine learning medical diagnostic software.[101] In 2014, it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognized influences among artists.[102] In 2019 Springer Nature published the first research book created using machine learning.[103] In 2020, machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID-19.[104] Machine learning was recently applied to predict the pro-environmental behavior of travelers.[105] Recently, machine learning technology was also applied to optimize smartphone's performance and thermal behavior based on the user's interaction with the phone.[106][107][108] When applied correctly, machine learning algorithms (MLAs) can utilize a wide range of company characteristics to predict stock returns without overfitting. By employing effective feature engineering and combining forecasts, MLAs can generate results that far surpass those obtained from basic linear techniques like OLS.[109]\nRecent advancements in machine learning have extended into the field of quantum chemistry, where novel algorithms now enable the prediction of solvent effects on chemical reactions, thereby offering new tools for chemists to tailor experimental conditions for optimal outcomes.[110]\nMachine Learning is becoming a useful tool to investigate and predict evacuation decision making in large scale and small scale disasters. Different solutions have been tested to predict if and when householders decide to evacuate during wildfires and hurricanes.[111][112][113] Other applications have been focusing on pre evacuation decisions in building fires.[114][115]\n\nLimitations[edit]\nAlthough machine learning has been transformative in some fields, machine-learning programs often fail to deliver expected results.[116][117][118] Reasons for this are numerous: lack of (suitable) data, lack of access to the data, data bias, privacy problems, badly chosen tasks and algorithms, wrong tools and people, lack of resources, and evaluation problems.[119]\nThe \"black box theory\" poses another yet significant challenge. Black box refers to a situation where the algorithm or the process of producing an output is entirely opaque, meaning that even the coders of the algorithm cannot audit the pattern that the machine extracted out of the data.[120] The House of Lords Select Committee, which claimed that such an \"intelligence system\" that could have a \"substantial impact on an individual's life\" would not be considered acceptable unless it provided \"a full and satisfactory explanation for the decisions\" it makes.[120]\nIn 2018, a self-driving car from Uber failed to detect a pedestrian, who was killed after a collision.[121] Attempts to use machine learning in healthcare with the IBM Watson system failed to deliver even after years of time and billions of dollars invested.[122][123] Microsoft's Bing Chat chatbot has been reported to produce hostile and offensive response against its users.[124]\nMachine learning has been used as a strategy to update the evidence related to a systematic review and increased reviewer burden related to the growth of biomedical literature. While it has improved with training sets, it has not yet developed sufficiently to reduce the workload burden without limiting the necessary sensitivity for the findings research themselves.[125]\n\nBias[edit]\nMain article: Algorithmic bias\nDifferent machine learning approaches can suffer from different data biases. A machine learning system trained specifically on current customers may not be able to predict the needs of new customer groups that are not represented in the training data. When trained on human-made data, machine learning is likely to pick up the constitutional and unconscious biases already present in society.[126]\nLanguage models learned from data have been shown to contain human-like biases.[127][128] In an experiment carried out by ProPublica, an investigative journalism organization, a machine learning algorithm's insight into the recidivism rates among prisoners falsely flagged \"black defendants high risk twice as often as white defendants.\"[129] In 2015, Google Photos would often tag black people as gorillas,[129] and in 2018, this still was not well resolved, but Google reportedly was still using the workaround to remove all gorillas from the training data and thus was not able to recognize real gorillas at all.[130] Similar issues with recognizing non-white people have been found in many other systems.[131] In 2016, Microsoft tested Tay, a chatbot that learned from Twitter, and it quickly picked up racist and sexist language.[132]\nBecause of such challenges, the effective use of machine learning may take longer to be adopted in other domains.[133] Concern for fairness in machine learning, that is, reducing bias in machine learning and propelling its use for human good, is increasingly expressed by artificial intelligence scientists, including Fei-Fei Li, who reminds engineers that \"[t]here's nothing artificial about AI. It's inspired by people, it's created by people, and\u2014most importantly\u2014it impacts people. It is a powerful tool we are only just beginning to understand, and that is a profound responsibility.\"[134]\n\nExplainability[edit]\nMain article: Explainable artificial intelligence\nExplainable AI (XAI), or Interpretable AI, or Explainable Machine Learning (XML), is artificial intelligence (AI) in which humans can understand the decisions or predictions made by the AI.[135] It contrasts with the \"black box\" concept in machine learning where even its designers cannot explain why an AI arrived at a specific decision.[136] By refining the mental models of users of AI-powered systems and dismantling their misconceptions, XAI promises to help users perform more effectively. XAI may be an implementation of the social right to explanation.\n\nOverfitting[edit]\nMain article: Overfitting\nThe blue line could be an example of overfitting a linear function due to random noise.\nSettling on a bad, overly complex theory gerrymandered to fit all the past training data is known as overfitting. Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data but penalizing the theory in accordance with how complex the theory is.[137]\n\nOther limitations and vulnerabilities[edit]\nLearners can also disappoint by \"learning the wrong lesson\". A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses.[138] A real-world example is that, unlike humans, current image classifiers often do not primarily make judgments from the spatial relationship between components of the picture, and they learn relationships between pixels that humans are oblivious to, but that still correlate with images of certain types of real objects. Modifying these patterns on a legitimate image can result in \"adversarial\" images that the system misclassifies.[139][140]\nAdversarial vulnerabilities can also result in nonlinear systems, or from non-pattern perturbations. For some systems, it is possible to change the output by only changing a single adversarially chosen pixel.[141] Machine learning models are often vulnerable to manipulation and/or evasion via adversarial machine learning.[142]\nResearchers have demonstrated how backdoors can be placed undetectably into classifying (e.g., for categories \"spam\" and well-visible \"not spam\" of posts) machine learning models that are often developed and/or trained by third parties. Parties can change the classification of any input, including in cases for which a type of data/software transparency is provided, possibly including white-box access.[143][144][145]\n\nModel assessments[edit]\nClassification of machine learning models can be validated by accuracy estimation techniques like the holdout method, which splits the data in a training and test set (conventionally 2/3 training set and 1/3 test set designation) and evaluates the performance of the training model on the test set. In comparison, the K-fold-cross-validation method randomly partitions the data into K subsets and then K experiments are performed each respectively considering 1 subset for evaluation and the remaining K-1 subsets for training the model. In addition to the holdout and cross-validation methods, bootstrap, which samples n instances with replacement from the dataset, can be used to assess model accuracy.[146]\nIn addition to overall accuracy, investigators frequently report sensitivity and specificity meaning True Positive Rate (TPR) and True Negative Rate (TNR) respectively. Similarly, investigators sometimes report the false positive rate (FPR) as well as the false negative rate (FNR). However, these rates are ratios that fail to reveal their numerators and denominators. The total operating characteristic (TOC) is an effective method to express a model's diagnostic ability. TOC shows the numerators and denominators of the previously mentioned rates, thus TOC provides more information than the commonly used receiver operating characteristic (ROC) and ROC's associated area under the curve (AUC).[147]\n\nEthics[edit]\nSee also: AI alignment, Toronto Declaration, and Ethics of artificial intelligence\nMachine learning poses a host of ethical questions. Systems that are trained on datasets collected with biases may exhibit these biases upon use (algorithmic bias), thus digitizing cultural prejudices.[148] For example, in 1988, the UK's Commission for Racial Equality found that St. George's Medical School had been using a computer program trained from data of previous admissions staff and that this program had denied nearly 60 candidates who were found to either be women or have non-European sounding names.[126] Using job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants by similarity to previous successful applicants.[149][150] Another example includes predictive policing company Geolitica's predictive algorithm that resulted in \"disproportionately high levels of over-policing in low-income and minority communities\" after being trained with historical crime data.[129]\nWhile responsible collection of data and documentation of algorithmic rules used by a system is considered a critical part of machine learning, some researchers blame lack of participation and representation of minority population in the field of AI for machine learning's vulnerability to biases.[151] In fact, according to research carried out by the Computing Research Association (CRA) in 2021, \"female faculty merely make up 16.1%\" of all faculty members who focus on AI among several universities around the world.[152] Furthermore, among the group of \"new U.S. resident AI PhD graduates,\" 45% identified as white, 22.4% as Asian, 3.2% as Hispanic, and 2.4% as African American, which further demonstrates a lack of diversity in the field of AI.[152]\nAI can be well-equipped to make decisions in technical fields, which rely heavily on data and historical information. These decisions rely on objectivity and logical reasoning.[153] Because human languages contain biases, machines trained on language corpora will necessarily also learn these biases.[154][155]\nOther forms of ethical challenges, not related to personal biases, are seen in health care. There are concerns among health care professionals that these systems might not be designed in the public's interest but as income-generating machines.[156] This is especially true in the United States where there is a long-standing ethical dilemma of improving health care, but also increasing profits. For example, the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithm's proprietary owners hold stakes. There is potential for machine learning in health care to provide professionals an additional tool to diagnose, medicate, and plan recovery paths for patients, but this requires these biases to be mitigated.[157]\n\nHardware[edit]\nSince the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks (a particular narrow subdomain of machine learning) that contain many layers of nonlinear hidden units.[158] By 2019, graphic processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI.[159] OpenAI estimated the hardware computing used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of 3.4 months.[160][161]\n\nNeuromorphic/Physical Neural Networks[edit]\nA physical neural network or Neuromorphic computer  is a type of artificial neural network in which an electrically adjustable material is used to emulate the function of a neural synapse. \"Physical\" neural network is used to emphasize the reliance on physical hardware used to emulate neurons as opposed to software-based approaches. More generally the term is applicable to other artificial neural networks in which a memristor or other electrically adjustable resistance material is used to emulate a neural synapse.[162][163]\n\nEmbedded Machine Learning[edit]\nEmbedded Machine Learning is a sub-field of machine learning, where the machine learning model is run on embedded systems with limited computing resources such as wearable computers, edge devices and microcontrollers.[164][165][166] Running machine learning model in embedded devices removes the need for transferring and storing data on cloud servers for further processing, henceforth, reducing data breaches and privacy leaks happening because of transferring data, and also minimizes theft of intellectual properties, personal data and business secrets. Embedded Machine Learning could be applied through several techniques including hardware acceleration,[167][168] using approximate computing,[169] optimization of machine learning models and many more.[170][171] Pruning, Quantization, Knowledge Distillation, Low-Rank Factorization, Network Architecture Search (NAS) & Parameter Sharing are few of the techniques used for optimization of machine learning models.\n\nSoftware[edit]\nSoftware suites containing a variety of machine learning algorithms include the following:\n\nFree and open-source software[edit]\n\nCaffe\nDeeplearning4j\nDeepSpeed\nELKI\nGoogle JAX\nInfer.NET\nKeras\nKubeflow\nLightGBM\nMahout\nMallet\nMicrosoft Cognitive Toolkit\nML.NET\nmlpack\nMXNet\nOpenNN\nOrange\npandas (software)\nROOT (TMVA with ROOT)\nscikit-learn\nShogun\nSpark MLlib\nSystemML\nTensorFlow\nTorch / PyTorch\nWeka / MOA\nXGBoost\nYooreeka\n\nProprietary software with free and open-source editions[edit]\nKNIME\nRapidMiner\nProprietary software[edit]\n\nAmazon Machine Learning\nAngoss KnowledgeSTUDIO\nAzure Machine Learning\nIBM Watson Studio\nGoogle Cloud Vertex AI\nGoogle Prediction API\nIBM SPSS Modeler\nKXEN Modeler\nLIONsolver\nMathematica\nMATLAB\nNeural Designer\nNeuroSolutions\nOracle Data Mining\nOracle AI Platform Cloud Service\nPolyAnalyst\nRCASE\nSAS Enterprise Miner\nSequenceL\nSplunk\nSTATISTICA Data Miner\n\nJournals[edit]\nJournal of Machine Learning Research\nMachine Learning\nNature Machine Intelligence\nNeural Computation\nIEEE Transactions on Pattern Analysis and Machine Intelligence\nConferences[edit]\nAAAI Conference on Artificial Intelligence\nAssociation for Computational Linguistics (ACL)\nEuropean Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)\nInternational Conference on Computational Intelligence Methods for Bioinformatics and Biostatistics (CIBB)\nInternational Conference on Machine Learning (ICML)\nInternational Conference on Learning Representations (ICLR)\nInternational Conference on Intelligent Robots and Systems (IROS)\nConference on Knowledge Discovery and Data Mining (KDD)\nConference on Neural Information Processing Systems (NeurIPS)\nSee also[edit]\nAutomated machine learning\u00a0\u2013 Process of automating the application of machine learning\nBig data\u00a0\u2013 Extremely large or complex datasets\nDeep learning \u2014 branch of ML concerned with artificial neural networks\nDifferentiable programming\u00a0\u2013 Programming paradigm\nList of datasets for machine-learning research\u00a0\u2013 Machine learning based fault detection in Electronics Circuit\nM-theory (learning framework)\nReferences[edit]\n\n\n^ The definition \"without being explicitly programmed\" is often attributed to Arthur Samuel, who coined the term \"machine learning\" in 1959, but the phrase is not found verbatim in this publication, and may be a paraphrase that appeared later. Confer \"Paraphrasing Arthur Samuel (1959), the question is: How can computers learn to solve problems without being explicitly programmed?\" in Koza, John R.; Bennett, Forrest H.; Andre, David; Keane, Martin A. (1996). \"Automated Design of Both the Topology and Sizing of Analog Electrical Circuits Using Genetic Programming\". Artificial Intelligence in Design '96. Artificial Intelligence in Design '96. Dordrecht, Netherlands: Springer Netherlands. pp.\u00a0151\u2013170. doi:10.1007/978-94-009-0279-4_9. ISBN\u00a0978-94-010-6610-5.\n\n^ \"What is Machine Learning?\". IBM. 22 September 2021. Archived from the original on 2023-12-27. Retrieved 2023-06-27.\n\n^ Hu, Junyan; Niu, Hanlin; Carrasco, Joaquin; Lennox, Barry; Arvin, Farshad (2020). \"Voronoi-Based Multi-Robot Autonomous Exploration in Unknown Environments via Deep Reinforcement Learning\". IEEE Transactions on Vehicular Technology. 69 (12): 14413\u201314423. doi:10.1109/tvt.2020.3034800. ISSN\u00a00018-9545. S2CID\u00a0228989788.\n\n^ a b Yoosefzadeh-Najafabadi, Mohsen; Hugh, Earl; Tulpan, Dan; Sulik, John; Eskandari, Milad (2021). \"Application of Machine Learning Algorithms in Plant Breeding: Predicting Yield From Hyperspectral Reflectance in Soybean?\". Front. Plant Sci. 11: 624273. doi:10.3389/fpls.2020.624273. PMC\u00a07835636. PMID\u00a033510761.\n\n^ a b c Bishop, C. M. (2006), Pattern Recognition and Machine Learning, Springer, ISBN\u00a0978-0-387-31073-2\n\n^ Machine learning and pattern recognition \"can be viewed as two facets of the same field\".[5]:\u200avii\u200a\n\n^ a b Friedman, Jerome H. (1998). \"Data Mining and Statistics: What's the connection?\". Computing Science and Statistics. 29 (1): 3\u20139.\n\n^ Samuel, Arthur (1959). \"Some Studies in Machine Learning Using the Game of Checkers\". IBM Journal of Research and Development. 3 (3): 210\u2013229. CiteSeerX\u00a010.1.1.368.2254. doi:10.1147/rd.33.0210. S2CID\u00a02126705.\n\n^ a b R. Kohavi and F. Provost, \"Glossary of terms\", Machine Learning, vol. 30, no. 2\u20133, pp. 271\u2013274, 1998.\n\n^ Gerovitch, Slava (9 April 2015). \"How the Computer Got Its Revenge on the Soviet Union\". Nautilus. Archived from the original on 22 September 2021. Retrieved 19 September 2021.\n\n^ Lindsay, Richard P. (1 September 1964). \"The Impact of Automation On Public Administration\". Western Political Quarterly. 17 (3): 78\u201381. doi:10.1177/106591296401700364. ISSN\u00a00043-4078. S2CID\u00a0154021253. Archived from the original on 6 October 2021. Retrieved 6 October 2021.\n\n^ a b c \"History and Evolution of Machine Learning: A Timeline\". WhatIs. Archived from the original on 2023-12-08. Retrieved 2023-12-08.\n\n^ Milner, Peter M. (1993). \"The Mind and Donald O. Hebb\". Scientific American. 268 (1): 124\u2013129. Bibcode:1993SciAm.268a.124M. doi:10.1038/scientificamerican0193-124. ISSN\u00a00036-8733. JSTOR\u00a024941344. PMID\u00a08418480. Archived from the original on 2023-12-20. Retrieved 2023-12-09.\n\n^ \"Science: The Goof Button\", Time (magazine), 18 August 1961.\n\n^ Nilsson N. Learning Machines, McGraw Hill, 1965.\n\n^ Duda, R., Hart P. Pattern Recognition and Scene Analysis, Wiley Interscience, 1973\n\n^ S. Bozinovski \"Teaching space: A representation concept for adaptive pattern classification\" COINS Technical Report No. 81-28, Computer and Information Science Department, University of Massachusetts at Amherst, MA, 1981. https://web.cs.umass.edu/publication/docs/1981/UM-CS-1981-028.pdf Archived 2021-02-25 at the Wayback Machine\n\n^ a b Mitchell, T. (1997). Machine Learning. McGraw Hill. p.\u00a02. ISBN\u00a0978-0-07-042807-2.\n\n^ Harnad, Stevan (2008), \"The Annotation Game: On Turing (1950) on Computing, Machinery, and Intelligence\", in Epstein, Robert; Peters, Grace (eds.), The Turing Test Sourcebook: Philosophical and Methodological Issues in the Quest for the Thinking Computer, Kluwer, pp.\u00a023\u201366, ISBN\u00a09781402067082, archived from the original on 2012-03-09, retrieved 2012-12-11\n\n^ \"Introduction to AI Part 1\". Edzion. 2020-12-08. Archived from the original on 2021-02-18. Retrieved 2020-12-09.\n\n^ Sindhu V, Nivedha S, Prakash M (February 2020). \"An Empirical Science Research on Bioinformatics in Machine Learning\". Journal of Mechanics of Continua and Mathematical Sciences (7). doi:10.26782/jmcms.spl.7/2020.02.00006.\n\n^ Sarle, Warren S. (1994). \"Neural Networks and statistical models\". SUGI 19: proceedings of the Nineteenth Annual SAS Users Group International Conference. SAS Institute. pp.\u00a01538\u201350. ISBN\u00a09781555446116. OCLC\u00a035546178.\n\n^ a b c d Russell, Stuart; Norvig, Peter (2003) [1995]. Artificial Intelligence: A Modern Approach (2nd\u00a0ed.). Prentice Hall. ISBN\u00a0978-0137903955.\n\n^ a b Langley, Pat (2011). \"The changing science of machine learning\". Machine Learning. 82 (3): 275\u20139. doi:10.1007/s10994-011-5242-y.\n\n^ Mahoney, Matt. \"Rationale for a Large Text Compression Benchmark\". Florida Institute of Technology. Retrieved 5 March 2013.\n\n^ Shmilovici A.; Kahiri Y.; Ben-Gal I.; Hauser S. (2009). \"Measuring the Efficiency of the Intraday Forex Market with a Universal Data Compression Algorithm\" (PDF). Computational Economics. 33 (2): 131\u2013154. CiteSeerX\u00a010.1.1.627.3751. doi:10.1007/s10614-008-9153-3. S2CID\u00a017234503. Archived (PDF) from the original on 2009-07-09.\n\n^ I. Ben-Gal (2008). \"On the Use of Data Compression Measures to Analyze Robust Designs\" (PDF). IEEE Transactions on Reliability. 54 (3): 381\u2013388. doi:10.1109/TR.2005.853280. S2CID\u00a09376086.\n\n^ D. Scully; Carla E. Brodley (2006). \"Compression and Machine Learning: A New Perspective on Feature Space Vectors\". Data Compression Conference (DCC'06). p.\u00a0332. doi:10.1109/DCC.2006.13. ISBN\u00a00-7695-2545-8. S2CID\u00a012311412.\n\n^ Gary Adcock (January 5, 2023). \"What Is AI Video Compression?\". massive.io. Retrieved 6 April 2023.\n\n^ Mentzer, Fabian; Toderici, George; Tschannen, Michael; Agustsson, Eirikur (2020). \"High-Fidelity Generative Image Compression\". arXiv:2006.09965 [eess.IV].\n\n^ \"What is Unsupervised Learning? | IBM\". www.ibm.com. 23 September 2021. Retrieved 2024-02-05.\n\n^ \"Differentially private clustering for large-scale datasets\". blog.research.google. 2023-05-25. Retrieved 2024-03-16.\n\n^ Edwards, Benj (2023-09-28). \"AI language models can exceed PNG and FLAC in lossless compression, says study\". Ars Technica. Retrieved 2024-03-07.\n\n^ Le Roux, Nicolas; Bengio, Yoshua; Fitzgibbon, Andrew (2012). \"Improving First and Second-Order Methods by Modeling Uncertainty\". In Sra, Suvrit; Nowozin, Sebastian; Wright, Stephen J. (eds.). Optimization for Machine Learning. MIT Press. p.\u00a0404. ISBN\u00a09780262016469. Archived from the original on 2023-01-17. Retrieved 2020-11-12.\n\n^ Bzdok, Danilo; Altman, Naomi; Krzywinski, Martin (2018). \"Statistics versus Machine Learning\". Nature Methods. 15 (4): 233\u2013234. doi:10.1038/nmeth.4642. PMC\u00a06082636. PMID\u00a030100822.\n\n^ a b Michael I. Jordan (2014-09-10). \"statistics and machine learning\". reddit. Archived from the original on 2017-10-18. Retrieved 2014-10-01.\n\n^ Hung et al. Algorithms to Measure Surgeon Performance and Anticipate Clinical Outcomes in Robotic Surgery. JAMA Surg. 2018\n\n^ Cornell University Library (August 2001). \"Breiman: Statistical Modeling: The Two Cultures (with comments and a rejoinder by the author)\". Statistical Science. 16 (3). doi:10.1214/ss/1009213726. S2CID\u00a062729017. Archived from the original on 26 June 2017. Retrieved 8 August 2015.\n\n^ Gareth James; Daniela Witten; Trevor Hastie; Robert Tibshirani (2013). An Introduction to Statistical Learning. Springer. p.\u00a0vii. Archived from the original on 2019-06-23. Retrieved 2014-10-25.\n\n^ Ramezanpour, A.; Beam, A.L.; Chen, J.H.; Mashaghi, A. (17 November 2020). \"Statistical Physics for Medical Diagnostics: Learning, Inference, and Optimization Algorithms\". Diagnostics. 10 (11): 972. doi:10.3390/diagnostics10110972. PMC\u00a07699346. PMID\u00a033228143.\n\n^ Mashaghi, A.; Ramezanpour, A. (16 March 2018). \"Statistical physics of medical diagnostics: Study of a probabilistic model\". Physical Review E. 97 (3\u20131): 032118. arXiv:1803.10019. Bibcode:2018PhRvE..97c2118M. doi:10.1103/PhysRevE.97.032118. PMID\u00a029776109. S2CID\u00a04955393.\n\n^ Mohri, Mehryar; Rostamizadeh, Afshin; Talwalkar, Ameet (2012). Foundations of Machine Learning. US, Massachusetts: MIT Press. ISBN\u00a09780262018258.\n\n^ Alpaydin, Ethem (2010). Introduction to Machine Learning. London: The MIT Press. ISBN\u00a0978-0-262-01243-0. Retrieved 4 February 2017.\n\n^ Jordan, M. I.; Mitchell, T. M. (17 July 2015). \"Machine learning: Trends, perspectives, and prospects\". Science. 349 (6245): 255\u2013260. Bibcode:2015Sci...349..255J. doi:10.1126/science.aaa8415. PMID\u00a026185243. S2CID\u00a0677218.\n\n^ El Naqa, Issam; Murphy, Martin J. (2015). \"What is Machine Learning?\". Machine Learning in Radiation Oncology. pp.\u00a03\u201311. doi:10.1007/978-3-319-18305-3_1. ISBN\u00a0978-3-319-18304-6. S2CID\u00a0178586107.\n\n^ Okolie, Jude A.; Savage, Shauna; Ogbaga, Chukwuma C.; Gunes, Burcu (June 2022). \"Assessing the potential of machine learning methods to study the removal of pharmaceuticals from wastewater using biochar or activated carbon\". Total Environment Research Themes. 1\u20132: 100001. Bibcode:2022TERT....100001O. doi:10.1016/j.totert.2022.100001. S2CID\u00a0249022386.\n\n^ Russell, Stuart J.; Norvig, Peter (2010). Artificial Intelligence: A Modern Approach (Third\u00a0ed.). Prentice Hall. ISBN\u00a09780136042594.\n\n^ Mohri, Mehryar; Rostamizadeh, Afshin; Talwalkar, Ameet (2012). Foundations of Machine Learning. The MIT Press. ISBN\u00a09780262018258.\n\n^ Alpaydin, Ethem (2010). Introduction to Machine Learning. MIT Press. p.\u00a09. ISBN\u00a0978-0-262-01243-0. Archived from the original on 2023-01-17. Retrieved 2018-11-25.\n\n^ \"Lecture 2 Notes: Supervised Learning\". www.cs.cornell.edu. Retrieved 2024-07-01.\n\n^ Jordan, Michael I.; Bishop, Christopher M. (2004). \"Neural Networks\". In Allen B. Tucker (ed.). Computer Science Handbook, Second Edition (Section VII: Intelligent Systems). Boca Raton, Florida: Chapman & Hall/CRC Press LLC. ISBN\u00a0978-1-58488-360-9.\n\n^ Zhang, Bosen; Huang, Haiyan; Tibbs-Cortes, Laura E.; Vanous, Adam; Zhang, Zhiwu; Sanguinet, Karen; Garland-Campbell, Kimberly A.; Yu, Jianming; Li, Xianran (2023). \"Streamline unsupervised machine learning to survey and graph indel-based haplotypes from pan-genomes\". Molecular Plant. 16 (6): 975\u2013978. doi:10.1016/j.molp.2023.05.005. PMID\u00a037202927.\n\n^ Zhang, Bosen; Huang, Haiyan; Tibbs-Cortes, Laura E.; Vanous, Adam; Zhang, Zhiwu; Sanguinet, Karen; Garland-Campbell, Kimberly A.; Yu, Jianming; Li, Xianran (2023-02-13). Streamline unsupervised machine learning to survey and graph indel-based haplotypes from pan-genomes (Report). doi:10.1101/2023.02.11.527743.\n\n^ Misra, Ishan; Maaten, Laurens van der (2020). Self-Supervised Learning of Pretext-Invariant Representations. 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Seattle, WA, USA: IEEE. pp.\u00a06707\u20136717. arXiv:1912.01991. doi:10.1109/CVPR42600.2020.00674.\n\n^ Jaiswal, Ashish; Babu, Ashwin Ramesh; Zadeh, Mohammad Zaki; Banerjee, Debapriya; Makedon, Fillia (March 2021). \"A Survey on Contrastive Self-Supervised Learning\". Technologies. 9 (1): 2. arXiv:2011.00362. doi:10.3390/technologies9010002. ISSN\u00a02227-7080.\n\n^ Alex Ratner; Stephen Bach; Paroma Varma; Chris. \"Weak Supervision: The New Programming Paradigm for Machine Learning\". hazyresearch.github.io. referencing work by many other members of Hazy Research. Archived from the original on 2019-06-06. Retrieved 2019-06-06.\n\n^ van Otterlo, M.; Wiering, M. (2012). \"Reinforcement Learning and Markov Decision Processes\". Reinforcement Learning. Adaptation, Learning, and Optimization. Vol.\u00a012. pp.\u00a03\u201342. doi:10.1007/978-3-642-27645-3_1. ISBN\u00a0978-3-642-27644-6.\n\n^ Roweis, Sam T.; Saul, Lawrence K. (22 Dec 2000). \"Nonlinear Dimensionality Reduction by Locally Linear Embedding\". Science. 290 (5500): 2323\u20132326. Bibcode:2000Sci...290.2323R. doi:10.1126/science.290.5500.2323. PMID\u00a011125150. S2CID\u00a05987139. Archived from the original on 15 August 2021. Retrieved 17 July 2023.\n\n^ Pavel Brazdil; Christophe Giraud Carrier; Carlos Soares; Ricardo Vilalta (2009). Metalearning: Applications to Data Mining (Fourth\u00a0ed.). Springer Science+Business Media. pp.\u00a010\u201314, passim. ISBN\u00a0978-3540732624.\n\n^ Bozinovski, S. (1982). \"A self-learning system using secondary reinforcement\". In Trappl, Robert (ed.). Cybernetics and Systems Research: Proceedings of the Sixth European Meeting on Cybernetics and Systems Research. North-Holland. pp. 397\u2013402. ISBN\u00a0978-0-444-86488-8.\n\n^ Bozinovski, Stevo (2014) \"Modeling mechanisms of cognition-emotion interaction in artificial neural networks, since 1981.\" Procedia Computer Science p. 255-263\n\n^ Bozinovski, S. (2001) \"Self-learning agents: A connectionist theory of emotion based on crossbar value judgment.\" Cybernetics and Systems 32(6) 637\u2013667.\n\n^ Y. Bengio; A. Courville; P. Vincent (2013). \"Representation Learning: A Review and New Perspectives\". IEEE Transactions on Pattern Analysis and Machine Intelligence. 35 (8): 1798\u20131828. arXiv:1206.5538. doi:10.1109/tpami.2013.50. PMID\u00a023787338. S2CID\u00a0393948.\n\n^ Nathan Srebro; Jason D. M. Rennie; Tommi S. Jaakkola (2004). Maximum-Margin Matrix Factorization. NIPS.\n\n^ Coates, Adam; Lee, Honglak; Ng, Andrew Y. (2011). An analysis of single-layer networks in unsupervised feature learning (PDF). Int'l Conf. on AI and Statistics (AISTATS). Archived from the original (PDF) on 2017-08-13. Retrieved 2018-11-25.\n\n^ Csurka, Gabriella; Dance, Christopher C.; Fan, Lixin; Willamowski, Jutta; Bray, C\u00e9dric (2004). Visual categorization with bags of keypoints (PDF). ECCV Workshop on Statistical Learning in Computer Vision. Archived (PDF) from the original on 2019-07-13. Retrieved 2019-08-29.\n\n^ Daniel Jurafsky; James H. Martin (2009). Speech and Language Processing. Pearson Education International. pp.\u00a0145\u2013146.\n\n^ Lu, Haiping; Plataniotis, K.N.; Venetsanopoulos, A.N. (2011). \"A Survey of Multilinear Subspace Learning for Tensor Data\" (PDF). Pattern Recognition. 44 (7): 1540\u20131551. Bibcode:2011PatRe..44.1540L. doi:10.1016/j.patcog.2011.01.004. Archived (PDF) from the original on 2019-07-10. Retrieved 2015-09-04.\n\n^ Yoshua Bengio (2009). Learning Deep Architectures for AI. Now Publishers Inc. pp.\u00a01\u20133. ISBN\u00a0978-1-60198-294-0. Archived from the original on 2023-01-17. Retrieved 2016-02-15.\n\n^ Tillmann, A. M. (2015). \"On the Computational Intractability of Exact and Approximate Dictionary Learning\". IEEE Signal Processing Letters. 22 (1): 45\u201349. arXiv:1405.6664. Bibcode:2015ISPL...22...45T. doi:10.1109/LSP.2014.2345761. S2CID\u00a013342762.\n\n^ Aharon, M, M Elad, and A Bruckstein. 2006. \"K-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation Archived 2018-11-23 at the Wayback Machine.\" Signal Processing, IEEE Transactions on 54 (11): 4311\u20134322\n\n^ Zimek, Arthur; Schubert, Erich (2017), \"Outlier Detection\", Encyclopedia of Database Systems, Springer New York, pp.\u00a01\u20135, doi:10.1007/978-1-4899-7993-3_80719-1, ISBN\u00a09781489979933\n\n^ Hodge, V. J.; Austin, J. (2004). \"A Survey of Outlier Detection Methodologies\" (PDF). Artificial Intelligence Review. 22 (2): 85\u2013126. CiteSeerX\u00a010.1.1.318.4023. doi:10.1007/s10462-004-4304-y. S2CID\u00a059941878. Archived (PDF) from the original on 2015-06-22. Retrieved 2018-11-25.\n\n^ Dokas, Paul; Ertoz, Levent; Kumar, Vipin; Lazarevic, Aleksandar; Srivastava, Jaideep; Tan, Pang-Ning (2002). \"Data mining for network intrusion detection\" (PDF). Proceedings NSF Workshop on Next Generation Data Mining. Archived (PDF) from the original on 2015-09-23. Retrieved 2023-03-26.\n\n^ Chandola, V.; Banerjee, A.; Kumar, V. (2009). \"Anomaly detection: A survey\". ACM Computing Surveys. 41 (3): 1\u201358. doi:10.1145/1541880.1541882. S2CID\u00a0207172599.\n\n^ Fleer, S.; Moringen, A.; Klatzky, R. L.; Ritter, H. (2020). \"Learning efficient haptic shape exploration with a rigid tactile sensor array, S. Fleer, A. Moringen, R. Klatzky, H. Ritter\". PLOS ONE. 15 (1): e0226880. arXiv:1902.07501. doi:10.1371/journal.pone.0226880. PMC\u00a06940144. PMID\u00a031896135.\n\n^ Moringen, Alexandra; Fleer, Sascha; Walck, Guillaume; Ritter, Helge (2020), Nisky, Ilana; Hartcher-O'Brien, Jess; Wiertlewski, Micha\u00ebl; Smeets, Jeroen (eds.), \"Attention-Based Robot Learning of Haptic Interaction\", Haptics: Science, Technology, Applications, Lecture Notes in Computer Science, vol.\u00a012272, Cham: Springer International Publishing, pp.\u00a0462\u2013470, doi:10.1007/978-3-030-58147-3_51, ISBN\u00a0978-3-030-58146-6, S2CID\u00a0220069113\n\n^ Piatetsky-Shapiro, Gregory (1991), Discovery, analysis, and presentation of strong rules, in Piatetsky-Shapiro, Gregory; and Frawley, William J.; eds., Knowledge Discovery in Databases, AAAI/MIT Press, Cambridge, MA.\n\n^ Bassel, George W.; Glaab, Enrico; Marquez, Julietta; Holdsworth, Michael J.; Bacardit, Jaume (2011-09-01). \"Functional Network Construction in Arabidopsis Using Rule-Based Machine Learning on Large-Scale Data Sets\". The Plant Cell. 23 (9): 3101\u20133116. doi:10.1105/tpc.111.088153. ISSN\u00a01532-298X. PMC\u00a03203449. PMID\u00a021896882.\n\n^ Agrawal, R.; Imieli\u0144ski, T.; Swami, A. (1993). \"Mining association rules between sets of items in large databases\". Proceedings of the 1993 ACM SIGMOD international conference on Management of data - SIGMOD '93. p.\u00a0207. CiteSeerX\u00a010.1.1.40.6984. doi:10.1145/170035.170072. ISBN\u00a0978-0897915922. S2CID\u00a0490415.\n\n^ Urbanowicz, Ryan J.; Moore, Jason H. (2009-09-22). \"Learning Classifier Systems: A Complete Introduction, Review, and Roadmap\". Journal of Artificial Evolution and Applications. 2009: 1\u201325. doi:10.1155/2009/736398. ISSN\u00a01687-6229.\n\n^ Plotkin G.D. Automatic Methods of Inductive Inference Archived 2017-12-22 at the Wayback Machine, PhD thesis, University of Edinburgh, 1970.\n\n^ Shapiro, Ehud Y. Inductive inference of theories from facts Archived 2021-08-21 at the Wayback Machine, Research Report 192, Yale University, Department of Computer Science, 1981. Reprinted in J.-L. Lassez, G. Plotkin (Eds.), Computational Logic, The MIT Press, Cambridge, MA, 1991, pp. 199\u2013254.\n\n^ Shapiro, Ehud Y. (1983). Algorithmic program debugging. Cambridge, Mass: MIT Press. ISBN\u00a00-262-19218-7\n\n^ Shapiro, Ehud Y. \"The model inference system Archived 2023-04-06 at the Wayback Machine.\" Proceedings of the 7th international joint conference on Artificial intelligence-Volume 2. Morgan Kaufmann Publishers Inc., 1981.\n\n^ Burkov, Andriy (2019). The hundred-page machine learning book. Polen: Andriy Burkov. ISBN\u00a0978-1-9995795-0-0.\n\n^ Russell, Stuart J.; Norvig, Peter (2021). Artificial intelligence: a modern approach. Pearson series in artificial intelligence (Fourth\u00a0ed.). Hoboken: Pearson. ISBN\u00a0978-0-13-461099-3.\n\n^ Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng. \"Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations Archived 2017-10-18 at the Wayback Machine\" Proceedings of the 26th Annual International Conference on Machine Learning, 2009.\n\n^ Cortes, Corinna; Vapnik, Vladimir N. (1995). \"Support-vector networks\". Machine Learning. 20 (3): 273\u2013297. doi:10.1007/BF00994018.\n\n^ Stevenson, Christopher. \"Tutorial: Polynomial Regression in Excel\". facultystaff.richmond.edu. Archived from the original on 2 June 2013. Retrieved 22 January 2017.\n\n^ The documentation for scikit-learn also has similar examples Archived 2022-11-02 at the Wayback Machine.\n\n^ Goldberg, David E.; Holland, John H. (1988). \"Genetic algorithms and machine learning\" (PDF). Machine Learning. 3 (2): 95\u201399. doi:10.1007/bf00113892. S2CID\u00a035506513. Archived (PDF) from the original on 2011-05-16. Retrieved 2019-09-03.\n\n^ Michie, D.; Spiegelhalter, D. J.; Taylor, C. C. (1994). \"Machine Learning, Neural and Statistical Classification\". Ellis Horwood Series in Artificial Intelligence. Bibcode:1994mlns.book.....M.\n\n^ Zhang, Jun; Zhan, Zhi-hui; Lin, Ying; Chen, Ni; Gong, Yue-jiao; Zhong, Jing-hui; Chung, Henry S.H.; Li, Yun; Shi, Yu-hui (2011). \"Evolutionary Computation Meets Machine Learning: A Survey\". Computational Intelligence Magazine. 6 (4): 68\u201375. doi:10.1109/mci.2011.942584. S2CID\u00a06760276.\n\n^ \"Federated Learning: Collaborative Machine Learning without Centralized Training Data\". Google AI Blog. 6 April 2017. Archived from the original on 2019-06-07. Retrieved 2019-06-08.\n\n^ Machine learning is included in the CFA Curriculum (discussion is top-down); see: Kathleen DeRose and Christophe Le Lanno (2020). \"Machine Learning\" Archived 2020-01-13 at the Wayback Machine.\n\n^ Ivanenko, Mikhail; Smolik, Waldemar T.; Wanta, Damian; Midura, Mateusz; Wr\u00f3blewski, Przemys\u0142aw; Hou, Xiaohan; Yan, Xiaoheng (2023). \"Image Reconstruction Using Supervised Learning in Wearable Electrical Impedance Tomography of the Thorax\". Sensors. 23 (18): 7774. Bibcode:2023Senso..23.7774I. doi:10.3390/s23187774. PMC\u00a010538128. PMID\u00a037765831.\n\n^ \"BelKor Home Page\" research.att.com\n\n^ \"The Netflix Tech Blog: Netflix Recommendations: Beyond the 5 stars (Part 1)\". 2012-04-06. Archived from the original on 31 May 2016. Retrieved 8 August 2015.\n\n^ Scott Patterson (13 July 2010). \"Letting the Machines Decide\". The Wall Street Journal. Archived from the original on 24 June 2018. Retrieved 24 June 2018.\n\n^ Vinod Khosla (January 10, 2012). \"Do We Need Doctors or Algorithms?\". Tech Crunch. Archived from the original on June 18, 2018. Retrieved October 20, 2016.\n\n^ When A Machine Learning Algorithm Studied Fine Art Paintings, It Saw Things Art Historians Had Never Noticed Archived 2016-06-04 at the Wayback Machine, The Physics at ArXiv blog\n\n^ Vincent, James (2019-04-10). \"The first AI-generated textbook shows what robot writers are actually good at\". The Verge. Archived from the original on 2019-05-05. Retrieved 2019-05-05.\n\n^ Vaishya, Raju; Javaid, Mohd; Khan, Ibrahim Haleem; Haleem, Abid (July 1, 2020). \"Artificial Intelligence (AI) applications for COVID-19 pandemic\". Diabetes & Metabolic Syndrome: Clinical Research & Reviews. 14 (4): 337\u2013339. doi:10.1016/j.dsx.2020.04.012. PMC\u00a07195043. PMID\u00a032305024.\n\n^ Rezapouraghdam, Hamed; Akhshik, Arash; Ramkissoon, Haywantee (March 10, 2021). \"Application of machine learning to predict visitors' green behavior in marine protected areas: evidence from Cyprus\". Journal of Sustainable Tourism. 31 (11): 2479\u20132505. doi:10.1080/09669582.2021.1887878. hdl:10037/24073.\n\n^ Dey, Somdip; Singh, Amit Kumar; Wang, Xiaohang; McDonald-Maier, Klaus (2020-06-15). \"User Interaction Aware Reinforcement Learning for Power and Thermal Efficiency of CPU-GPU Mobile MPSoCs\". 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE) (PDF). pp.\u00a01728\u20131733. doi:10.23919/DATE48585.2020.9116294. ISBN\u00a0978-3-9819263-4-7. S2CID\u00a0219858480. Archived from the original on 2021-12-13. Retrieved 2022-01-20.\n\n^ Quested, Tony. \"Smartphones get smarter with Essex innovation\". Business Weekly. Archived from the original on 2021-06-24. Retrieved 2021-06-17.\n\n^ Williams, Rhiannon (2020-07-21). \"Future smartphones 'will prolong their own battery life by monitoring owners' behaviour'\". i. Archived from the original on 2021-06-24. Retrieved 2021-06-17.\n\n^ Rasekhschaffe, Keywan Christian; Jones, Robert C. (2019-07-01). \"Machine Learning for Stock Selection\". Financial Analysts Journal. 75 (3): 70\u201388. doi:10.1080/0015198X.2019.1596678. ISSN\u00a00015-198X. S2CID\u00a0108312507. Archived from the original on 2023-11-26. Retrieved 2023-11-26.\n\n^ Chung, Yunsie; Green, William H. (2024). \"Machine learning from quantum chemistry to predict experimental solvent effects on reaction rates\". Chemical Science. 15 (7): 2410\u20132424. doi:10.1039/D3SC05353A. ISSN\u00a02041-6520. PMC\u00a010866337. PMID\u00a038362410. Archived from the original on 2024-05-19. Retrieved 2024-04-21.\n\n^ Sun, Yuran; Huang, Shih-Kai; Zhao, Xilei (2024-02-01). \"Predicting Hurricane Evacuation Decisions with Interpretable Machine Learning Methods\". International Journal of Disaster Risk Science. 15 (1): 134\u2013148. arXiv:2303.06557. Bibcode:2024IJDRS..15..134S. doi:10.1007/s13753-024-00541-1. ISSN\u00a02192-6395.\n\n^ Sun, Yuran; Zhao, Xilei; Lovreglio, Ruggiero; Kuligowski, Erica (2024-01-01), Naser, M. Z. (ed.), \"8 - AI for large-scale evacuation modeling: promises and challenges\", Interpretable Machine Learning for the Analysis, Design, Assessment, and Informed Decision Making for Civil Infrastructure, Woodhead Publishing Series in Civil and Structural Engineering, Woodhead Publishing, pp.\u00a0185\u2013204, ISBN\u00a0978-0-12-824073-1, archived from the original on 2024-05-19, retrieved 2024-05-19\n\n^ Xu, Ningzhe; Lovreglio, Ruggiero; Kuligowski, Erica D.; Cova, Thomas J.; Nilsson, Daniel; Zhao, Xilei (2023-03-01). \"Predicting and Assessing Wildfire Evacuation Decision-Making Using Machine Learning: Findings from the 2019 Kincade Fire\". Fire Technology. 59 (2): 793\u2013825. doi:10.1007/s10694-023-01363-1. ISSN\u00a01572-8099. Archived from the original on 2024-05-19. Retrieved 2024-05-19.\n\n^ Wang, Ke; Shi, Xiupeng; Goh, Algena Pei Xuan; Qian, Shunzhi (2019-06-01). \"A machine learning based study on pedestrian movement dynamics under emergency evacuation\". Fire Safety Journal. 106: 163\u2013176. Bibcode:2019FirSJ.106..163W. doi:10.1016/j.firesaf.2019.04.008. hdl:10356/143390. ISSN\u00a00379-7112. Archived from the original on 2024-05-19. Retrieved 2024-05-19.\n\n^ Zhao, Xilei; Lovreglio, Ruggiero; Nilsson, Daniel (2020-05-01). \"Modelling and interpreting pre-evacuation decision-making using machine learning\". Automation in Construction. 113: 103140. doi:10.1016/j.autcon.2020.103140. ISSN\u00a00926-5805. Archived from the original on 2024-05-19. Retrieved 2024-05-19.\n\n^ \"Why Machine Learning Models Often Fail to Learn: QuickTake Q&A\". Bloomberg.com. 2016-11-10. Archived from the original on 2017-03-20. Retrieved 2017-04-10.\n\n^ \"The First Wave of Corporate AI Is Doomed to Fail\". Harvard Business Review. 2017-04-18. Archived from the original on 2018-08-21. Retrieved 2018-08-20.\n\n^ \"Why the A.I. euphoria is doomed to fail\". VentureBeat. 2016-09-18. Archived from the original on 2018-08-19. Retrieved 2018-08-20.\n\n^ \"9 Reasons why your machine learning project will fail\". www.kdnuggets.com. Archived from the original on 2018-08-21. Retrieved 2018-08-20.\n\n^ a b Babuta, Alexander; Oswald, Marion; Rinik, Christine (2018). Transparency and Intelligibility (Report). Royal United Services Institute (RUSI). pp.\u00a017\u201322. Archived from the original on 2023-12-09. Retrieved 2023-12-09.\n\n^ \"Why Uber's self-driving car killed a pedestrian\". The Economist. Archived from the original on 2018-08-21. Retrieved 2018-08-20.\n\n^ \"IBM's Watson recommended 'unsafe and incorrect' cancer treatments \u2013 STAT\". STAT. 2018-07-25. Archived from the original on 2018-08-21. Retrieved 2018-08-21.\n\n^ Hernandez, Daniela; Greenwald, Ted (2018-08-11). \"IBM Has a Watson Dilemma\". The Wall Street Journal. ISSN\u00a00099-9660. Archived from the original on 2018-08-21. Retrieved 2018-08-21.\n\n^ Allyn, Bobby (Feb 27, 2023). \"How Microsoft's experiment in artificial intelligence tech backfired\". National Public Radio. Archived from the original on December 8, 2023. Retrieved Dec 8, 2023.\n\n^ Reddy, Shivani M.; Patel, Sheila; Weyrich, Meghan; Fenton, Joshua; Viswanathan, Meera (2020). \"Comparison of a traditional systematic review approach with review-of-reviews and semi-automation as strategies to update the evidence\". Systematic Reviews. 9 (1): 243. doi:10.1186/s13643-020-01450-2. ISSN\u00a02046-4053. PMC\u00a07574591. PMID\u00a033076975.\n\n^ a b Garcia, Megan (2016). \"Racist in the Machine\". World Policy Journal. 33 (4): 111\u2013117. doi:10.1215/07402775-3813015. ISSN\u00a00740-2775. S2CID\u00a0151595343.\n\n^ Caliskan, Aylin; Bryson, Joanna J.; Narayanan, Arvind (2017-04-14). \"Semantics derived automatically from language corpora contain human-like biases\". Science. 356 (6334): 183\u2013186. arXiv:1608.07187. Bibcode:2017Sci...356..183C. doi:10.1126/science.aal4230. ISSN\u00a00036-8075. PMID\u00a028408601. S2CID\u00a023163324.\n\n^ Wang, Xinan; Dasgupta, Sanjoy (2016), Lee, D. D.; Sugiyama, M.; Luxburg, U. V.; Guyon, I. (eds.), \"An algorithm for L1 nearest neighbor search via monotonic embedding\" (PDF), Advances in Neural Information Processing Systems 29, Curran Associates, Inc., pp.\u00a0983\u2013991, archived (PDF) from the original on 2017-04-07, retrieved 2018-08-20\n\n^ a b c Silva, Selena; Kenney, Martin (2018). \"Algorithms, Platforms, and Ethnic Bias: An Integrative Essay\" (PDF). Phylon. 55 (1 & 2): 9\u201337. ISSN\u00a00031-8906. JSTOR\u00a026545017. Archived (PDF) from the original on Jan 27, 2024.\n\n^ Vincent, James (Jan 12, 2018). \"Google 'fixed' its racist algorithm by removing gorillas from its image-labeling tech\". The Verge. Archived from the original on 2018-08-21. Retrieved 2018-08-20.\n\n^ Crawford, Kate (25 June 2016). \"Opinion | Artificial Intelligence's White Guy Problem\". New York Times. Archived from the original on 2021-01-14. Retrieved 2018-08-20.\n\n^ Metz, Rachel (March 24, 2016). \"Why Microsoft Accidentally Unleashed a Neo-Nazi Sexbot\". MIT Technology Review. Archived from the original on 2018-11-09. Retrieved 2018-08-20.\n\n^ Simonite, Tom (March 30, 2017). \"Microsoft: AI Isn't Yet Adaptable Enough to Help Businesses\". MIT Technology Review. Archived from the original on 2018-11-09. Retrieved 2018-08-20.\n\n^ Hempel, Jessi (2018-11-13). \"Fei-Fei Li's Quest to Make Machines Better for Humanity\". Wired. ISSN\u00a01059-1028. Archived from the original on 2020-12-14. Retrieved 2019-02-17.\n\n^ Rudin, Cynthia (2019). \"Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead\". Nature Machine Intelligence. 1 (5): 206\u2013215. doi:10.1038/s42256-019-0048-x. PMC\u00a09122117. PMID\u00a035603010.\n\n^ Hu, Tongxi; Zhang, Xuesong; Bohrer, Gil; Liu, Yanlan; Zhou, Yuyu; Martin, Jay; LI, Yang; Zhao, Kaiguang (2023). \"Crop yield prediction via explainable AI and interpretable machine learning: Dangers of black box models for evaluating climate change impacts on crop yield\". Agricultural and Forest Meteorology. 336: 109458. doi:10.1016/j.agrformet.2023.109458. S2CID\u00a0258552400.\n\n^ Domingos 2015, Chapter 6, Chapter 7.\n\n^ Domingos 2015, p.\u00a0286.\n\n^ \"Single pixel change fools AI programs\". BBC News. 3 November 2017. Archived from the original on 22 March 2018. Retrieved 12 March 2018.\n\n^ \"AI Has a Hallucination Problem That's Proving Tough to Fix\". WIRED. 2018. Archived from the original on 12 March 2018. Retrieved 12 March 2018.\n\n^ Madry, A.; Makelov, A.; Schmidt, L.; Tsipras, D.; Vladu, A. (4 September 2019). \"Towards deep learning models resistant to adversarial attacks\". arXiv:1706.06083 [stat.ML].\n\n^ \"Adversarial Machine Learning \u2013 CLTC UC Berkeley Center for Long-Term Cybersecurity\". CLTC. Archived from the original on 2022-05-17. Retrieved 2022-05-25.\n\n^ \"Machine-learning models vulnerable to undetectable backdoors\". The Register. Archived from the original on 13 May 2022. Retrieved 13 May 2022.\n\n^ \"Undetectable Backdoors Plantable In Any Machine-Learning Algorithm\". IEEE Spectrum. 10 May 2022. Archived from the original on 11 May 2022. Retrieved 13 May 2022.\n\n^ Goldwasser, Shafi; Kim, Michael P.; Vaikuntanathan, Vinod; Zamir, Or (14 April 2022). \"Planting Undetectable Backdoors in Machine Learning Models\". arXiv:2204.06974 [cs.LG].\n\n^ Kohavi, Ron (1995). \"A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection\" (PDF). International Joint Conference on Artificial Intelligence. Archived (PDF) from the original on 2018-07-12. Retrieved 2023-03-26.\n\n^ Pontius, Robert Gilmore; Si, Kangping (2014). \"The total operating characteristic to measure diagnostic ability for multiple thresholds\". International Journal of Geographical Information Science. 28 (3): 570\u2013583. Bibcode:2014IJGIS..28..570P. doi:10.1080/13658816.2013.862623. S2CID\u00a029204880.\n\n^ Bostrom, Nick (2011). \"The Ethics of Artificial Intelligence\" (PDF). Archived from the original (PDF) on 4 March 2016. Retrieved 11 April 2016.\n\n^ Edionwe, Tolulope. \"The fight against racist algorithms\". The Outline. Archived from the original on 17 November 2017. Retrieved 17 November 2017.\n\n^ Jeffries, Adrianne. \"Machine learning is racist because the internet is racist\". The Outline. Archived from the original on 17 November 2017. Retrieved 17 November 2017.\n\n^ Wong, Carissa (2023-03-30). \"AI 'fairness' research held back by lack of diversity\". Nature. doi:10.1038/d41586-023-00935-z. PMID\u00a036997714. S2CID\u00a0257857012. Archived from the original on 2023-04-12. Retrieved 2023-12-09.\n\n^ a b Zhang, Jack Clark. \"Artificial Intelligence Index Report 2021\" (PDF). Stanford Institute for Human-Centered Artificial Intelligence. Archived (PDF) from the original on 2024-05-19. Retrieved 2023-12-09.\n\n^ Bostrom, Nick; Yudkowsky, Eliezer (2011). \"THE ETHICS OF ARTIFICIAL INTELLIGENCE\" (PDF). Nick Bostrom. Archived (PDF) from the original on 2015-12-20. Retrieved 2020-11-18.\n\n^ M.O.R. Prates; P.H.C. Avelar; L.C. Lamb (11 Mar 2019). \"Assessing Gender Bias in Machine Translation \u2013 A Case Study with Google Translate\". arXiv:1809.02208 [cs.CY].\n\n^ Narayanan, Arvind (August 24, 2016). \"Language necessarily contains human biases, and so will machines trained on language corpora\". Freedom to Tinker. Archived from the original on June 25, 2018. Retrieved November 19, 2016.\n\n^ Char, Danton S.; Shah, Nigam H.; Magnus, David (2018-03-15). \"Implementing Machine Learning in Health Care \u2014 Addressing Ethical Challenges\". New England Journal of Medicine. 378 (11): 981\u2013983. doi:10.1056/NEJMp1714229. ISSN\u00a00028-4793. PMC\u00a05962261. PMID\u00a029539284.\n\n^ Char, D. S.; Shah, N. H.; Magnus, D. (2018). \"Implementing Machine Learning in Health Care\u2014Addressing Ethical Challenges\". New England Journal of Medicine. 378 (11): 981\u2013983. doi:10.1056/nejmp1714229. PMC\u00a05962261. PMID\u00a029539284.\n\n^ Research, AI (23 October 2015). \"Deep Neural Networks for Acoustic Modeling in Speech Recognition\". airesearch.com. Archived from the original on 1 February 2016. Retrieved 23 October 2015.\n\n^ \"GPUs Continue to Dominate the AI Accelerator Market for Now\". InformationWeek. December 2019. Archived from the original on 10 June 2020. Retrieved 11 June 2020.\n\n^ Ray, Tiernan (2019). \"AI is changing the entire nature of compute\". ZDNet. Archived from the original on 25 May 2020. Retrieved 11 June 2020.\n\n^ \"AI and Compute\". OpenAI. 16 May 2018. Archived from the original on 17 June 2020. Retrieved 11 June 2020.\n\n^ \"Cornell & NTT's Physical Neural Networks: A \"Radical Alternative for Implementing Deep Neural Networks\" That Enables Arbitrary Physical Systems Training | Synced\". 27 May 2021. Archived from the original on 27 October 2021. Retrieved 12 October 2021.\n\n^ \"Nano-spaghetti to solve neural network power consumption\". Archived from the original on 2021-10-06. Retrieved 2021-10-12.\n\n^ Fafoutis, Xenofon; Marchegiani, Letizia; Elsts, Atis; Pope, James; Piechocki, Robert; Craddock, Ian (2018-05-07). \"Extending the battery lifetime of wearable sensors with embedded machine learning\". 2018 IEEE 4th World Forum on Internet of Things (WF-IoT). pp.\u00a0269\u2013274. doi:10.1109/WF-IoT.2018.8355116. hdl:1983/b8fdb58b-7114-45c6-82e4-4ab239c1327f. ISBN\u00a0978-1-4673-9944-9. S2CID\u00a019192912. Archived from the original on 2022-01-18. Retrieved 2022-01-17.\n\n^ \"A Beginner's Guide To Machine learning For Embedded Systems\". Analytics India Magazine. 2021-06-02. Archived from the original on 2022-01-18. Retrieved 2022-01-17.\n\n^ Synced (2022-01-12). \"Google, Purdue & Harvard U's Open-Source Framework for TinyML Achieves up to 75x Speedups on FPGAs | Synced\". syncedreview.com. Archived from the original on 2022-01-18. Retrieved 2022-01-17.\n\n^ Giri, Davide; Chiu, Kuan-Lin; Di Guglielmo, Giuseppe; Mantovani, Paolo; Carloni, Luca P. (2020-06-15). \"ESP4ML: Platform-Based Design of Systems-on-Chip for Embedded Machine Learning\". 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE). pp.\u00a01049\u20131054. arXiv:2004.03640. doi:10.23919/DATE48585.2020.9116317. ISBN\u00a0978-3-9819263-4-7. S2CID\u00a0210928161. Archived from the original on 2022-01-18. Retrieved 2022-01-17.\n\n^ Louis, Marcia Sahaya; Azad, Zahra; Delshadtehrani, Leila; Gupta, Suyog; Warden, Pete; Reddi, Vijay Janapa; Joshi, Ajay (2019). \"Towards Deep Learning using TensorFlow Lite on RISC-V\". Harvard University. Archived from the original on 2022-01-17. Retrieved 2022-01-17.\n\n^ Ibrahim, Ali; Osta, Mario; Alameh, Mohamad; Saleh, Moustafa; Chible, Hussein; Valle, Maurizio (2019-01-21). \"Approximate Computing Methods for Embedded Machine Learning\". 2018 25th IEEE International Conference on Electronics, Circuits and Systems (ICECS). pp.\u00a0845\u2013848. doi:10.1109/ICECS.2018.8617877. ISBN\u00a0978-1-5386-9562-3. S2CID\u00a058670712. Archived from the original on 2022-01-17. Retrieved 2022-01-17.\n\n^ \"dblp: TensorFlow Eager: A Multi-Stage, Python-Embedded DSL for Machine Learning\". dblp.org. Archived from the original on 2022-01-18. Retrieved 2022-01-17.\n\n^ Branco, S\u00e9rgio; Ferreira, Andr\u00e9 G.; Cabral, Jorge (2019-11-05). \"Machine Learning in Resource-Scarce Embedded Systems, FPGAs, and End-Devices: A Survey\". Electronics. 8 (11): 1289. doi:10.3390/electronics8111289. hdl:1822/62521. ISSN\u00a02079-9292.\n\n\nSources[edit]\nDomingos, Pedro (September 22, 2015). The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World. Basic Books. ISBN\u00a0978-0465065707.\nNilsson, Nils (1998). Artificial Intelligence: A New Synthesis. Morgan Kaufmann. ISBN\u00a0978-1-55860-467-4. Archived from the original on 26 July 2020. Retrieved 18 November 2019.\nPoole, David; Mackworth, Alan; Goebel, Randy (1998). Computational Intelligence: A Logical Approach. New York: Oxford University Press. ISBN\u00a0978-0-19-510270-3. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\nRussell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd\u00a0ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN\u00a00-13-790395-2.\nFurther reading[edit]\n\nNils J. Nilsson, Introduction to Machine Learning Archived 2019-08-16 at the Wayback Machine.\nTrevor Hastie, Robert Tibshirani and Jerome H. Friedman (2001). The Elements of Statistical Learning Archived 2013-10-27 at the Wayback Machine, Springer. ISBN\u00a00-387-95284-5.\nPedro Domingos (September 2015), The Master Algorithm, Basic Books, ISBN\u00a0978-0-465-06570-7\nIan H. Witten and Eibe Frank (2011). Data Mining: Practical machine learning tools and techniques Morgan Kaufmann, 664pp., ISBN\u00a0978-0-12-374856-0.\nEthem Alpaydin (2004). Introduction to Machine Learning, MIT Press, ISBN\u00a0978-0-262-01243-0.\nDavid J. C. MacKay. Information Theory, Inference, and Learning Algorithms Archived 2016-02-17 at the Wayback Machine Cambridge: Cambridge University Press, 2003. ISBN\u00a00-521-64298-1\nRichard O. Duda, Peter E. Hart, David G. Stork (2001) Pattern classification (2nd edition), Wiley, New York, ISBN\u00a00-471-05669-3.\nChristopher Bishop (1995). Neural Networks for Pattern Recognition, Oxford University Press. ISBN\u00a00-19-853864-2.\nStuart Russell & Peter Norvig, (2009). Artificial Intelligence \u2013 A Modern Approach Archived 2011-02-28 at the Wayback Machine. Pearson, ISBN\u00a09789332543515.\nRay Solomonoff, An Inductive Inference Machine, IRE Convention Record, Section on Information Theory, Part 2, pp., 56\u201362, 1957.\nRay Solomonoff, An Inductive Inference Machine Archived 2011-04-26 at the Wayback Machine A privately circulated report from the 1956 Dartmouth Summer Research Conference on AI.\nKevin P. Murphy (2021). Probabilistic Machine Learning: An Introduction Archived 2021-04-11 at the Wayback Machine, MIT Press.\n\nExternal links[edit]\n\n\n\nWikimedia Commons has media related to Machine learning.\n\n\n\n\nWikiquote has quotations related to Machine learning.\n\nInternational Machine Learning Society\nmloss is an academic database of open-source machine learning software.\nvteArtificial intelligenceConcepts\nParameter\nHyperparameter\nLoss functions\nRegression\nBias\u2013variance tradeoff\nDouble descent\nOverfitting\nClustering\nGradient descent\nSGD\nQuasi-Newton method\nConjugate gradient method\nBackpropagation\nAttention\nConvolution\nNormalization\nBatchnorm\nActivation\nSoftmax\nSigmoid\nRectifier\nGating\nWeight initialization\nRegularization\nDatasets\nAugmentation\nReinforcement learning\nQ-learning\nSARSA\nImitation\nDiffusion\nAutoregression\nAdversary\nHallucination\nApplications\nMachine learning\nIn-context learning\nArtificial neural network\nDeep learning\nLanguage model\nLarge language model\nNMT\nArtificial general intelligence\nImplementationsAudio\u2013visual\nAlexNet\nWaveNet\nHuman image synthesis\nHWR\nOCR\nSpeech synthesis\nElevenLabs\nSpeech recognition\nFacial recognition\nAlphaFold\nText-to-image models\nLatent diffusion model\nDALL-E\nFLUX.1\nIdeogram\nMidjourney\nStable Diffusion\nText-to-video models\nSora\nDream Machine\nVideoPoet\nWhisper\nText\nWord2vec\nSeq2seq\nGloVe\nBERT\nT5\nLlama\nChinchilla AI\nPaLM\nGPT\n1\nJ\n2\n3\nChatGPT\n4\n4o\no1\nClaude\nGemini\nGrok\nLaMDA\nBLOOM\nProject Debater\nIBM Watson\nIBM Watsonx\nGranite\nPanGu-\u03a3\nDecisional\nAlphaGo\nAlphaZero\nOpenAI Five\nSelf-driving car\nMuZero\nAction selection\nAutoGPT\nRobot control\nPeople\nAlan Turing\nClaude Shannon\nAllen Newell\nHerbert A. Simon\nFrank Rosenblatt\nMarvin Minsky\nJohn McCarthy\nNathaniel Rochester\nSeymour Papert\nJoseph Weizenbaum\nBernard Widrow\nPaul Werbos\nYoshua Bengio\nAlex Graves\nIan Goodfellow\nStephen Grossberg\nDemis Hassabis\nGeoffrey Hinton\nYann LeCun\nFei-Fei Li\nAndrew Ng\nJ\u00fcrgen Schmidhuber\nDavid Silver\nIlya Sutskever\nOrganizations\nAnthropic\nEleutherAI\nGoogle DeepMind\nHugging Face\nKuaishou\nMeta AI\nMila\nMiniMax\nMistral AI\nMIT CSAIL\nOpenAI\nRunway\nxAI\nArchitectures\nNeural Turing machine\nDifferentiable neural computer\nTransformer\nVision transformer (ViT)\nRecurrent neural network (RNN)\nLong short-term memory (LSTM)\nGated recurrent unit (GRU)\nEcho state network\nMultilayer perceptron (MLP)\nConvolutional neural network (CNN)\nResidual neural network (RNN)\nHighway network\nMamba\nAutoencoder\nVariational autoencoder (VAE)\nGenerative adversarial network (GAN)\nGraph neural network (GNN)\n\n Portals\nTechnology\n Categories\nArtificial neural networks\nMachine learning\n\nvteComputer scienceNote: This template roughly follows the 2012 ACM Computing Classification System.Hardware\nPrinted circuit board\nPeripheral\nIntegrated circuit\nVery Large Scale Integration\nSystems on Chip (SoCs)\nEnergy consumption (Green computing)\nElectronic design automation\nHardware acceleration\nProcessor\nSize / Form\nComputer systems organization\nComputer architecture\nComputational complexity\nDependability\nEmbedded system\nReal-time computing\nNetworks\nNetwork architecture\nNetwork protocol\nNetwork components\nNetwork scheduler\nNetwork performance evaluation\nNetwork service\nSoftware organization\nInterpreter\nMiddleware\nVirtual machine\nOperating system\nSoftware quality\nSoftware notations and tools\nProgramming paradigm\nProgramming language\nCompiler\nDomain-specific language\nModeling language\nSoftware framework\nIntegrated development environment\nSoftware configuration management\nSoftware library\nSoftware repository\nSoftware development\nControl variable\nSoftware development process\nRequirements analysis\nSoftware design\nSoftware construction\nSoftware deployment\nSoftware engineering\nSoftware maintenance\nProgramming team\nOpen-source model\nTheory of computation\nModel of computation\nStochastic\nFormal language\nAutomata theory\nComputability theory\nComputational complexity theory\nLogic\nSemantics\nAlgorithms\nAlgorithm design\nAnalysis of algorithms\nAlgorithmic efficiency\nRandomized algorithm\nComputational geometry\nMathematics of computing\nDiscrete mathematics\nProbability\nStatistics\nMathematical software\nInformation theory\nMathematical analysis\nNumerical analysis\nTheoretical computer science\nInformation systems\nDatabase management system\nInformation storage systems\nEnterprise information system\nSocial information systems\nGeographic information system\nDecision support system\nProcess control system\nMultimedia information system\nData mining\nDigital library\nComputing platform\nDigital marketing\nWorld Wide Web\nInformation retrieval\nSecurity\nCryptography\nFormal methods\nSecurity hacker\nSecurity services\nIntrusion detection system\nHardware security\nNetwork security\nInformation security\nApplication security\nHuman\u2013computer interaction\nInteraction design\nSocial computing\nUbiquitous computing\nVisualization\nAccessibility\nConcurrency\nConcurrent computing\nParallel computing\nDistributed computing\nMultithreading\nMultiprocessing\nArtificial intelligence\nNatural language processing\nKnowledge representation and reasoning\nComputer vision\nAutomated planning and scheduling\nSearch methodology\nControl method\nPhilosophy of artificial intelligence\nDistributed artificial intelligence\nMachine learning\nSupervised learning\nUnsupervised learning\nReinforcement learning\nMulti-task learning\nCross-validation\nGraphics\nAnimation\nRendering\nPhotograph manipulation\nGraphics processing unit\nMixed reality\nVirtual reality\nImage compression\nSolid modeling\nApplied computing\nQuantum Computing\nE-commerce\nEnterprise software\nComputational mathematics\nComputational physics\nComputational chemistry\nComputational biology\nComputational social science\nComputational engineering\nDifferentiable computing\nComputational healthcare\nDigital art\nElectronic publishing\nCyberwarfare\nElectronic voting\nVideo games\nWord processing\nOperations research\nEducational technology\nDocument management\n\n Category\n Outline\n Glossaries\n\nAuthority control databases: National GermanyUnited StatesJapanCzech RepublicIsrael\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Machine_learning&oldid=1257985178\""}, {"url": "https://en.wikipedia.org/wiki/Artificial_intelligenceehttps://en.wikipedia.org/wiki/Hyperparameter_optimization", "content": "\n\nLook for Artificial intelligenceehttps://en.wikipedia.org/wiki/Hyperparameter optimization on one of Wikipedia's sister projects:\n\n\n\n\nWiktionary (dictionary)\n\n\n\nWikibooks (textbooks)\n\n\n\nWikiquote (quotations)\n\n\n\nWikisource (library)\n\n\n\nWikiversity (learning resources)\n\n\n\nCommons (media)\n\n\n\nWikivoyage (travel guide)\n\n\n\nWikinews (news source)\n\n\n\nWikidata (linked database)\n\n\n\nWikispecies (species directory)\n\n\n\nWikipedia does not have an article with this exact name. Please search for Artificial intelligenceehttps://en.wikipedia.org/wiki/Hyperparameter optimization in Wikipedia to check for alternative titles or spellings.\nThis page is template-protected from creation, so only template editors can create it.\nSearch for \"Artificial intelligenceehttps://en.wikipedia.org/wiki/Hyperparameter optimization\" in existing articles.\nLook for pages within Wikipedia that link to this title.\n\n\nOther reasons this message may be displayed:\n\nIf a page was recently created here, it may not be visible yet because of a delay in updating the database; wait a few minutes or try the purge function.\nTitles on Wikipedia are case sensitive except for the first character; please check alternative capitalizations and consider adding a redirect here to the correct title.\nIf the page has been deleted, check the deletion log, and see Why was the page I created deleted?\n\n\n\nRetrieved from \"https://en.wikipedia.org/wiki/Artificial_intelligenceehttps://en.wikipedia.org/wiki/Hyperparameter_optimization\""}, {"url": "https://en.wikipedia.org/wiki/Meta-learning_(computer_science)", "content": "Subfield of machine learning\nThis article is about meta-learning in machine learning. For meta-learning in social psychology, see Meta-learning. For metalearning in neuroscience, see Metalearning (neuroscience).\nSee also: Ensemble learning\n\nPart of a series onMachine learningand data mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\n\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\n\nSupervised learning(classification\u00a0\u2022 regression) \nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\n\nClustering\nBIRCH\nCURE\nHierarchical\nk-means\nFuzzy\nExpectation\u2013maximization (EM)\nDBSCAN\nOPTICS\nMean shift\n\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\n\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\n\nAnomaly detection\nRANSAC\nk-NN\nLocal outlier factor\nIsolation forest\n\nArtificial neural network\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural radiance field\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM (ECRAM)\n\nReinforcement learning\nQ-learning\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\n\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nRLHF\n\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\n\nMathematical foundations\nKernel machines\nBias\u2013variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\n\nJournals and conferences\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\n\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nvte\nMeta-learning[1][2]\nis a subfield of machine learning where automatic learning algorithms are applied to metadata about machine learning experiments. As of 2017, the term had not found a standard interpretation, however the main goal is to use such metadata to understand how automatic learning can become flexible in solving learning problems, hence to improve the performance of existing learning algorithms or to learn (induce) the learning algorithm itself, hence the alternative term learning to learn.[1]\nFlexibility is important because each learning algorithm is based on a set of assumptions about the data, its inductive bias.[3] This means that it will only learn well if the bias matches the learning problem. A learning algorithm may perform very well in one domain, but not on the next. This poses strong restrictions on the use of machine learning or data mining techniques, since the relationship between the learning problem (often some kind of database) and the effectiveness of different learning algorithms is not yet understood.\nBy using different kinds of metadata, like properties of the learning problem, algorithm properties (like performance measures), or patterns previously derived from the data, it is possible to learn, select, alter or combine different learning algorithms to effectively solve a given learning problem. Critiques of meta-learning approaches bear a strong resemblance to the critique of metaheuristic, a possibly related problem. A good analogy to meta-learning, and the inspiration for J\u00fcrgen Schmidhuber's early work (1987)[1] and Yoshua Bengio et al.'s work (1991),[4] considers that genetic evolution learns the learning procedure encoded in genes and executed in each individual's brain. In an open-ended hierarchical meta-learning system[1] using genetic programming, better evolutionary methods can be learned by meta evolution, which itself can be improved by meta meta evolution, etc.[1]\n\n\nDefinition[edit]\nA proposed definition[5] for a meta-learning system combines three requirements:\n\nThe system must include a learning subsystem.\nExperience is gained by exploiting meta knowledge extracted\nin a previous learning episode on a single dataset, or\nfrom different domains.\nLearning bias must be chosen dynamically.\nBias refers to the assumptions that influence the choice of explanatory hypotheses[6] and not the notion of bias represented in the bias-variance dilemma. Meta-learning is concerned with two aspects of learning bias.\n\nDeclarative bias specifies the representation of the space of hypotheses, and affects the size of the search space (e.g., represent hypotheses using linear functions only).\nProcedural bias imposes constraints on the ordering of the inductive hypotheses (e.g., preferring smaller hypotheses).[7]\nCommon approaches[edit]\nThere are three common approaches:[8]\n\nusing (cyclic) networks with external or internal memory (model-based)\nlearning effective distance metrics (metrics-based)\nexplicitly optimizing model parameters for fast learning (optimization-based).\nModel-Based[edit]\nModel-based meta-learning models updates its parameters rapidly with a few training steps, which can be achieved by its internal architecture or controlled by another meta-learner model.[8]\n\nMemory-Augmented Neural Networks[edit]\nA Memory-Augmented Neural Network, or MANN for short, is claimed to be able to encode new information quickly and thus to adapt to new tasks after only a few examples.[9]\n\nMeta Networks[edit]\nMeta Networks (MetaNet) learns a meta-level knowledge across tasks and shifts its inductive biases via fast parameterization for rapid generalization.[10]\n\nMetric-Based[edit]\nThe core idea in metric-based meta-learning is similar to nearest neighbors algorithms, which weight is generated by a kernel function. It aims to learn a metric or distance function over objects. The notion of a good metric is problem-dependent. It should represent the relationship between inputs in the task space and facilitate problem solving.[8]\n\nConvolutional Siamese Neural Network[edit]\nSiamese neural network is composed of two twin networks whose output is jointly trained. There is a function above to learn the relationship between input data sample pairs. The two networks are the same, sharing the same weight and network parameters.[11]\n\nMatching Networks[edit]\nMatching Networks learn a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types.[12]\n\nRelation Network[edit]\nThe Relation Network (RN), is trained end-to-end from scratch. During meta-learning, it learns to learn a deep distance metric to compare a small number of images within episodes, each of which is designed to simulate the few-shot setting.[13]\n\nPrototypical Networks[edit]\nPrototypical Networks learn a metric space in which classification can be performed by computing distances to prototype representations of each class. Compared to recent approaches for few-shot learning, they reflect a simpler inductive bias that is beneficial in this limited-data regime, and achieve satisfied results.[14]\n\nOptimization-Based[edit]\nWhat optimization-based meta-learning algorithms intend for is to adjust the optimization algorithm so that the model can be good at learning with a few examples.[8]\n\nLSTM Meta-Learner[edit]\nLSTM-based meta-learner is to learn the exact optimization algorithm used to train another learner neural network classifier in the few-shot regime. The parametrization allows it to learn appropriate parameter updates specifically for the scenario where a set amount of updates will be made, while also learning a general initialization of the learner (classifier) network that allows for quick convergence of training.[15]\n\nTemporal Discreteness[edit]\nModel-Agnostic Meta-Learning (MAML) is a fairly general optimization algorithm, compatible with any model that learns through gradient descent.[16]\n\nReptile[edit]\nReptile is a remarkably simple meta-learning optimization algorithm, given that both of its components rely on meta-optimization through gradient descent and both are model-agnostic.[17]\n\nExamples[edit]\nSome approaches which have been viewed as instances of meta-learning:\n\nRecurrent neural networks (RNNs) are universal computers. In 1993, J\u00fcrgen Schmidhuber showed how \"self-referential\" RNNs can in principle learn by backpropagation to run their own weight change algorithm, which may be quite different from backpropagation.[18] In 2001, Sepp Hochreiter & A.S. Younger & P.R. Conwell built a successful supervised meta-learner based on Long short-term memory RNNs. It learned through backpropagation a learning algorithm for quadratic functions that is much faster than backpropagation.[19][2] Researchers at Deepmind (Marcin Andrychowicz et al.) extended this approach to optimization in 2017.[20]\nIn the 1990s, Meta Reinforcement Learning or Meta RL was achieved in Schmidhuber's research group through self-modifying policies written in a universal programming language that contains special instructions for changing the policy itself. There is a single lifelong trial. The goal of the RL agent is to maximize reward. It learns to accelerate reward intake by continually improving its own learning algorithm which is part of the \"self-referential\" policy.[21][22]\nAn extreme type of Meta Reinforcement Learning is embodied by the G\u00f6del machine, a theoretical construct which can inspect and modify any part of its own software which also contains a general theorem prover. It can achieve recursive self-improvement in a provably optimal way.[23][2]\nModel-Agnostic Meta-Learning (MAML) was introduced in 2017 by Chelsea Finn et al.[16] Given a sequence of tasks, the parameters of a given model are trained such that few iterations of gradient descent with few training data from a new task will lead to good generalization performance on that task. MAML \"trains the model to be easy to fine-tune.\"[16] MAML was successfully applied to few-shot image classification benchmarks and to policy-gradient-based reinforcement learning.[16]\nVariational Bayes-Adaptive Deep RL (VariBAD) was introduced in 2019.[24] While MAML is optimization-based, VariBAD is a model-based method for meta reinforcement learning, and leverages a variational autoencoder to capture the task information in an internal memory, thus conditioning its decision making on the task.\nWhen addressing a set of tasks, most meta learning approaches optimize the average score across all tasks. Hence, certain tasks may be sacrificed in favor of the average score, which is often unacceptable in real-world applications. By contrast, Robust Meta Reinforcement Learning (RoML) focuses on improving low-score tasks, increasing robustness to the selection of task.[25] RoML works as a meta-algorithm, as it can be applied on top of other meta learning algorithms (such as MAML and VariBAD) to increase their robustness. It is applicable to both supervised meta learning and meta reinforcement learning.\nDiscovering meta-knowledge works by inducing knowledge (e.g. rules) that expresses how each learning method will perform on different learning problems. The metadata is formed by characteristics of the data (general, statistical, information-theoretic,... ) in the learning problem, and characteristics of the learning algorithm (type, parameter settings, performance measures,...). Another learning algorithm then learns how the data characteristics relate to the algorithm characteristics. Given a new learning problem, the data characteristics are measured, and the performance of different learning algorithms are predicted. Hence, one can predict the algorithms best suited for the new problem.\nStacked generalisation works by combining multiple (different) learning algorithms. The metadata is formed by the predictions of those different algorithms. Another learning algorithm learns from this metadata to predict which combinations of algorithms give generally good results. Given a new learning problem, the predictions of the selected set of algorithms are combined (e.g. by (weighted) voting) to provide the final prediction. Since each algorithm is deemed to work on a subset of problems, a combination is hoped to be more flexible and able to make good predictions.\nBoosting is related to stacked generalisation, but uses the same algorithm multiple times, where the examples in the training data get different weights over each run. This yields different predictions, each focused on rightly predicting a subset of the data, and combining those predictions leads to better (but more expensive) results.\nDynamic bias selection works by altering the inductive bias of a learning algorithm to match the given problem. This is done by altering key aspects of the learning algorithm, such as the hypothesis representation, heuristic formulae, or parameters. Many different approaches exist.\nInductive transfer studies how the learning process can be improved over time. Metadata consists of knowledge about previous learning episodes and is used to efficiently develop an effective hypothesis for a new task. A related approach is called learning to learn, in which the goal is to use acquired knowledge from one domain to help learning in other domains.\nOther approaches using metadata to improve automatic learning are learning classifier systems, case-based reasoning and constraint satisfaction.\nSome initial, theoretical work has been initiated to use Applied Behavioral Analysis as a foundation for agent-mediated meta-learning about the performances of human learners, and adjust the instructional course of an artificial agent.[26]\nAutoML such as Google Brain's \"AI building AI\" project, which according to Google briefly exceeded existing ImageNet benchmarks in 2017.[27][28]\nReferences\n\n\n^ a b c d e Schmidhuber, J\u00fcrgen (1987). \"Evolutionary principles in self-referential learning, or on learning how to learn: the meta-meta-... hook\" (PDF). Diploma Thesis, Tech. Univ. Munich.\n\n^ a b c Schaul, Tom; Schmidhuber, J\u00fcrgen (2010). \"Metalearning\". Scholarpedia. 5 (6): 4650. Bibcode:2010SchpJ...5.4650S. doi:10.4249/scholarpedia.4650.\n\n^ P. E. Utgoff (1986). \"Shift of bias for inductive concept learning\". In R. Michalski; J. Carbonell; T. Mitchell (eds.). Machine Learning: An Artificial Intelligence Approach. Morgan Kaufmann. pp.\u00a0163\u2013190. ISBN\u00a0978-0-934613-00-2.\n\n^ Bengio, Yoshua; Bengio, Samy; Cloutier, Jocelyn (1991). Learning to learn a synaptic rule (PDF). IJCNN'91.\n\n^ Lemke, Christiane; Budka, Marcin; Gabrys, Bogdan (2013-07-20). \"Metalearning: a survey of trends and technologies\". Artificial Intelligence Review. 44 (1): 117\u2013130. doi:10.1007/s10462-013-9406-y. ISSN\u00a00269-2821. PMC\u00a04459543. PMID\u00a026069389.\n\n^ Brazdil, Pavel; Carrier, Christophe Giraud; Soares, Carlos; Vilalta, Ricardo (2009). Metalearning - Springer. Cognitive Technologies. doi:10.1007/978-3-540-73263-1. ISBN\u00a0978-3-540-73262-4.\n\n^ Gordon, Diana; Desjardins, Marie (1995). \"Evaluation and Selection of Biases in Machine Learning\" (PDF). Machine Learning. 20: 5\u201322. doi:10.1023/A:1022630017346. Retrieved 27 March 2020.\n\n^ a b c d Weng, Lilian (30 November 2018). \"Meta-Learning: Learning to Learn Fast\". OpenAI Blog. Retrieved 27 October 2019.\n\n^ Santoro, Adam; Bartunov, Sergey; Wierstra, Daan; Lillicrap, Timothy. \"Meta-Learning with Memory-Augmented Neural Networks\" (PDF). Google DeepMind. Retrieved 29 October 2019.\n\n^ Munkhdalai, Tsendsuren; Yu, Hong (2017). \"Meta Networks\". arXiv:1703.00837 [cs.LG].\n\n^ Koch, Gregory; Zemel, Richard; Salakhutdinov, Ruslan (2015). \"Siamese Neural Networks for One-shot Image Recognition\" (PDF). Toronto, Ontario, Canada: Department of Computer Science, University of Toronto.\n\n^ Vinyals, O.; Blundell, C.; Lillicrap, T.; Kavukcuoglu, K.; Wierstra, D. (2016). \"Matching networks for one shot learning\" (PDF). Google DeepMind. Retrieved 3 November 2019.\n\n^ Sung, F.; Yang, Y.; Zhang, L.; Xiang, T.; Torr, P. H. S.; Hospedales, T. M. (2018). \"Learning to compare: relation network for few-shot learning\" (PDF).\n\n^ Snell, J.; Swersky, K.; Zemel, R. S. (2017). \"Prototypical networks for few-shot learning\" (PDF).\n\n^ Ravi, Sachin; Larochelle, Hugo (2017). Optimization as a model for few-shot learning. ICLR 2017. Retrieved 3 November 2019.\n\n^ a b c d Finn, Chelsea; Abbeel, Pieter; Levine, Sergey (2017). \"Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks\". arXiv:1703.03400 [cs.LG].\n\n^ Nichol, Alex; Achiam, Joshua; Schulman, John (2018). \"On First-Order Meta-Learning Algorithms\". arXiv:1803.02999 [cs.LG].\n\n^ Schmidhuber, J\u00fcrgen (1993). \"A self-referential weight matrix\". Proceedings of ICANN'93, Amsterdam: 446\u2013451.\n\n^ Hochreiter, Sepp; Younger, A. S.; Conwell, P. R. (2001). \"Learning to Learn Using Gradient Descent\". Proceedings of ICANN'01: 87\u201394.\n\n^ Andrychowicz, Marcin; Denil, Misha; Gomez, Sergio; Hoffmann, Matthew; Pfau, David; Schaul, Tom; Shillingford, Brendan; de Freitas, Nando (2017). \"Learning to learn by gradient descent by gradient descent\". Proceedings of ICML'17, Sydney, Australia. arXiv:1606.04474.\n\n^ Schmidhuber, J\u00fcrgen (1994). \"On learning how to learn learning strategies\" (PDF). Technical Report FKI-198-94, Tech. Univ. Munich.\n\n^ Schmidhuber, J\u00fcrgen; Zhao, J.; Wiering, M. (1997). \"Shifting inductive bias with success-story algorithm, adaptive Levin search, and incremental self-improvement\". Machine Learning. 28: 105\u2013130. doi:10.1023/a:1007383707642.\n\n^ Schmidhuber, J\u00fcrgen (2006). \"G\u00f6del machines: Fully Self-Referential Optimal Universal Self-Improvers\". In B. Goertzel & C. Pennachin, Eds.: Artificial General Intelligence: 199\u2013226.\n\n^ Zintgraf, Luisa; Schulze, Sebastian; Lu, Cong; Feng, Leo; Igl, Maximilian; Shiarlis, Kyriacos; Gal, Yarin; Hofmann, Katja; Whiteson, Shimon (2021). \"VariBAD: Variational Bayes-Adaptive Deep RL via Meta-Learning\". Journal of Machine Learning Research. 22 (289): 1\u201339. ISSN\u00a01533-7928.\n\n^ Greenberg, Ido; Mannor, Shie; Chechik, Gal; Meirom, Eli (2023-12-15). \"Train Hard, Fight Easy: Robust Meta Reinforcement Learning\". Advances in Neural Information Processing Systems. 36: 68276\u201368299.\n\n^ Begoli, Edmon (May 2014). \"Procedural-Reasoning Architecture for Applied Behavior Analysis-based Instructions\". Doctoral Dissertations. Knoxville, Tennessee, USA: University of Tennessee, Knoxville: 44\u201379. Retrieved 14 October 2017.\n\n^ \"Robots Are Now 'Creating New Robots,' Tech Reporter Says\". NPR.org. 2018. Retrieved 29 March 2018.\n\n^ \"AutoML for large scale image classification and object detection\". Google Research Blog. November 2017. Retrieved 29 March 2018.\n\n\nExternal links[edit]\nMetalearning article in Scholarpedia\nVilalta, R.; Drissi, Y. (2002). \"A perspective view and survey of meta-learning\" (PDF). Artificial Intelligence Review. 18 (2): 77\u201395. doi:10.1023/A:1019956318069.\nGiraud-Carrier, C.; Keller, J. (2002). \"Meta-Learning\". In Meij, J. (ed.). Dealing with the data flood. The Hague: STT/Beweton.\nBrazdil, P.; Giraud-Carrier, C.; Soares, C.; Vilalta, R. (2009). \"Metalearning: Concepts and Systems\". Metalearning: applications to data mining. Springer. ISBN\u00a0978-3-540-73262-4.\nVideo courses about Meta-Learning with step-by-step explanation of MAML, Prototypical Networks, and Relation Networks.\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Meta-learning_(computer_science)&oldid=1230244062\""}, {"url": "https://en.wikipedia.org/wiki/Neural_architecture_search", "content": "Machine learning-powered structure design\n\nPart of a series onMachine learningand data mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\n\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\n\nSupervised learning(classification\u00a0\u2022 regression) \nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\n\nClustering\nBIRCH\nCURE\nHierarchical\nk-means\nFuzzy\nExpectation\u2013maximization (EM)\nDBSCAN\nOPTICS\nMean shift\n\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\n\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\n\nAnomaly detection\nRANSAC\nk-NN\nLocal outlier factor\nIsolation forest\n\nArtificial neural network\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural radiance field\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM (ECRAM)\n\nReinforcement learning\nQ-learning\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\n\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nRLHF\n\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\n\nMathematical foundations\nKernel machines\nBias\u2013variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\n\nJournals and conferences\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\n\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nvte\nNeural architecture search (NAS)[1][2] is a technique for automating the design of artificial neural networks (ANN), a widely used model in the field of machine learning. NAS has been used to design networks that are on par with or outperform hand-designed architectures.[3][4] Methods for NAS can be categorized according to the search space, search strategy and performance estimation strategy used:[1]\n\nThe search space defines the type(s) of ANN that can be designed and optimized.\nThe search strategy defines the approach used to explore the search space.\nThe performance estimation strategy evaluates the performance of a possible ANN from its design (without constructing and training it).\nNAS is closely related to hyperparameter optimization[5] and meta-learning[6] and is a subfield of automated machine learning (AutoML).[7]\n\n\nReinforcement learning[edit]\nReinforcement learning (RL) can underpin a NAS search strategy. Barret Zoph and Quoc Viet Le[3] applied NAS with RL targeting the CIFAR-10 dataset and achieved a network architecture that rivals the best manually-designed architecture for accuracy, with an error rate of 3.65, 0.09 percent better and 1.05x faster than a related hand-designed model. On the Penn Treebank dataset, that model composed a recurrent cell that outperforms LSTM, reaching a test set perplexity of 62.4, or 3.6 perplexity better than the prior leading system. On the PTB character language modeling task it achieved bits per character of 1.214.[3]\nLearning a model architecture directly on a large dataset can be a lengthy process. NASNet[4][8] addressed this issue by transferring a building block designed for a small dataset to a larger dataset. The design was constrained to use two types of convolutional cells to return feature maps that serve two main functions when convoluting an input feature map: normal cells that return maps of the same extent (height and width) and reduction cells in which the returned feature map height and width is reduced by a factor of two. For the reduction cell, the initial operation applied to the cell's inputs uses a stride of two (to reduce the height and width).[4] The learned aspect of the design included elements such as which lower layer(s) each higher layer took as input, the transformations applied at that layer and to merge multiple outputs at each layer. In the studied example, the best convolutional layer (or \"cell\") was designed for the CIFAR-10 dataset and then applied to the ImageNet dataset by stacking copies of this cell, each with its own parameters. The approach yielded accuracy of 82.7% top-1 and 96.2% top-5. This exceeded the best human-invented architectures at a cost of 9 billion fewer FLOPS\u2014a reduction of 28%. The system continued to exceed the manually-designed alternative at varying computation levels. The image features learned from image classification can be transferred to other computer vision problems. E.g., for object detection, the learned cells integrated with the Faster-RCNN framework improved performance by 4.0% on the COCO dataset.[4]\nIn the so-called Efficient Neural Architecture Search (ENAS), a controller discovers architectures by learning to search for an optimal subgraph within a large graph. The controller is trained with policy gradient to select a subgraph that maximizes the validation set's expected reward. The model corresponding to the subgraph is trained to minimize a canonical cross entropy loss. Multiple child models share parameters, ENAS requires fewer GPU-hours than other approaches and 1000-fold less than \"standard\" NAS. On CIFAR-10, the ENAS design achieved a test error of 2.89%, comparable to NASNet. On Penn Treebank, the ENAS design reached test perplexity of 55.8.[9]\n\nEvolution[edit]\nAn alternative approach to NAS is based on evolutionary algorithms, which has been employed by several groups.[10][11][12][13][14][15][16] An Evolutionary Algorithm for Neural Architecture Search generally performs the following procedure.[17] First a pool consisting of different candidate architectures along with their validation scores (fitness) is initialised. At each step the architectures in the candidate pool are mutated (e.g.: 3x3 convolution instead of a 5x5 convolution). Next the new architectures are trained from scratch for a few epochs and their validation scores are obtained. This is followed by replacing the lowest scoring architectures in the candidate pool with the better, newer architectures. This procedure is repeated multiple times and thus the candidate pool is refined over time. Mutations in the context of evolving ANNs are operations such as adding or removing a layer, which include changing the type of a layer (e.g., from convolution to pooling), changing the hyperparameters of a layer, or changing the training hyperparameters. On CIFAR-10 and ImageNet, evolution and RL performed comparably, while both slightly outperformed random search.[13][12]\n\nBayesian optimization[edit]\nBayesian Optimization (BO), which has proven to be an efficient method for hyperparameter optimization, can also be applied to NAS. In this context, the objective function maps an architecture to its validation error after being trained for a number of epochs. At each iteration, BO uses a surrogate to model this objective function based on previously obtained architectures and their validation errors. One then chooses the next architecture to evaluate by maximizing an acquisition function, such as expected improvement, which provides a balance between exploration and exploitation. Acquisition function maximization and objective function evaluation are often computationally expensive for NAS, and make the application of BO challenging in this context. Recently, BANANAS[18] has achieved promising results in this direction by introducing a high-performing instantiation of BO coupled to a neural predictor.\n\nHill-climbing[edit]\nAnother group used a hill climbing procedure that applies network morphisms, followed by short cosine-annealing optimization runs. The approach yielded competitive results, requiring resources on the same order of magnitude as training a single network. E.g., on CIFAR-10, the method designed and trained a network with an error rate below 5% in 12 hours on a single GPU.[19]\n\nMulti-objective search[edit]\nWhile most approaches solely focus on finding architecture with maximal predictive performance, for most practical applications other objectives are relevant, such as memory consumption, model size or inference time (i.e., the time required to obtain a prediction). Because of that, researchers created a multi-objective search.[16][20]\nLEMONADE[16] is an evolutionary algorithm that adopted Lamarckism to efficiently optimize multiple objectives. In every generation, child networks are generated to improve the Pareto frontier with respect to the current population of ANNs.\nNeural Architect[20] is claimed to be a resource-aware multi-objective RL-based NAS with network embedding and performance prediction. Network embedding encodes an existing network to a trainable embedding vector. Based on the embedding, a controller network generates transformations of the target network. A multi-objective reward function considers network accuracy, computational resource and training time. The reward is predicted by multiple performance simulation networks that are pre-trained or co-trained with the controller network. The controller network is trained via policy gradient. Following a modification, the resulting candidate network is evaluated by both an accuracy network and a training time network. The results are combined by a reward engine that passes its output back to the controller network.\n\nOne-shot models[edit]\nRL or evolution-based NAS require thousands of GPU-days of searching/training to achieve state-of-the-art computer vision results as described in the NASNet, mNASNet and MobileNetV3 papers.[4][21][22]\nTo reduce computational cost, many recent NAS methods rely on the weight-sharing idea.[23][24] In this approach, a single overparameterized supernetwork (also known as the one-shot model) is defined. A supernetwork is a very large Directed Acyclic Graph (DAG) whose subgraphs are different candidate neural networks. Thus, in a supernetwork, the weights are shared among a large number of different sub-architectures that have edges in common, each of which is considered as a path within the supernet. The essential idea is to train one supernetwork that spans many options for the final design rather than generating and training thousands of networks independently. In addition to the learned parameters, a set of architecture parameters are learnt to depict preference for one module over another. Such methods reduce the required computational resources to only a few GPU days.\nMore recent works further combine this weight-sharing paradigm, with a continuous relaxation of the search space,[25][26][27][28] which enables the use of gradient-based optimization methods. These approaches are generally referred to as differentiable NAS and have proven very efficient in exploring the search space of neural architectures. One of the most popular algorithms amongst the gradient-based methods for NAS is DARTS.[27] However, DARTS faces problems such as performance collapse due to an inevitable aggregation of skip connections and poor generalization which were tackled by many future algorithms.[29][30][31][32] Methods like [30][31] aim at robustifying DARTS and making the validation accuracy landscape smoother by introducing a Hessian norm based regularisation and random smoothing/adversarial attack respectively. The cause of performance degradation is later analyzed from the architecture selection aspect.[33]\nDifferentiable NAS has shown to produce competitive results using a fraction of the search-time required by RL-based search methods. For example, FBNet (which is short for Facebook Berkeley Network) demonstrated that supernetwork-based search produces networks that outperform the speed-accuracy tradeoff curve of mNASNet and MobileNetV2 on the ImageNet image-classification dataset. FBNet accomplishes this using over 400x less search time than was used for mNASNet.[34][35][36] Further, SqueezeNAS demonstrated that supernetwork-based NAS produces neural networks that outperform the speed-accuracy tradeoff curve of MobileNetV3 on the Cityscapes semantic segmentation dataset, and SqueezeNAS uses over 100x less search time than was used in the MobileNetV3 authors' RL-based search.[37][38]\n\nNeural architecture search benchmarks[edit]\nNeural architecture search often requires large computational resources, due to its expensive training and evaluation phases. This further leads to a large carbon footprint required for the evaluation of these methods.  To overcome this limitation, NAS benchmarks[39][40][41][42] have been introduced, from which one can either query or predict the final performance of neural architectures in seconds. A NAS benchmark is defined as a dataset with a fixed train-test split, a search space, and a fixed training pipeline (hyperparameters). There are primarily two types of NAS benchmarks: a surrogate NAS benchmark and a tabular NAS benchmark. A surrogate benchmark uses a  surrogate model (e.g.: a neural network) to predict the performance of an architecture from the search space. On the other hand, a tabular benchmark queries the actual performance of an architecture trained up to convergence. Both of these benchmarks are queryable and can be used to efficiently simulate many NAS algorithms using only a CPU to query the benchmark instead of training an architecture from scratch.\n\nSee also[edit]\nNeural Network Intelligence\nAutomated Machine Learning\nHyperparameter Optimization\nFurther reading[edit]\nSurvey articles.\n\nWistuba, Martin; Rawat, Ambrish; Pedapati, Tejaswini (2019-05-04). \"A Survey on Neural Architecture Search\". arXiv:1905.01392 [cs.LG].\nElsken, Thomas; Metzen, Jan Hendrik; Hutter, Frank (August 8, 2019). \"Neural Architecture Search: A Survey\". Journal of Machine Learning Research. 20 (55): 1\u201321. arXiv:1808.05377.\nLiu, Yuqiao; Sun, Yanan; Xue, Bing; Zhang, Mengjie; Yen, Gary G; Tan, Kay Chen (2021). \"A Survey on Evolutionary Neural Architecture Search\". IEEE Transactions on Neural Networks and Learning Systems. 34 (2): 1\u201321. arXiv:2008.10937. doi:10.1109/TNNLS.2021.3100554. PMID\u00a034357870. S2CID\u00a0221293236.\nWhite, Colin; Safari, Mahmoud; Sukthanker, Rhea; Ru, Binxin; Elsken, Thomas; Zela, Arber; Dey, Debadeepta; Hutter, Frank (2023-01-25). \"Neural Architecture Search: Insights from 1000 Papers\". arXiv:2301.08727 [cs.LG].\nReferences[edit]\n\n\n^ a b Elsken, Thomas; Metzen, Jan Hendrik; Hutter, Frank (August 8, 2019). \"Neural Architecture Search: A Survey\". Journal of Machine Learning Research. 20 (55): 1\u201321. arXiv:1808.05377.\n\n^ Wistuba, Martin; Rawat, Ambrish; Pedapati, Tejaswini (2019-05-04). \"A Survey on Neural Architecture Search\". arXiv:1905.01392 [cs.LG].\n\n^ a b c Zoph, Barret; Le, Quoc V. (2016-11-04). \"Neural Architecture Search with Reinforcement Learning\". arXiv:1611.01578 [cs.LG].\n\n^ a b c d e Zoph, Barret; Vasudevan, Vijay; Shlens, Jonathon; Le, Quoc V. (2017-07-21). \"Learning Transferable Architectures for Scalable Image Recognition\". arXiv:1707.07012 [cs.CV].\n\n^ Matthias Feurer and Frank Hutter. Hyperparameter optimization. In: AutoML: Methods, Systems, Challenges, pages 3\u201338.\n\n^ Vanschoren, Joaquin (2019). \"Meta-Learning\". Automated Machine Learning. The Springer Series on Challenges in Machine Learning. pp.\u00a035\u201361. doi:10.1007/978-3-030-05318-5_2. ISBN\u00a0978-3-030-05317-8. S2CID\u00a0239362577.\n\n^ Salehin, Imrus; Islam, Md. Shamiul; Saha, Pritom; Noman, S. M.; Tuni, Azra; Hasan, Md. Mehedi; Baten, Md. Abu (2024-01-01). \"AutoML: A systematic review on automated machine learning with neural architecture search\". Journal of Information and Intelligence. 2 (1): 52\u201381. doi:10.1016/j.jiixd.2023.10.002. ISSN\u00a02949-7159.\n\n^ Zoph, Barret; Vasudevan, Vijay; Shlens, Jonathon; Le, Quoc V. (November 2, 2017). \"AutoML for large scale image classification and object detection\". Research Blog. Retrieved 2018-02-20.\n\n^ Pham, Hieu; Guan, Melody Y.; Zoph, Barret; Le, Quoc V.; Dean, Jeff (2018-02-09). \"Efficient Neural Architecture Search via Parameter Sharing\". arXiv:1802.03268 [cs.LG].\n\n^ Real, Esteban; Moore, Sherry; Selle, Andrew; Saxena, Saurabh; Suematsu, Yutaka Leon; Tan, Jie; Le, Quoc; Kurakin, Alex (2017-03-03). \"Large-Scale Evolution of Image Classifiers\". arXiv:1703.01041 [cs.NE].\n\n^ Suganuma, Masanori; Shirakawa, Shinichi; Nagao, Tomoharu (2017-04-03). \"A Genetic Programming Approach to Designing Convolutional Neural Network Architectures\". arXiv:1704.00764v2 [cs.NE].\n\n^ a b Liu, Hanxiao; Simonyan, Karen; Vinyals, Oriol; Fernando, Chrisantha; Kavukcuoglu, Koray (2017-11-01). \"Hierarchical Representations for Efficient Architecture Search\". arXiv:1711.00436v2 [cs.LG].\n\n^ a b Real, Esteban; Aggarwal, Alok; Huang, Yanping; Le, Quoc V. (2018-02-05). \"Regularized Evolution for Image Classifier Architecture Search\". arXiv:1802.01548 [cs.NE].\n\n^ Miikkulainen, Risto; Liang, Jason; Meyerson, Elliot; Rawal, Aditya; Fink, Dan; Francon, Olivier; Raju, Bala; Shahrzad, Hormoz; Navruzyan, Arshak; Duffy, Nigel; Hodjat, Babak (2017-03-04). \"Evolving Deep Neural Networks\". arXiv:1703.00548 [cs.NE].\n\n^ Xie, Lingxi; Yuille, Alan (2017). \"Genetic CNN\". 2017 IEEE International Conference on Computer Vision (ICCV). pp.\u00a01388\u20131397. arXiv:1703.01513. doi:10.1109/ICCV.2017.154. ISBN\u00a0978-1-5386-1032-9. S2CID\u00a0206770867.\n\n^ a b c Elsken, Thomas; Metzen, Jan Hendrik; Hutter, Frank (2018-04-24). \"Efficient Multi-objective Neural Architecture Search via Lamarckian Evolution\". arXiv:1804.09081 [stat.ML].\n\n^ Liu, Yuqiao; Sun, Yanan; Xue, Bing; Zhang, Mengjie; Yen, Gary G; Tan, Kay Chen (2021). \"A Survey on Evolutionary Neural Architecture Search\". IEEE Transactions on Neural Networks and Learning Systems. 34 (2): 1\u201321. arXiv:2008.10937. doi:10.1109/TNNLS.2021.3100554. PMID\u00a034357870. S2CID\u00a0221293236.\n\n^ White, Colin; Neiswanger, Willie; Savani, Yash (2020-11-02). \"BANANAS: Bayesian Optimization with Neural Architectures for Neural Architecture Search\". arXiv:1910.11858 [cs.LG].\n\n^ Thomas, Elsken; Jan Hendrik, Metzen; Frank, Hutter (2017-11-13). \"Simple And Efficient Architecture Search for Convolutional Neural Networks\". arXiv:1711.04528 [stat.ML].\n\n^ a b Zhou, Yanqi; Diamos, Gregory. \"Neural Architect: A Multi-objective Neural Architecture Search with Performance Prediction\" (PDF). Baidu. Archived from the original (PDF) on 2019-09-27. Retrieved 2019-09-27.\n\n^ Tan, Mingxing; Chen, Bo; Pang, Ruoming; Vasudevan, Vijay; Sandler, Mark; Howard, Andrew; Le, Quoc V. (2018). \"MnasNet: Platform-Aware Neural Architecture Search for Mobile\". arXiv:1807.11626 [cs.CV].\n\n^ Howard, Andrew; Sandler, Mark; Chu, Grace; Chen, Liang-Chieh; Chen, Bo; Tan, Mingxing; Wang, Weijun; Zhu, Yukun; Pang, Ruoming; Vasudevan, Vijay; Le, Quoc V.; Adam, Hartwig (2019-05-06). \"Searching for MobileNetV3\". arXiv:1905.02244 [cs.CV].\n\n^ Pham, Hieu; Guan, Melody Y.; Zoph, Barret; Le, Quoc V.; Dean, Jeff (2018). \"Efficient Neural Architecture Search via Parameter Sharing\". arXiv:1802.03268 [cs.LG].\n\n^ Li, Liam; Talwalkar, Ameet (2019). \"Random Search and Reproducibility for Neural Architecture Search\". arXiv:1902.07638 [cs.LG].\n\n^ Cai, Han; Zhu, Ligeng; Han, Song (2018). \"ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware\". arXiv:1812.00332 [cs.LG].\n\n^ Dong, Xuanyi; Yang, Yi (2019). \"Searching for a Robust Neural Architecture in Four GPU Hours\". arXiv:1910.04465 [cs.CV].\n\n^ a b Liu, Hanxiao; Simonyan, Karen; Yang, Yiming (2018). \"DARTS: Differentiable Architecture Search\". arXiv:1806.09055 [cs.LG].\n\n^ Xie, Sirui; Zheng, Hehui; Liu, Chunxiao; Lin, Liang (2018). \"SNAS: Stochastic Neural Architecture Search\". arXiv:1812.09926 [cs.LG].\n\n^ Chu, Xiangxiang; Zhou, Tianbao; Zhang, Bo; Li, Jixiang (2019). \"Fair DARTS: Eliminating Unfair Advantages in Differentiable Architecture Search\". arXiv:1911.12126 [cs.LG].\n\n^ a b Zela, Arber; Elsken, Thomas; Saikia, Tonmoy; Marrakchi, Yassine; Brox, Thomas; Hutter, Frank (2019). \"Understanding and Robustifying Differentiable Architecture Search\". arXiv:1909.09656 [cs.LG].\n\n^ a b Chen, Xiangning; Hsieh, Cho-Jui (2020). \"Stabilizing Differentiable Architecture Search via Perturbation-based Regularization\". arXiv:2002.05283 [cs.LG].\n\n^ Xu, Yuhui; Xie, Lingxi; Zhang, Xiaopeng; Chen, Xin; Qi, Guo-Jun; Tian, Qi; Xiong, Hongkai (2019). \"PC-DARTS: Partial Channel Connections for Memory-Efficient Architecture Search\". arXiv:1907.05737 [cs.CV].\n\n^ Wang, Ruochen; Cheng, Minhao; Chen, Xiangning; Tang, Xiaocheng; Hsieh, Cho-Jui (2021). \"Rethinking Architecture Selection in Differentiable NAS\". arXiv:2108.04392 [cs.LG].\n\n^ Wu, Bichen; Dai, Xiaoliang; Zhang, Peizhao; Wang, Yanghan; Sun, Fei; Wu, Yiming; Tian, Yuandong; Vajda, Peter; Jia, Yangqing; Keutzer, Kurt (24 May 2019). \"FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search\". arXiv:1812.03443 [cs.CV].\n\n^ Sandler, Mark; Howard, Andrew; Zhu, Menglong; Zhmoginov, Andrey; Chen, Liang-Chieh (2018). \"MobileNetV2: Inverted Residuals and Linear Bottlenecks\". arXiv:1801.04381 [cs.CV].\n\n^ Keutzer, Kurt (2019-05-22). \"Co-Design of DNNs and NN Accelerators\" (PDF). IEEE. Retrieved 2019-09-26.\n\n^ Shaw, Albert; Hunter, Daniel; Iandola, Forrest; Sidhu, Sammy (2019). \"SqueezeNAS: Fast neural architecture search for faster semantic segmentation\". arXiv:1908.01748 [cs.CV].\n\n^ Yoshida, Junko (2019-08-25). \"Does Your AI Chip Have Its Own DNN?\". EE Times. Retrieved 2019-09-26.\n\n^ Ying, Chris; Klein, Aaron; Real, Esteban; Christiansen, Eric; Murphy, Kevin; Hutter, Frank (2019). \"NAS-Bench-101: Towards Reproducible Neural Architecture Search\". arXiv:1902.09635 [cs.LG].\n\n^ Zela, Arber; Siems, Julien; Hutter, Frank (2020). \"NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search\". arXiv:2001.10422 [cs.LG].\n\n^ Dong, Xuanyi; Yang, Yi (2020). \"NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search\". arXiv:2001.00326 [cs.CV].\n\n^ Zela, Arber; Siems, Julien; Zimmer, Lucas; Lukasik, Jovita; Keuper, Margret; Hutter, Frank (2020). \"Surrogate NAS Benchmarks: Going Beyond the Limited Search Spaces of Tabular NAS Benchmarks\". arXiv:2008.09777 [cs.LG].\n\n\nvteDifferentiable computingGeneral\nDifferentiable programming\nInformation geometry\nStatistical manifold\nAutomatic differentiation\nNeuromorphic engineering\nPattern recognition\nTensor calculus\nComputational learning theory\nInductive bias\nHardware\nIPU\nTPU\nVPU\nMemristor\nSpiNNaker\nSoftware libraries\nTensorFlow\nPyTorch\nKeras\nscikit-learn\nTheano\nJAX\nFlux.jl\nMindSpore\n\n Portals\nComputer programming\nTechnology\n\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Neural_architecture_search&oldid=1250234727\""}, {"url": "https://en.wikipedia.org/wiki/Data_pre-processing", "content": "Manipulation of data before it is analyzed\nThis article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources:\u00a0\"Data preprocessing\"\u00a0\u2013\u00a0news\u00a0\u00b7 newspapers\u00a0\u00b7 books\u00a0\u00b7 scholar\u00a0\u00b7 JSTOR (August 2023) (Learn how and when to remove this message)\nData preprocessing can refer to manipulation, filtration or augmentation of data before it is analyzed,[1] and is often an important step in the data mining process. Data collection methods are often loosely controlled, resulting in out-of-range values, impossible data combinations, and missing values, amongst other issues.\nThe preprocessing pipeline used can often have large effects on the conclusions drawn from the downstream analysis. Thus, representation and quality of data is necessary before running any analysis.[2] \nOften, data preprocessing is the most important phase of a machine learning project, especially in computational biology.[3] If there is a high proportion of irrelevant and redundant information present or noisy and unreliable data, then knowledge discovery during the training phase may be more difficult. Data preparation and filtering steps can take a considerable amount of processing time. Examples of methods used in data preprocessing include cleaning, instance selection, normalization, one-hot encoding, data transformation, feature extraction and feature selection.\n\n\nApplications[edit]\nData mining[edit]\nThis section may require cleanup to meet Wikipedia's quality standards. The specific problem is: This section requires grammar and capitalisation fixes. Please help improve this section if you can. (August 2023) (Learn how and when to remove this message)\nData preprocessing allows for the removal of unwanted data with the use of data cleaning, this allows the user to have a dataset to contain more valuable information after the preprocessing stage for data manipulation later in the data mining process. Editing such dataset to either correct data corruption or human error is a crucial step to get accurate quantifiers like true positives, true negatives, false positives and false negatives found in a confusion matrix that are commonly used for a medical diagnosis. Users are able to join data files together and use preprocessing to filter any unnecessary noise from the data which can allow for higher accuracy. Users use Python programming scripts accompanied by the pandas library which gives them the ability to import data from a comma-separated values as a data-frame. The data-frame is then used to manipulate data that can be challenging otherwise to do in Excel. Pandas (software) which is a powerful tool that allows for data analysis and manipulation; which makes data visualizations, statistical operations and much more, a lot easier. Many also use the R programming language to do such tasks as well. \nThe reason why a user transforms existing files into a new one is because of many reasons. Aspects of data preprocessing may include imputing missing values, aggregating numerical quantities and transforming continuous data into categories (data binning).[4] More advanced techniques like principal component analysis and feature selection are working with statistical formulas and are applied to complex datasets which are recorded by GPS trackers and motion capture devices.\n\nSemantic data preprocessing[edit]\nSemantic data mining is a subset of data mining that specifically seeks to incorporate domain knowledge, such as formal semantics, into the data mining process. Domain knowledge is the knowledge of the environment the data was processed in. Domain knowledge can have a positive influence on many aspects of data mining, such as filtering out redundant or inconsistent data during the preprocessing phase.[5] Domain knowledge also works as constraint. It does this by using working as set of prior knowledge to reduce the space required for searching and acting as a guide to the data. Simply put, semantic preprocessing seeks to filter data using the original environment of said data more correctly and efficiently.\nThere are increasingly complex problems which are asking to be solved by more elaborate techniques to better analyze existing information.[fact or opinion?] Instead of creating a simple script for aggregating different numerical values into a single value, it make sense to focus on semantic based data preprocessing.[6] The idea is to build a dedicated ontology, which explains on a higher level what the problem is about.[7] In regards to semantic data mining and semantic pre-processing, ontologies are a way to conceptualize and formally define semantic knowledge and data. The Prot\u00e9g\u00e9 (software) is the standard tool for constructing an ontology.[citation needed] In general, the use of ontologies bridges the gaps between data, applications, algorithms, and results that occur from semantic mismatches. As a result, semantic data mining combined with ontology has many applications where semantic ambiguity can impact the usefulness and efficiency of data systems.[citation needed] Applications include the medical field, language processing, banking,[8] and even tutoring,[9] among many more.\nThere are various strengths to using a semantic data mining and ontological based approach. As previously mentioned, these tools can help during the per-processing phase by filtering out non-desirable data from the data set. Additionally, well-structured formal semantics integrated into well designed ontologies can return powerful data that can be easily read and processed by machines.[10] A specifically useful example of this exists in the medical use of semantic data processing. As an example, a patient is having a medical emergency and is being rushed to hospital. The emergency responders are trying to figure out the best medicine to administer to help the patient. Under normal data processing, scouring all the patient\u2019s medical data to ensure they are getting the best treatment could take too long and risk the patients\u2019 health or even life. However, using semantically processed ontologies, the first responders could save the patient\u2019s life. Tools like a semantic reasoner can use ontology to infer the what best medicine to administer to the patient is based on their medical history, such as if they have a certain cancer or other conditions, simply by examining the natural language used in the patient's medical records.[11] This would allow the first responders to quickly and efficiently search for medicine without having worry about the patient\u2019s medical history themselves, as the semantic reasoner would already have analyzed this data and found solutions. In general, this illustrates the incredible strength of using semantic data mining and ontologies. They allow for quicker and more efficient data extraction on the user side, as the user has fewer variables to account for, since the semantically pre-processed data and ontology built for the data have already accounted for many of these variables. However, there are some drawbacks to this approach. Namely, it requires a high amount of computational power and complexity, even with relatively small data sets.[12] This could result in higher costs and increased difficulties in building and maintaining semantic data processing systems. This can be mitigated somewhat if the data set is already well organized and formatted, but even then, the complexity is still higher when compared to standard data processing.[tone]\nBelow is a simple a diagram combining some of the processes, in particular semantic data mining and their use in ontology.\n\nThe diagram depicts a data set being broken up into two parts: the characteristics of its domain, or domain knowledge, and then the actual acquired data. The domain characteristics are then processed to become user understood domain knowledge that can be applied to the data. Meanwhile, the data set is processed and stored so that the domain knowledge can applied to it, so that the process may continue. This application forms the ontology. From there, the ontology can be used to analyze data and process results.\nFuzzy preprocessing is another, more advanced technique for solving complex problems. Fuzzy preprocessing and fuzzy data mining make use of fuzzy sets. These data sets are composed of two elements: a set and a membership function for the set which comprises 0 and 1. Fuzzy preprocessing uses this fuzzy data set to ground numerical values with linguistic information. Raw data is then transformed into natural language. Ultimately, fuzzy data mining's goal is to help deal with inexact information, such as an incomplete database. Currently fuzzy preprocessing, as well as other fuzzy based data mining techniques see frequent use with neural networks and artificial intelligence.[13]\n\nReferences[edit]\n\n\n^ \"Guide To Data Cleaning: Definition, Benefits, Components, And How To Clean Your Data\". Tableau. Retrieved 2021-10-17.\n\n^ Pyle, D., 1999. Data Preparation for Data Mining. Morgan Kaufmann Publishers, Los Altos, California.\n\n^ Chicco D (December 2017). \"Ten quick tips for machine learning in computational biology\". BioData Mining. 10 (35): 35. doi:10.1186/s13040-017-0155-3. PMC\u00a05721660. PMID\u00a029234465.\n\n^ Hastie, Trevor; Tibshirani, Robert; Friedman, Jerome H. (2009). The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Springer. ISBN\u00a0978-0-387-84884-6.\n\n^ Dou, Deijing and Wang, Hao and Liu, Haishan. \"Semantic Data Mining: A Survey of Ontology-based Approaches\" (PDF). University of Oregon.{{cite web}}:  CS1 maint: multiple names: authors list (link)\n\n^ Culmone, Rosario and Falcioni, Marco and Quadrini, Michela (2014). An ontology-based framework for semantic data preprocessing aimed at human activity recognition. SEMAPRO 2014: The Eighth International Conference on Advances in Semantic Processing. Alexey Cheptsov, High Performance Computing Center Stuttgart (HLRS). S2CID\u00a0196091422.{{cite conference}}:  CS1 maint: multiple names: authors list (link)\n\n^ David Perez-Rey and Alberto Anguita and Jose Crespo (2006). OntoDataClean: Ontology-Based Integration and Preprocessing of Distributed Data. Biological and Medical Data Analysis. Springer Berlin Heidelberg. pp.\u00a0262\u2013272. doi:10.1007/11946465_24.\n\n^ Yerashenia, Natalia and Bolotov, Alexander and Chan, David and Pierantoni, Gabriele (2020). \"Semantic Data Pre-Processing for Machine Learning Based Bankruptcy Prediction Computational Model\". 2020 IEEE 22nd Conference on Business Informatics (CBI) (PDF). IEEE. pp.\u00a066\u201375. doi:10.1109/CBI49978.2020.00015. ISBN\u00a0978-1-7281-9926-9. S2CID\u00a0219499599.{{cite book}}:  CS1 maint: multiple names: authors list (link)\n\n^ Chang, Maiga; D'Aniello, Giuseppe; Gaeta, Matteo; Orciuoli, Francesco; Sampson, Demetrois; Simonelli, Carmine (2020). \"Building Ontology-Driven Tutoring Models for Intelligent Tutoring Systems Using Data Mining\". IEEE Access. 8. IEEE: 48151\u201348162. Bibcode:2020IEEEA...848151C. doi:10.1109/ACCESS.2020.2979281. S2CID\u00a0214594754.\n\n^ Dou, Deijing and Wang, Hao and Liu, Haishan. \"Semantic Data Mining: A Survey of Ontology-based Approaches\" (PDF). University of Oregon.{{cite web}}:  CS1 maint: multiple names: authors list (link)\n\n^ Kahn, Atif and Doucette, John A. and Jin, Changjiu and Fu Lijie and Cohen, Robin. \"AN ONTOLOGICAL APPROACH TO DATA MINING FOR EMERGENCY MEDICINE\" (PDF). University of Waterloo.{{cite web}}:  CS1 maint: multiple names: authors list (link)\n\n^ Sirichanya, Chanmee and Kraisak Kesorn (2021). \"Semantic data mining in the information age: A systematic review\". International Journal of Intelligent Systems. 36 (8): 3880\u20133916. doi:10.1002/int.22443. S2CID\u00a0235506360.\n\n^ Wong, Kok Wai and Fung, Chun Che and Law, Kok Way (2000). \"Fuzzy preprocessing rules for the improvement of an artificial neural network well log interpretation model\". 2000 TENCON Proceedings. Intelligent Systems and Technologies for the New Millennium (Cat. No.00CH37119). Vol.\u00a01. IEEE. pp.\u00a0400\u2013405. doi:10.1109/TENCON.2000.893697. ISBN\u00a00-7803-6355-8. S2CID\u00a010384426.{{cite book}}:  CS1 maint: multiple names: authors list (link)\n\n\nExternal links[edit]\nOnline Data Processing Compendium\nData preprocessing in predictive data mining. Knowledge Eng. Review 34: e1 (2019)\nvteData\nAcquisition\nAugmentation\nAnalysis\nArchaeology\nBig\nCleansing\nCollection\nCompression\nCorruption\nCuration\nDegradation\nEcosystem\nEditing\nETL/ELT\nExtract\nTransform\nLoad\nEthics\nFarming\nFormat management\nFusion\nGovernance\nCooperatives\nInfrastructure\nIntegration\nIntegrity\nLibrary\nLineage\nLoss\nManagement\nMigration\nMining\nPhilanthropy\nPre-processing\nPreservation\nProcessing\nProtection (privacy)\nPublishing\nOpen data\nRecovery\nReduction\nRetention\nQuality\nScience\nScraping\nScrubbing\nSecurity\nStewardship\nStorage\nSynchronization\nType\nValidation\nWarehouse\nWrangling/munging\n\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Data_preprocessing&oldid=1247187477\""}, {"url": "https://en.wikipedia.org/wiki/Feature_engineering", "content": "Extracting features from raw data for machine learning\n\nPart of a series onMachine learningand data mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\n\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\n\nSupervised learning(classification\u00a0\u2022 regression) \nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\n\nClustering\nBIRCH\nCURE\nHierarchical\nk-means\nFuzzy\nExpectation\u2013maximization (EM)\nDBSCAN\nOPTICS\nMean shift\n\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\n\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\n\nAnomaly detection\nRANSAC\nk-NN\nLocal outlier factor\nIsolation forest\n\nArtificial neural network\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural radiance field\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM (ECRAM)\n\nReinforcement learning\nQ-learning\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\n\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nRLHF\n\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\n\nMathematical foundations\nKernel machines\nBias\u2013variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\n\nJournals and conferences\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\n\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nvteThis article needs to be updated. Please help update this article to reflect recent events or newly available information. (February 2024)\nFeature engineering is a preprocessing step in supervised machine learning and statistical modeling[1] which transforms raw data into a more effective set of inputs. Each input comprises several attributes, known as features. By providing models with relevant information, feature engineering significantly enhances their predictive accuracy and decision-making capability.[2][3][4]\nBeyond machine learning, the principles of feature engineering are applied in various scientific fields, including physics. For example, physicists construct dimensionless numbers such as the Reynolds number in fluid dynamics, the Nusselt number in heat transfer, and the Archimedes number in sedimentation. They also develop first approximations of solutions, such as analytical solutions for the strength of materials in mechanics.[5]\n\n\nClustering[edit]\nOne of the applications of feature engineering has been clustering of feature-objects or sample-objects in a dataset. Especially, feature engineering based on matrix decomposition has been extensively used for data clustering under non-negativity constraints on the feature coefficients. These include Non-Negative Matrix Factorization (NMF),[6] Non-Negative Matrix-Tri Factorization (NMTF),[7] Non-Negative Tensor Decomposition/Factorization (NTF/NTD),[8] etc. The non-negativity constraints on coefficients of the feature vectors mined by the above-stated algorithms yields a part-based representation, and different factor matrices exhibit natural clustering properties. Several extensions of the above-stated feature engineering methods have been reported in literature, including orthogonality-constrained factorization for hard clustering, and manifold learning to overcome inherent issues with these algorithms.\nOther classes of feature engineering algorithms include leveraging a common hidden structure across multiple inter-related datasets to obtain a consensus (common) clustering scheme. An example is Multi-view Classification based on Consensus Matrix Decomposition (MCMD),[2] which mines a common clustering scheme across multiple datasets. MCMD is designed to output two types of class labels (scale-variant and scale-invariant clustering), and:\n\nis computationally robust to missing information,\ncan obtain shape- and scale-based outliers,\nand can handle high-dimensional data effectively.\nCoupled matrix and tensor decompositions are popular in multi-view feature engineering.[9]\n\nPredictive modelling[edit]\nFeature engineering in machine learning and statistical modeling involves selecting, creating, transforming, and extracting data features. Key components include feature creation from existing data, transforming and imputing missing or invalid features, reducing data dimensionality through methods like Principal Components Analysis (PCA), Independent Component Analysis (ICA), and Linear Discriminant Analysis (LDA), and selecting the most relevant features for model training based on importance scores and correlation matrices.[10]\nFeatures vary in significance.[11] Even relatively insignificant features may contribute to a model. Feature selection can reduce the number of features to prevent a model from becoming too specific to the training data set (overfitting).[12]\nFeature explosion occurs when the number of identified features is too large for effective model estimation or optimization. Common causes include:\n\nFeature templates - implementing feature templates instead of coding new features\nFeature combinations - combinations that cannot be represented by a linear system\nFeature explosion can be limited via techniques such as: regularization, kernel methods, and feature selection.[13]\n\nAutomation[edit]\nAutomation of feature engineering is a research topic that dates back to the 1990s.[14] Machine learning software that incorporates automated feature engineering has been commercially available since 2016.[15] Related academic literature can be roughly separated into two types:\n\nMulti-relational decision tree learning (MRDTL) uses a supervised algorithm that is similar to a decision tree.\nDeep Feature Synthesis uses simpler methods.[citation needed]\nMulti-relational decision tree learning (MRDTL)[edit]\nMulti-relational Decision Tree Learning (MRDTL) extends traditional decision tree methods to relational databases, handling complex data relationships across tables. It innovatively uses selection graphs as decision nodes, refined systematically until a specific termination criterion is reached.[14]\nMost MRDTL studies base implementations on relational databases, which results in many redundant operations. These redundancies can be reduced by using techniques such as tuple id propagation.[16][17]\n\nOpen-source implementations[edit]\nThere are a number of open-source libraries and tools that automate feature engineering on relational data and time series:\n\nfeaturetools is a Python library for transforming time series and relational data into feature matrices for machine learning.[18][19][20]\nMCMD: An open-source feature engineering algorithm for joint clustering of multiple datasets . [21][2]\nOneBM or One-Button Machine combines feature transformations and feature selection on relational data with feature selection techniques.[22] [OneBM] helps data scientists reduce data exploration time allowing them to try and error many ideas in short time. On the other hand, it enables non-experts, who are not familiar with data science, to quickly extract value from their data with a little effort, time, and cost.[22]\ngetML community is an open source tool for automated feature engineering on time series and relational data.[23][24] It is implemented in C/C++ with a Python interface.[24] It has been shown to be at least 60 times faster than tsflex, tsfresh, tsfel, featuretools or kats.[24]\ntsfresh is a Python library for feature extraction on time series data.[25] It evaluates the quality of the features using hypothesis testing.[26]\ntsflex is an open source Python library for extracting features from time series data.[27] Despite being 100% written in Python, it has been shown to be faster and more memory efficient than tsfresh, seglearn or tsfel.[28]\nseglearn is an extension for multivariate, sequential time series data to the scikit-learn Python library.[29]\ntsfel is a Python package for feature extraction on time series data.[30]\nkats is a Python toolkit for analyzing time series data.[31]\nDeep feature synthesis[edit]\nThe deep feature synthesis (DFS) algorithm beat 615 of 906 human teams in a competition.[32][33]\n\nFeature stores[edit]\nThe Feature Store is where the features are stored and organized for the explicit purpose of being used to either train models (by data scientists) or make predictions (by applications that have a trained model). It is a central location where you can either create or update groups of features created from multiple different data sources, or create and update new datasets from those feature groups for training models or for use in applications that do not want to compute the features but just retrieve them when it needs them to make predictions.[34]\nA feature store includes the ability to store code used to generate features, apply the code to raw data, and serve those features to models upon request. Useful capabilities include feature versioning and policies governing the circumstances under which features can be used.[35]\nFeature stores can be standalone software tools or built into machine learning platforms.\n\nAlternatives[edit]\nFeature engineering can be a time-consuming and error-prone process, as it requires domain expertise and often involves trial and error.[36][37] Deep learning algorithms may be used to process a large raw dataset without having to resort to feature engineering.[38] However, deep learning algorithms still require careful preprocessing and cleaning of the input data.[39] In addition, choosing the right architecture, hyperparameters, and optimization algorithm for a deep neural network can be a challenging and iterative process.[40]\n\nSee also[edit]\nCovariate\nData transformation\nFeature extraction\nFeature learning\nHashing trick\nInstrumental variables estimation\nKernel method\nList of datasets for machine learning research\nScale co-occurrence matrix\nSpace mapping\nReferences[edit]\n\n\n^ Hastie, Trevor; Tibshirani, Robert; Friedman, Jerome H. (2009). The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Springer. ISBN\u00a0978-0-387-84884-6.\n\n^ a b c Sharma, Shubham; Nayak, Richi; Bhaskar, Ashish (2024-05-01). \"Multi-view feature engineering for day-to-day joint clustering of multiple traffic datasets\". Transportation Research Part C: Emerging Technologies. 162: 104607. Bibcode:2024TRPC..16204607S. doi:10.1016/j.trc.2024.104607. ISSN\u00a00968-090X.\n\n^ Shalev-Shwartz, Shai; Ben-David, Shai (2014). Understanding Machine Learning: From Theory to Algorithms. Cambridge: Cambridge University Press. ISBN\u00a09781107057135.\n\n^ Murphy, Kevin P. (2022). Probabilistic Machine Learning. Cambridge, Massachusetts: The MIT Press (Copyright 2022 Massachusetts Institute of Technology, this work is subject to a Creative Commons CC-BY-NC-ND license). ISBN\u00a09780262046824.\n\n^ MacQueron C (2021). SOLID-LIQUID MIXING IN STIRRED TANKS\u00a0: Modeling, Validation, Design Optimization and Suspension Quality Prediction (Report). doi:10.13140/RG.2.2.11074.84164/1.\n\n^ Lee, Daniel D.; Seung, H. Sebastian (1999). \"Learning the parts of objects by non-negative matrix factorization\". Nature. 401 (6755): 788\u2013791. Bibcode:1999Natur.401..788L. doi:10.1038/44565. ISSN\u00a01476-4687. PMID\u00a010548103.\n\n^ Wang, Hua; Nie, Feiping; Huang, Heng; Ding, Chris (2011). \"Nonnegative Matrix Tri-factorization Based High-Order Co-clustering and Its Fast Implementation\". 2011 IEEE 11th International Conference on Data Mining. IEEE. pp.\u00a0774\u2013783. doi:10.1109/icdm.2011.109. ISBN\u00a0978-1-4577-2075-8.\n\n^ Lim, Lek-Heng; Comon, Pierre (2009-04-12). \"Nonnegative approximations of nonnegative tensors\". arXiv:0903.4530 [cs.NA].\n\n^ Nayak, Richi; Luong, Khanh (2023). \"Multi-aspect Learning\". Intelligent Systems Reference Library. 242. doi:10.1007/978-3-031-33560-0. ISBN\u00a0978-3-031-33559-4. ISSN\u00a01868-4394.\n\n^ \"Feature engineering - Machine Learning Lens\". docs.aws.amazon.com. Retrieved 2024-03-01.\n\n^ \"Feature Engineering\" (PDF). 2010-04-22. Retrieved 12 November 2015.\n\n^ \"Feature engineering and selection\" (PDF). Alexandre Bouchard-C\u00f4t\u00e9. October 1, 2009. Retrieved 12 November 2015.\n\n^ \"Feature engineering in Machine Learning\" (PDF). Zdenek Zabokrtsky. Archived from the original (PDF) on 4 March 2016. Retrieved 12 November 2015.\n\n^ a b Knobbe AJ, Siebes A, Van Der Wallen D (1999). \"Multi-relational Decision Tree Induction\" (PDF). Principles of Data Mining and Knowledge Discovery. Lecture Notes in Computer Science. Vol.\u00a01704. pp.\u00a0378\u2013383. doi:10.1007/978-3-540-48247-5_46. ISBN\u00a0978-3-540-66490-1.\n\n^ \"Its all about the features\". Reality AI Blog. September 2017.\n\n^ Yin X, Han J, Yang J, Yu PS (2004). \"CrossMine: Efficient classification across multiple database relations\". Proceedings. 20th International Conference on Data Engineering. pp.\u00a0399\u2013410. doi:10.1109/ICDE.2004.1320014. ISBN\u00a00-7695-2065-0. S2CID\u00a01183403.\n\n^ Frank R, Moser F, Ester M (2007). \"A Method for Multi-relational Classification Using Single and Multi-feature Aggregation Functions\". Knowledge Discovery in Databases: PKDD 2007. Lecture Notes in Computer Science. Vol.\u00a04702. pp.\u00a0430\u2013437. doi:10.1007/978-3-540-74976-9_43. ISBN\u00a0978-3-540-74975-2.\n\n^ \"What is Featuretools?\". Retrieved September 7, 2022.\n\n^ \"Featuretools - An open source python framework for automated feature engineering\". Retrieved September 7, 2022.\n\n^ \"github: alteryx/featuretools\". GitHub. Retrieved September 7, 2022.\n\n^ Sharma, Shubham, mcmd: Multi-view Classification framework based on Consensus Matrix Decomposition developed by Shubham Sharma at QUT, retrieved 2024-04-14\n\n^ a b Thanh Lam, Hoang; Thiebaut, Johann-Michael; Sinn, Mathieu; Chen, Bei; Mai, Tiep; Alkan, Oznur (2017-06-01). \"One button machine for automating feature engineering in relational databases\". arXiv:1706.00327 [cs.DB].\n\n^ \"getML documentation\". Retrieved September 7, 2022.\n\n^ a b c \"github: getml/getml-community\". GitHub. Retrieved September 7, 2022.\n\n^ \"tsfresh documentation\". Retrieved September 7, 2022.\n\n^ \"Time Series FeatuRe Extraction on basis of Scalable Hypothesis tests (tsfresh \u2013 A Python package)\". Retrieved September 7, 2022.\n\n^ \"predict-idlab/tsflex\". GitHub. Retrieved September 7, 2022.\n\n^ Van Der Donckt, Jonas; Van Der Donckt, Jeroen; Deprost, Emiel; Van Hoecke, Sofie (2022). \"tsflex: Flexible time series processing & feature extraction\". SoftwareX. 17: 100971. arXiv:2111.12429. Bibcode:2022SoftX..1700971V. doi:10.1016/j.softx.2021.100971. S2CID\u00a0244527198. Retrieved September 7, 2022.\n\n^ \"seglearn user guide\". Retrieved September 7, 2022.\n\n^ \"Welcome to TSFEL documentation!\". Retrieved September 7, 2022.\n\n^ \"github: facebookresearch/Kats\". GitHub. Retrieved September 7, 2022.\n\n^ \"Automating big-data analysis\". 16 October 2015.\n\n^ Kanter, James Max; Veeramachaneni, Kalyan (2015). \"Deep feature synthesis: Towards automating data science endeavors\". 2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA). pp.\u00a01\u201310. doi:10.1109/DSAA.2015.7344858. ISBN\u00a0978-1-4673-8272-4. S2CID\u00a0206610380.\n\n^ \"What is a feature store\". Retrieved 2022-04-19.\n\n^ \"An Introduction to Feature Stores\". Retrieved 2021-04-15.\n\n^ \"Feature Engineering in Machine Learning\". Engineering Education (EngEd) Program | Section. Retrieved 2023-03-21.\n\n^ explorium_admin (2021-10-25). \"5 Reasons Why Feature Engineering is Challenging\". Explorium. Retrieved 2023-03-21.\n\n^ Spiegelhalter, D. J. (2019). The art of statistics\u00a0: learning from data. [London] UK. ISBN\u00a0978-0-241-39863-0. OCLC\u00a01064776283.{{cite book}}:  CS1 maint: location missing publisher (link)\n\n^ Sarker IH (November 2021). \"Deep Learning: A Comprehensive Overview on Techniques, Taxonomy, Applications and Research Directions\". SN Computer Science. 2 (6): 420. doi:10.1007/s42979-021-00815-1. PMC\u00a08372231. PMID\u00a034426802.\n\n^ Bengio, Yoshua (2012), \"Practical Recommendations for Gradient-Based Training of Deep Architectures\", Neural Networks: Tricks of the Trade, Lecture Notes in Computer Science, vol.\u00a07700, Berlin, Heidelberg: Springer Berlin Heidelberg, pp.\u00a0437\u2013478, arXiv:1206.5533, doi:10.1007/978-3-642-35289-8_26, ISBN\u00a0978-3-642-35288-1, S2CID\u00a010808461, retrieved 2023-03-21\n\n\nFurther reading[edit]\n\nBoehmke B, Greenwell B (2019). \"Feature & Target Engineering\". Hands-On Machine Learning with R. Chapman & Hall. pp.\u00a041\u201375. ISBN\u00a0978-1-138-49568-5.\nZheng A, Casari A (2018). Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists. O'Reilly. ISBN\u00a0978-1-4919-5324-2.\nZumel N, Mount (2020). \"Data Engineering and Data Shaping\". Practical Data Science with R (2nd\u00a0ed.). Manning. pp.\u00a0113\u2013160. ISBN\u00a0978-1-61729-587-4.\nAbououf, M., Singh, S., Mizouni, R., Otrok, H. (2024), Feature engineering and deep learning-based approach for event detection in Medical Internet of Things (MIoT), Elsevier BV\nChicco D, Oneto L, Tavazzi E (December 2022). \"Eleven quick tips for data cleaning and feature engineering\". PLOS Computational Biology. 18 (12): e1010718. doi:10.1371/journal.pcbi.1010718. PMC\u00a09754225. PMID\u00a036520712. S2CID\u00a0254733288.\n\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Feature_engineering&oldid=1254881418\""}, {"url": "https://en.wikipedia.org/wiki/Feature_extraction", "content": "Extracting features from raw data for machine learning\n\nPart of a series onMachine learningand data mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\n\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\n\nSupervised learning(classification\u00a0\u2022 regression) \nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\n\nClustering\nBIRCH\nCURE\nHierarchical\nk-means\nFuzzy\nExpectation\u2013maximization (EM)\nDBSCAN\nOPTICS\nMean shift\n\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\n\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\n\nAnomaly detection\nRANSAC\nk-NN\nLocal outlier factor\nIsolation forest\n\nArtificial neural network\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural radiance field\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM (ECRAM)\n\nReinforcement learning\nQ-learning\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\n\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nRLHF\n\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\n\nMathematical foundations\nKernel machines\nBias\u2013variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\n\nJournals and conferences\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\n\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nvteThis article needs to be updated. Please help update this article to reflect recent events or newly available information. (February 2024)\nFeature engineering is a preprocessing step in supervised machine learning and statistical modeling[1] which transforms raw data into a more effective set of inputs. Each input comprises several attributes, known as features. By providing models with relevant information, feature engineering significantly enhances their predictive accuracy and decision-making capability.[2][3][4]\nBeyond machine learning, the principles of feature engineering are applied in various scientific fields, including physics. For example, physicists construct dimensionless numbers such as the Reynolds number in fluid dynamics, the Nusselt number in heat transfer, and the Archimedes number in sedimentation. They also develop first approximations of solutions, such as analytical solutions for the strength of materials in mechanics.[5]\n\n\nClustering[edit]\nOne of the applications of feature engineering has been clustering of feature-objects or sample-objects in a dataset. Especially, feature engineering based on matrix decomposition has been extensively used for data clustering under non-negativity constraints on the feature coefficients. These include Non-Negative Matrix Factorization (NMF),[6] Non-Negative Matrix-Tri Factorization (NMTF),[7] Non-Negative Tensor Decomposition/Factorization (NTF/NTD),[8] etc. The non-negativity constraints on coefficients of the feature vectors mined by the above-stated algorithms yields a part-based representation, and different factor matrices exhibit natural clustering properties. Several extensions of the above-stated feature engineering methods have been reported in literature, including orthogonality-constrained factorization for hard clustering, and manifold learning to overcome inherent issues with these algorithms.\nOther classes of feature engineering algorithms include leveraging a common hidden structure across multiple inter-related datasets to obtain a consensus (common) clustering scheme. An example is Multi-view Classification based on Consensus Matrix Decomposition (MCMD),[2] which mines a common clustering scheme across multiple datasets. MCMD is designed to output two types of class labels (scale-variant and scale-invariant clustering), and:\n\nis computationally robust to missing information,\ncan obtain shape- and scale-based outliers,\nand can handle high-dimensional data effectively.\nCoupled matrix and tensor decompositions are popular in multi-view feature engineering.[9]\n\nPredictive modelling[edit]\nFeature engineering in machine learning and statistical modeling involves selecting, creating, transforming, and extracting data features. Key components include feature creation from existing data, transforming and imputing missing or invalid features, reducing data dimensionality through methods like Principal Components Analysis (PCA), Independent Component Analysis (ICA), and Linear Discriminant Analysis (LDA), and selecting the most relevant features for model training based on importance scores and correlation matrices.[10]\nFeatures vary in significance.[11] Even relatively insignificant features may contribute to a model. Feature selection can reduce the number of features to prevent a model from becoming too specific to the training data set (overfitting).[12]\nFeature explosion occurs when the number of identified features is too large for effective model estimation or optimization. Common causes include:\n\nFeature templates - implementing feature templates instead of coding new features\nFeature combinations - combinations that cannot be represented by a linear system\nFeature explosion can be limited via techniques such as: regularization, kernel methods, and feature selection.[13]\n\nAutomation[edit]\nAutomation of feature engineering is a research topic that dates back to the 1990s.[14] Machine learning software that incorporates automated feature engineering has been commercially available since 2016.[15] Related academic literature can be roughly separated into two types:\n\nMulti-relational decision tree learning (MRDTL) uses a supervised algorithm that is similar to a decision tree.\nDeep Feature Synthesis uses simpler methods.[citation needed]\nMulti-relational decision tree learning (MRDTL)[edit]\nMulti-relational Decision Tree Learning (MRDTL) extends traditional decision tree methods to relational databases, handling complex data relationships across tables. It innovatively uses selection graphs as decision nodes, refined systematically until a specific termination criterion is reached.[14]\nMost MRDTL studies base implementations on relational databases, which results in many redundant operations. These redundancies can be reduced by using techniques such as tuple id propagation.[16][17]\n\nOpen-source implementations[edit]\nThere are a number of open-source libraries and tools that automate feature engineering on relational data and time series:\n\nfeaturetools is a Python library for transforming time series and relational data into feature matrices for machine learning.[18][19][20]\nMCMD: An open-source feature engineering algorithm for joint clustering of multiple datasets . [21][2]\nOneBM or One-Button Machine combines feature transformations and feature selection on relational data with feature selection techniques.[22] [OneBM] helps data scientists reduce data exploration time allowing them to try and error many ideas in short time. On the other hand, it enables non-experts, who are not familiar with data science, to quickly extract value from their data with a little effort, time, and cost.[22]\ngetML community is an open source tool for automated feature engineering on time series and relational data.[23][24] It is implemented in C/C++ with a Python interface.[24] It has been shown to be at least 60 times faster than tsflex, tsfresh, tsfel, featuretools or kats.[24]\ntsfresh is a Python library for feature extraction on time series data.[25] It evaluates the quality of the features using hypothesis testing.[26]\ntsflex is an open source Python library for extracting features from time series data.[27] Despite being 100% written in Python, it has been shown to be faster and more memory efficient than tsfresh, seglearn or tsfel.[28]\nseglearn is an extension for multivariate, sequential time series data to the scikit-learn Python library.[29]\ntsfel is a Python package for feature extraction on time series data.[30]\nkats is a Python toolkit for analyzing time series data.[31]\nDeep feature synthesis[edit]\nThe deep feature synthesis (DFS) algorithm beat 615 of 906 human teams in a competition.[32][33]\n\nFeature stores[edit]\nThe Feature Store is where the features are stored and organized for the explicit purpose of being used to either train models (by data scientists) or make predictions (by applications that have a trained model). It is a central location where you can either create or update groups of features created from multiple different data sources, or create and update new datasets from those feature groups for training models or for use in applications that do not want to compute the features but just retrieve them when it needs them to make predictions.[34]\nA feature store includes the ability to store code used to generate features, apply the code to raw data, and serve those features to models upon request. Useful capabilities include feature versioning and policies governing the circumstances under which features can be used.[35]\nFeature stores can be standalone software tools or built into machine learning platforms.\n\nAlternatives[edit]\nFeature engineering can be a time-consuming and error-prone process, as it requires domain expertise and often involves trial and error.[36][37] Deep learning algorithms may be used to process a large raw dataset without having to resort to feature engineering.[38] However, deep learning algorithms still require careful preprocessing and cleaning of the input data.[39] In addition, choosing the right architecture, hyperparameters, and optimization algorithm for a deep neural network can be a challenging and iterative process.[40]\n\nSee also[edit]\nCovariate\nData transformation\nFeature extraction\nFeature learning\nHashing trick\nInstrumental variables estimation\nKernel method\nList of datasets for machine learning research\nScale co-occurrence matrix\nSpace mapping\nReferences[edit]\n\n\n^ Hastie, Trevor; Tibshirani, Robert; Friedman, Jerome H. (2009). The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Springer. ISBN\u00a0978-0-387-84884-6.\n\n^ a b c Sharma, Shubham; Nayak, Richi; Bhaskar, Ashish (2024-05-01). \"Multi-view feature engineering for day-to-day joint clustering of multiple traffic datasets\". Transportation Research Part C: Emerging Technologies. 162: 104607. Bibcode:2024TRPC..16204607S. doi:10.1016/j.trc.2024.104607. ISSN\u00a00968-090X.\n\n^ Shalev-Shwartz, Shai; Ben-David, Shai (2014). Understanding Machine Learning: From Theory to Algorithms. Cambridge: Cambridge University Press. ISBN\u00a09781107057135.\n\n^ Murphy, Kevin P. (2022). Probabilistic Machine Learning. Cambridge, Massachusetts: The MIT Press (Copyright 2022 Massachusetts Institute of Technology, this work is subject to a Creative Commons CC-BY-NC-ND license). ISBN\u00a09780262046824.\n\n^ MacQueron C (2021). SOLID-LIQUID MIXING IN STIRRED TANKS\u00a0: Modeling, Validation, Design Optimization and Suspension Quality Prediction (Report). doi:10.13140/RG.2.2.11074.84164/1.\n\n^ Lee, Daniel D.; Seung, H. Sebastian (1999). \"Learning the parts of objects by non-negative matrix factorization\". Nature. 401 (6755): 788\u2013791. Bibcode:1999Natur.401..788L. doi:10.1038/44565. ISSN\u00a01476-4687. PMID\u00a010548103.\n\n^ Wang, Hua; Nie, Feiping; Huang, Heng; Ding, Chris (2011). \"Nonnegative Matrix Tri-factorization Based High-Order Co-clustering and Its Fast Implementation\". 2011 IEEE 11th International Conference on Data Mining. IEEE. pp.\u00a0774\u2013783. doi:10.1109/icdm.2011.109. ISBN\u00a0978-1-4577-2075-8.\n\n^ Lim, Lek-Heng; Comon, Pierre (2009-04-12). \"Nonnegative approximations of nonnegative tensors\". arXiv:0903.4530 [cs.NA].\n\n^ Nayak, Richi; Luong, Khanh (2023). \"Multi-aspect Learning\". Intelligent Systems Reference Library. 242. doi:10.1007/978-3-031-33560-0. ISBN\u00a0978-3-031-33559-4. ISSN\u00a01868-4394.\n\n^ \"Feature engineering - Machine Learning Lens\". docs.aws.amazon.com. Retrieved 2024-03-01.\n\n^ \"Feature Engineering\" (PDF). 2010-04-22. Retrieved 12 November 2015.\n\n^ \"Feature engineering and selection\" (PDF). Alexandre Bouchard-C\u00f4t\u00e9. October 1, 2009. Retrieved 12 November 2015.\n\n^ \"Feature engineering in Machine Learning\" (PDF). Zdenek Zabokrtsky. Archived from the original (PDF) on 4 March 2016. Retrieved 12 November 2015.\n\n^ a b Knobbe AJ, Siebes A, Van Der Wallen D (1999). \"Multi-relational Decision Tree Induction\" (PDF). Principles of Data Mining and Knowledge Discovery. Lecture Notes in Computer Science. Vol.\u00a01704. pp.\u00a0378\u2013383. doi:10.1007/978-3-540-48247-5_46. ISBN\u00a0978-3-540-66490-1.\n\n^ \"Its all about the features\". Reality AI Blog. September 2017.\n\n^ Yin X, Han J, Yang J, Yu PS (2004). \"CrossMine: Efficient classification across multiple database relations\". Proceedings. 20th International Conference on Data Engineering. pp.\u00a0399\u2013410. doi:10.1109/ICDE.2004.1320014. ISBN\u00a00-7695-2065-0. S2CID\u00a01183403.\n\n^ Frank R, Moser F, Ester M (2007). \"A Method for Multi-relational Classification Using Single and Multi-feature Aggregation Functions\". Knowledge Discovery in Databases: PKDD 2007. Lecture Notes in Computer Science. Vol.\u00a04702. pp.\u00a0430\u2013437. doi:10.1007/978-3-540-74976-9_43. ISBN\u00a0978-3-540-74975-2.\n\n^ \"What is Featuretools?\". Retrieved September 7, 2022.\n\n^ \"Featuretools - An open source python framework for automated feature engineering\". Retrieved September 7, 2022.\n\n^ \"github: alteryx/featuretools\". GitHub. Retrieved September 7, 2022.\n\n^ Sharma, Shubham, mcmd: Multi-view Classification framework based on Consensus Matrix Decomposition developed by Shubham Sharma at QUT, retrieved 2024-04-14\n\n^ a b Thanh Lam, Hoang; Thiebaut, Johann-Michael; Sinn, Mathieu; Chen, Bei; Mai, Tiep; Alkan, Oznur (2017-06-01). \"One button machine for automating feature engineering in relational databases\". arXiv:1706.00327 [cs.DB].\n\n^ \"getML documentation\". Retrieved September 7, 2022.\n\n^ a b c \"github: getml/getml-community\". GitHub. Retrieved September 7, 2022.\n\n^ \"tsfresh documentation\". Retrieved September 7, 2022.\n\n^ \"Time Series FeatuRe Extraction on basis of Scalable Hypothesis tests (tsfresh \u2013 A Python package)\". Retrieved September 7, 2022.\n\n^ \"predict-idlab/tsflex\". GitHub. Retrieved September 7, 2022.\n\n^ Van Der Donckt, Jonas; Van Der Donckt, Jeroen; Deprost, Emiel; Van Hoecke, Sofie (2022). \"tsflex: Flexible time series processing & feature extraction\". SoftwareX. 17: 100971. arXiv:2111.12429. Bibcode:2022SoftX..1700971V. doi:10.1016/j.softx.2021.100971. S2CID\u00a0244527198. Retrieved September 7, 2022.\n\n^ \"seglearn user guide\". Retrieved September 7, 2022.\n\n^ \"Welcome to TSFEL documentation!\". Retrieved September 7, 2022.\n\n^ \"github: facebookresearch/Kats\". GitHub. Retrieved September 7, 2022.\n\n^ \"Automating big-data analysis\". 16 October 2015.\n\n^ Kanter, James Max; Veeramachaneni, Kalyan (2015). \"Deep feature synthesis: Towards automating data science endeavors\". 2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA). pp.\u00a01\u201310. doi:10.1109/DSAA.2015.7344858. ISBN\u00a0978-1-4673-8272-4. S2CID\u00a0206610380.\n\n^ \"What is a feature store\". Retrieved 2022-04-19.\n\n^ \"An Introduction to Feature Stores\". Retrieved 2021-04-15.\n\n^ \"Feature Engineering in Machine Learning\". Engineering Education (EngEd) Program | Section. Retrieved 2023-03-21.\n\n^ explorium_admin (2021-10-25). \"5 Reasons Why Feature Engineering is Challenging\". Explorium. Retrieved 2023-03-21.\n\n^ Spiegelhalter, D. J. (2019). The art of statistics\u00a0: learning from data. [London] UK. ISBN\u00a0978-0-241-39863-0. OCLC\u00a01064776283.{{cite book}}:  CS1 maint: location missing publisher (link)\n\n^ Sarker IH (November 2021). \"Deep Learning: A Comprehensive Overview on Techniques, Taxonomy, Applications and Research Directions\". SN Computer Science. 2 (6): 420. doi:10.1007/s42979-021-00815-1. PMC\u00a08372231. PMID\u00a034426802.\n\n^ Bengio, Yoshua (2012), \"Practical Recommendations for Gradient-Based Training of Deep Architectures\", Neural Networks: Tricks of the Trade, Lecture Notes in Computer Science, vol.\u00a07700, Berlin, Heidelberg: Springer Berlin Heidelberg, pp.\u00a0437\u2013478, arXiv:1206.5533, doi:10.1007/978-3-642-35289-8_26, ISBN\u00a0978-3-642-35288-1, S2CID\u00a010808461, retrieved 2023-03-21\n\n\nFurther reading[edit]\n\nBoehmke B, Greenwell B (2019). \"Feature & Target Engineering\". Hands-On Machine Learning with R. Chapman & Hall. pp.\u00a041\u201375. ISBN\u00a0978-1-138-49568-5.\nZheng A, Casari A (2018). Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists. O'Reilly. ISBN\u00a0978-1-4919-5324-2.\nZumel N, Mount (2020). \"Data Engineering and Data Shaping\". Practical Data Science with R (2nd\u00a0ed.). Manning. pp.\u00a0113\u2013160. ISBN\u00a0978-1-61729-587-4.\nAbououf, M., Singh, S., Mizouni, R., Otrok, H. (2024), Feature engineering and deep learning-based approach for event detection in Medical Internet of Things (MIoT), Elsevier BV\nChicco D, Oneto L, Tavazzi E (December 2022). \"Eleven quick tips for data cleaning and feature engineering\". PLOS Computational Biology. 18 (12): e1010718. doi:10.1371/journal.pcbi.1010718. PMC\u00a09754225. PMID\u00a036520712. S2CID\u00a0254733288.\n\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Feature_engineering&oldid=1254881418\""}, {"url": "https://en.wikipedia.org/wiki/Feature_selection", "content": "Process in machine learning and statistics\nThis article includes a list of general references, but it lacks sufficient corresponding inline citations. Please help to improve this article by introducing more precise citations. (July 2010) (Learn how and when to remove this message)\nNot to be confused with Feature extraction.\nIn machine learning, feature selection is the process of selecting a subset of relevant features (variables, predictors) for use in model construction. Feature selection techniques are used for several reasons:\n\nsimplification of models to make them easier to interpret,[1]\nshorter training times,[2]\nto avoid the curse of dimensionality,[3]\nimprove the compatibility of the data with a certain learning model class,[4]\nto encode inherent symmetries present in the input space.[5][6][7][8]\nThe central premise when using feature selection is that data sometimes contains features that are redundant or irrelevant, and can thus be removed without incurring much loss of information.[9] Redundancy and irrelevance are two distinct notions, since one relevant feature may be redundant in the presence of another relevant feature with which it is strongly correlated.[10]\nFeature extraction creates new features from functions of the original features, whereas feature selection finds a subset of the features. Feature selection techniques are often used in domains where there are many features and comparatively few samples (data points).\n\n\nIntroduction[edit]\nA feature selection algorithm can be seen as the combination of a search technique for proposing new feature subsets, along with an evaluation measure which scores the different feature subsets. The simplest algorithm is to test each possible subset of features finding the one which minimizes the error rate. This is an exhaustive search of the space, and is computationally intractable for all but the smallest of feature sets. The choice of evaluation metric heavily influences the algorithm, and it is these evaluation metrics which distinguish between the three main categories of feature selection algorithms: wrappers, filters and embedded methods.[10]\n\nWrapper methods use a predictive model to score feature subsets. Each new subset is used to train a model, which is tested on a hold-out set. Counting the number of mistakes made on that hold-out set (the error rate of the model) gives the score for that subset. As wrapper methods train a new model for each subset, they are very computationally intensive, but usually provide the best performing feature set for that particular type of model or typical problem.\nFilter methods use a proxy measure instead of the error rate to score a feature subset. This measure is chosen to be fast to compute, while still capturing the usefulness of the feature set. Common measures include the mutual information,[10] the pointwise mutual information,[11] Pearson product-moment correlation coefficient, Relief-based algorithms,[12] and inter/intra class distance or the scores of significance tests for each class/feature combinations.[11][13] Filters are usually less computationally intensive than wrappers, but they produce a feature set which is not tuned to a specific type of predictive model.[14] This lack of tuning means a feature set from a filter is more general than the set from a wrapper, usually giving lower prediction performance than a wrapper. However the feature set doesn't contain the assumptions of a prediction model, and so is more useful for exposing the relationships between the features. Many filters provide a feature ranking rather than an explicit best feature subset, and the cut off point in the ranking is chosen via cross-validation. Filter methods have also been used as a preprocessing step for wrapper methods, allowing a wrapper to be used on larger problems. One other popular approach is the Recursive Feature Elimination algorithm,[15] commonly used with Support Vector Machines to repeatedly construct a model and remove features with low weights.\nEmbedded methods are a catch-all group of techniques which perform feature selection as part of the model construction process. The exemplar of this approach is the LASSO method for constructing a linear model, which penalizes the regression coefficients with an L1 penalty, shrinking many of them to zero. Any features which have non-zero regression coefficients are 'selected' by the LASSO algorithm. Improvements to the LASSO include Bolasso which bootstraps samples;[16] Elastic net regularization, which combines the L1 penalty of LASSO with the L2 penalty of ridge regression; and FeaLect which scores all the features based on combinatorial analysis of regression coefficients.[17] AEFS further extends LASSO to nonlinear scenario with autoencoders.[18] These approaches tend to be between filters and wrappers in terms of computational complexity.\nIn traditional regression analysis, the most popular form of feature selection is stepwise regression, which is a wrapper technique.  It is a greedy algorithm that adds the best feature (or deletes the worst feature) at each round.  The main control issue is deciding when to stop the algorithm.  In machine learning, this is typically done by cross-validation.  In statistics, some criteria are optimized.  This leads to the inherent problem of nesting. More robust methods have been explored, such as branch and bound and piecewise linear network.\n\nSubset selection[edit]\nSubset selection evaluates a subset of features as a group for suitability. Subset selection algorithms can be broken up into wrappers, filters, and embedded methods. Wrappers use a search algorithm to search through the space of possible features and evaluate each subset by running a model on the subset. Wrappers can be computationally expensive and have a risk of over fitting to the model. Filters are similar to wrappers in the search approach, but instead of evaluating against a model, a simpler filter is evaluated. Embedded techniques are embedded in, and specific to, a model.\nMany popular search approaches use greedy hill climbing, which iteratively evaluates a candidate subset of features, then modifies the subset and evaluates if the new subset is an improvement over the old. Evaluation of the subsets requires a scoring metric that grades a subset of features.  Exhaustive search is generally impractical, so at some implementor (or operator) defined stopping point, the subset of features with the highest score discovered up to that point is selected as the satisfactory feature subset.  The stopping criterion varies by algorithm; possible criteria include: a subset score exceeds a threshold, a program's maximum allowed run time has been surpassed, etc.\nAlternative search-based techniques are based on targeted projection pursuit which finds low-dimensional projections of the data that score highly: the features that have the largest projections in the lower-dimensional space are then selected.\nSearch approaches include:\n\nExhaustive[19]\nBest first\nSimulated annealing\nGenetic algorithm[20]\nGreedy forward selection[21][22][23]\nGreedy backward elimination\nParticle swarm optimization[24]\nTargeted projection pursuit\nScatter search[25][26]\nVariable neighborhood search[27][28]\nTwo popular filter metrics for classification problems are correlation and mutual information, although neither are true metrics or 'distance measures' in the mathematical sense, since they fail to obey the triangle inequality and thus do not compute any actual 'distance' \u2013 they should rather be regarded as 'scores'.  These scores are computed between a candidate feature (or set of features) and the desired output category.  There are, however, true metrics that are a simple function of the mutual information;[29] see here.\nOther available filter metrics include:\n\nClass separability\nError probability\nInter-class distance\nProbabilistic distance\nEntropy\nConsistency-based feature selection\nCorrelation-based feature selection\nOptimality criteria[edit]\nThe choice of optimality criteria is difficult as there are multiple objectives in a feature selection task. Many common criteria incorporate a measure of accuracy, penalised by the number of features selected. Examples include Akaike information criterion (AIC) and Mallows's Cp, which have a penalty of 2 for each added feature. AIC is based on information theory, and is effectively derived via the maximum entropy principle.[30][31]\nOther criteria are Bayesian information criterion (BIC), which uses a penalty of \n\n\n\n\n\nlog\n\u2061\n\nn\n\n\n\n\n\n{\\displaystyle {\\sqrt {\\log {n}}}}\n\n for each added feature, minimum description length (MDL) which asymptotically uses \n\n\n\n\n\nlog\n\u2061\n\nn\n\n\n\n\n\n{\\displaystyle {\\sqrt {\\log {n}}}}\n\n, Bonferroni / RIC which use \n\n\n\n\n\n2\nlog\n\u2061\n\np\n\n\n\n\n\n{\\displaystyle {\\sqrt {2\\log {p}}}}\n\n, maximum dependency feature selection, and a variety of new criteria that are motivated by false discovery rate (FDR), which use something close to \n\n\n\n\n\n2\nlog\n\u2061\n\n\np\nq\n\n\n\n\n\n\n{\\displaystyle {\\sqrt {2\\log {\\frac {p}{q}}}}}\n\n. A maximum entropy rate criterion may also be used to select the most relevant subset of features.[32]\n\nStructure learning[edit]\nFilter feature selection is a specific case of a more general paradigm called structure learning. Feature selection finds the relevant feature set for a specific target variable whereas structure learning finds the relationships between all the variables, usually by expressing these relationships as a graph. The most common structure learning algorithms assume the data is generated by a Bayesian Network, and so the structure is a directed graphical model. The optimal solution to the filter feature selection problem is the Markov blanket of the target node, and in a Bayesian Network, there is a unique Markov Blanket for each node.[33]\n\nInformation Theory Based Feature Selection Mechanisms[edit]\nThere are different Feature Selection mechanisms around that utilize mutual information for scoring the different features. They usually use all the same algorithm:\n\nCalculate the mutual information as score for between all features (\n\n\n\n\nf\n\ni\n\n\n\u2208\nF\n\n\n{\\displaystyle f_{i}\\in F}\n\n) and the target class (c)\nSelect the feature with the largest score (e.g. \n\n\n\n\n\nargmax\n\n\nf\n\ni\n\n\n\u2208\nF\n\n\n\n(\nI\n(\n\nf\n\ni\n\n\n,\nc\n)\n)\n\n\n{\\displaystyle {\\underset {f_{i}\\in F}{\\operatorname {argmax} }}(I(f_{i},c))}\n\n) and add it to the set of selected features (S)\nCalculate the score which might be derived from the mutual information\nSelect the feature with the largest score and add it to the set of select features (e.g. \n\n\n\n\n\nargmax\n\n\nf\n\ni\n\n\n\u2208\nF\n\n\n\n(\n\nI\n\nd\ne\nr\ni\nv\ne\nd\n\n\n(\n\nf\n\ni\n\n\n,\nc\n)\n)\n\n\n{\\displaystyle {\\underset {f_{i}\\in F}{\\operatorname {argmax} }}(I_{derived}(f_{i},c))}\n\n)\nRepeat 3. and 4. until a certain number of features is selected (e.g. \n\n\n\n\n|\n\nS\n\n|\n\n=\nl\n\n\n{\\displaystyle |S|=l}\n\n)\nThe simplest approach uses the mutual information as the \"derived\" score.[34]\nHowever, there are different approaches, that try to reduce the redundancy between features.\n\nMinimum-redundancy-maximum-relevance (mRMR) feature selection[edit]\nPeng et al.[35] proposed a feature selection method that can use either mutual information, correlation, or distance/similarity scores to select features. The aim is to penalise a feature's relevancy by its redundancy in the presence of the other selected features. The relevance of a feature set S for the class c is defined by the average value of all mutual information values between the individual feature fi and the class c as follows:\n\n\n\n\n\nD\n(\nS\n,\nc\n)\n=\n\n\n1\n\n\n|\n\nS\n\n|\n\n\n\n\n\n\u2211\n\n\nf\n\ni\n\n\n\u2208\nS\n\n\nI\n(\n\nf\n\ni\n\n\n;\nc\n)\n\n\n{\\displaystyle D(S,c)={\\frac {1}{|S|}}\\sum _{f_{i}\\in S}I(f_{i};c)}\n\n.\nThe redundancy of all features in the set S is the average value of all mutual information values between the feature fi and the feature fj:\n\n\n\n\n\nR\n(\nS\n)\n=\n\n\n1\n\n\n|\n\nS\n\n\n|\n\n\n2\n\n\n\n\n\n\n\u2211\n\n\nf\n\ni\n\n\n,\n\nf\n\nj\n\n\n\u2208\nS\n\n\nI\n(\n\nf\n\ni\n\n\n;\n\nf\n\nj\n\n\n)\n\n\n{\\displaystyle R(S)={\\frac {1}{|S|^{2}}}\\sum _{f_{i},f_{j}\\in S}I(f_{i};f_{j})}\n\n\nThe mRMR criterion is a combination of two measures given above and is defined as follows:\n\n\n\n\n\n\nm\nR\nM\nR\n\n=\n\nmax\n\nS\n\n\n\n[\n\n\n\n1\n\n\n|\n\nS\n\n|\n\n\n\n\n\n\u2211\n\n\nf\n\ni\n\n\n\u2208\nS\n\n\nI\n(\n\nf\n\ni\n\n\n;\nc\n)\n\u2212\n\n\n1\n\n\n|\n\nS\n\n\n|\n\n\n2\n\n\n\n\n\n\n\u2211\n\n\nf\n\ni\n\n\n,\n\nf\n\nj\n\n\n\u2208\nS\n\n\nI\n(\n\nf\n\ni\n\n\n;\n\nf\n\nj\n\n\n)\n\n]\n\n.\n\n\n{\\displaystyle \\mathrm {mRMR} =\\max _{S}\\left[{\\frac {1}{|S|}}\\sum _{f_{i}\\in S}I(f_{i};c)-{\\frac {1}{|S|^{2}}}\\sum _{f_{i},f_{j}\\in S}I(f_{i};f_{j})\\right].}\n\n\nSuppose that there are n full-set features. Let xi be the set membership indicator function for feature fi, so that xi=1 indicates presence and xi=0 indicates absence of the feature fi in the globally optimal feature set. Let \n\n\n\n\nc\n\ni\n\n\n=\nI\n(\n\nf\n\ni\n\n\n;\nc\n)\n\n\n{\\displaystyle c_{i}=I(f_{i};c)}\n\n and \n\n\n\n\na\n\ni\nj\n\n\n=\nI\n(\n\nf\n\ni\n\n\n;\n\nf\n\nj\n\n\n)\n\n\n{\\displaystyle a_{ij}=I(f_{i};f_{j})}\n\n. The above may then be written as an optimization problem:\n\n\n\n\n\n\nm\nR\nM\nR\n\n=\n\nmax\n\nx\n\u2208\n{\n0\n,\n1\n\n}\n\nn\n\n\n\n\n\n[\n\n\n\n\n\n\u2211\n\ni\n=\n1\n\n\nn\n\n\n\nc\n\ni\n\n\n\nx\n\ni\n\n\n\n\n\n\u2211\n\ni\n=\n1\n\n\nn\n\n\n\nx\n\ni\n\n\n\n\n\n\u2212\n\n\n\n\n\u2211\n\ni\n,\nj\n=\n1\n\n\nn\n\n\n\na\n\ni\nj\n\n\n\nx\n\ni\n\n\n\nx\n\nj\n\n\n\n\n(\n\n\u2211\n\ni\n=\n1\n\n\nn\n\n\n\nx\n\ni\n\n\n\n)\n\n2\n\n\n\n\n\n\n]\n\n.\n\n\n{\\displaystyle \\mathrm {mRMR} =\\max _{x\\in \\{0,1\\}^{n}}\\left[{\\frac {\\sum _{i=1}^{n}c_{i}x_{i}}{\\sum _{i=1}^{n}x_{i}}}-{\\frac {\\sum _{i,j=1}^{n}a_{ij}x_{i}x_{j}}{(\\sum _{i=1}^{n}x_{i})^{2}}}\\right].}\n\n\nThe mRMR algorithm is an approximation of the theoretically optimal maximum-dependency feature selection algorithm that maximizes the mutual information between the joint distribution of the selected features and the classification variable. As mRMR approximates the combinatorial estimation problem with a series of much smaller problems, each of which only involves two variables, it thus uses pairwise joint probabilities which are more robust. In certain situations the algorithm may underestimate the usefulness of features as it has no way to measure interactions between features which can increase relevancy. This can lead to poor performance[34] when the features are individually useless, but are useful when combined (a pathological case is found when the class is a parity function of the features). Overall the algorithm is more efficient (in terms of the amount of data required) than the theoretically optimal max-dependency selection, yet produces a feature set with little pairwise redundancy.\nmRMR is an instance of a large class of filter methods which trade off between relevancy and redundancy in different ways.[34][36]\n\nQuadratic programming feature selection[edit]\nmRMR is a typical example of an incremental greedy strategy for feature selection: once a feature has been selected, it cannot be deselected at a later stage. While mRMR could be optimized using floating search to reduce some features, it might also be reformulated as a global quadratic programming optimization problem as follows:[37]\n\n\n\n\n\n\nQ\nP\nF\nS\n\n:\n\nmin\n\n\nx\n\n\n\n\n{\n\n\u03b1\n\n\nx\n\n\nT\n\n\nH\n\nx\n\n\u2212\n\n\nx\n\n\nT\n\n\nF\n\n}\n\n\n\n\ns.t.\n\n\n\u00a0\n\n\u2211\n\ni\n=\n1\n\n\nn\n\n\n\nx\n\ni\n\n\n=\n1\n,\n\nx\n\ni\n\n\n\u2265\n0\n\n\n{\\displaystyle \\mathrm {QPFS} :\\min _{\\mathbf {x} }\\left\\{\\alpha \\mathbf {x} ^{T}H\\mathbf {x} -\\mathbf {x} ^{T}F\\right\\}\\quad {\\mbox{s.t.}}\\ \\sum _{i=1}^{n}x_{i}=1,x_{i}\\geq 0}\n\n\nwhere \n\n\n\n\nF\n\nn\n\u00d7\n1\n\n\n=\n[\nI\n(\n\nf\n\n1\n\n\n;\nc\n)\n,\n\u2026\n,\nI\n(\n\nf\n\nn\n\n\n;\nc\n)\n\n]\n\nT\n\n\n\n\n{\\displaystyle F_{n\\times 1}=[I(f_{1};c),\\ldots ,I(f_{n};c)]^{T}}\n\n is the vector of feature relevancy assuming there are n features in total, \n\n\n\n\nH\n\nn\n\u00d7\nn\n\n\n=\n[\nI\n(\n\nf\n\ni\n\n\n;\n\nf\n\nj\n\n\n)\n\n]\n\ni\n,\nj\n=\n1\n\u2026\nn\n\n\n\n\n{\\displaystyle H_{n\\times n}=[I(f_{i};f_{j})]_{i,j=1\\ldots n}}\n\n is the matrix of feature pairwise redundancy, and \n\n\n\n\n\nx\n\n\nn\n\u00d7\n1\n\n\n\n\n{\\displaystyle \\mathbf {x} _{n\\times 1}}\n\n represents relative feature weights. QPFS is solved via quadratic programming. It is recently shown that QFPS is biased towards features with smaller entropy,[38] due to its placement of the feature self redundancy term \n\n\n\nI\n(\n\nf\n\ni\n\n\n;\n\nf\n\ni\n\n\n)\n\n\n{\\displaystyle I(f_{i};f_{i})}\n\n on the diagonal of H.\n\nConditional mutual information[edit]\nAnother score derived for the mutual information is based on the conditional relevancy:[38]\n\n\n\n\n\n\nS\nP\nE\n\nC\n\nC\nM\nI\n\n\n\n:\n\nmax\n\n\nx\n\n\n\n\n{\n\n\n\nx\n\n\nT\n\n\nQ\n\nx\n\n\n}\n\n\n\n\ns.t.\n\n\n\u00a0\n\u2016\n\nx\n\n\u2016\n=\n1\n,\n\nx\n\ni\n\n\n\u2265\n0\n\n\n{\\displaystyle \\mathrm {SPEC_{CMI}} :\\max _{\\mathbf {x} }\\left\\{\\mathbf {x} ^{T}Q\\mathbf {x} \\right\\}\\quad {\\mbox{s.t.}}\\ \\|\\mathbf {x} \\|=1,x_{i}\\geq 0}\n\n\nwhere \n\n\n\n\nQ\n\ni\ni\n\n\n=\nI\n(\n\nf\n\ni\n\n\n;\nc\n)\n\n\n{\\displaystyle Q_{ii}=I(f_{i};c)}\n\n and \n\n\n\n\nQ\n\ni\nj\n\n\n=\n(\nI\n(\n\nf\n\ni\n\n\n;\nc\n\n|\n\n\nf\n\nj\n\n\n)\n+\nI\n(\n\nf\n\nj\n\n\n;\nc\n\n|\n\n\nf\n\ni\n\n\n)\n)\n\n/\n\n2\n,\ni\n\u2260\nj\n\n\n{\\displaystyle Q_{ij}=(I(f_{i};c|f_{j})+I(f_{j};c|f_{i}))/2,i\\neq j}\n\n.\nAn advantage of SPECCMI is that it can be solved simply via finding the dominant eigenvector of Q, thus is very scalable. SPECCMI also handles second-order feature interaction.\n\nJoint mutual information[edit]\nIn a study of different scores Brown et al.[34]  recommended the joint mutual information[39] as a good score for feature selection. The score tries to find the feature, that adds the most new information to the already selected features, in order to avoid redundancy. The score is formulated as follows:\n\n\n\n\n\n\n\n\n\nJ\nM\nI\n(\n\nf\n\ni\n\n\n)\n\n\n\n=\n\n\u2211\n\n\nf\n\nj\n\n\n\u2208\nS\n\n\n(\nI\n(\n\nf\n\ni\n\n\n;\nc\n)\n+\nI\n(\n\nf\n\ni\n\n\n;\nc\n\n|\n\n\nf\n\nj\n\n\n)\n)\n\n\n\n\n\n\n=\n\n\u2211\n\n\nf\n\nj\n\n\n\u2208\nS\n\n\n\n\n[\n\n\nI\n(\n\nf\n\nj\n\n\n;\nc\n)\n+\nI\n(\n\nf\n\ni\n\n\n;\nc\n)\n\u2212\n\n\n(\n\n\nI\n(\n\nf\n\ni\n\n\n;\n\nf\n\nj\n\n\n)\n\u2212\nI\n(\n\nf\n\ni\n\n\n;\n\nf\n\nj\n\n\n\n|\n\nc\n)\n\n\n)\n\n\n\n\n]\n\n\n\n\n\n\n\n\n{\\displaystyle {\\begin{aligned}JMI(f_{i})&=\\sum _{f_{j}\\in S}(I(f_{i};c)+I(f_{i};c|f_{j}))\\\\&=\\sum _{f_{j}\\in S}{\\bigl [}I(f_{j};c)+I(f_{i};c)-{\\bigl (}I(f_{i};f_{j})-I(f_{i};f_{j}|c){\\bigr )}{\\bigr ]}\\end{aligned}}}\n\n\nThe score uses the conditional mutual information and the mutual information to estimate the redundancy between the already selected features (\n\n\n\n\nf\n\nj\n\n\n\u2208\nS\n\n\n{\\displaystyle f_{j}\\in S}\n\n) and the feature under investigation (\n\n\n\n\nf\n\ni\n\n\n\n\n{\\displaystyle f_{i}}\n\n).\n\nHilbert-Schmidt Independence Criterion Lasso based feature selection[edit]\nFor high-dimensional and small sample data (e.g., dimensionality > 105 and the number of samples < 103), the Hilbert-Schmidt Independence Criterion Lasso (HSIC Lasso) is useful.[40] HSIC Lasso optimization problem is given as\n\n\n\n\n\n\nH\nS\nI\n\nC\n\nL\na\ns\ns\no\n\n\n\n:\n\nmin\n\n\nx\n\n\n\n\n\n1\n2\n\n\n\n\u2211\n\nk\n,\nl\n=\n1\n\n\nn\n\n\n\nx\n\nk\n\n\n\nx\n\nl\n\n\n\n\nHSIC\n\n\n(\n\nf\n\nk\n\n\n,\n\nf\n\nl\n\n\n)\n\u2212\n\n\u2211\n\nk\n=\n1\n\n\nn\n\n\n\nx\n\nk\n\n\n\n\nHSIC\n\n\n(\n\nf\n\nk\n\n\n,\nc\n)\n+\n\u03bb\n\u2016\n\nx\n\n\n\u2016\n\n1\n\n\n,\n\n\n\ns.t.\n\n\n\u00a0\n\nx\n\n1\n\n\n,\n\u2026\n,\n\nx\n\nn\n\n\n\u2265\n0\n,\n\n\n{\\displaystyle \\mathrm {HSIC_{Lasso}} :\\min _{\\mathbf {x} }{\\frac {1}{2}}\\sum _{k,l=1}^{n}x_{k}x_{l}{\\mbox{HSIC}}(f_{k},f_{l})-\\sum _{k=1}^{n}x_{k}{\\mbox{HSIC}}(f_{k},c)+\\lambda \\|\\mathbf {x} \\|_{1},\\quad {\\mbox{s.t.}}\\ x_{1},\\ldots ,x_{n}\\geq 0,}\n\n\nwhere \n\n\n\n\n\nHSIC\n\n\n(\n\nf\n\nk\n\n\n,\nc\n)\n=\n\n\ntr\n\n\n(\n\n\n\n\n\nK\n\n\u00af\n\n\n\n\n(\nk\n)\n\n\n\n\n\n\nL\n\n\u00af\n\n\n\n)\n\n\n{\\displaystyle {\\mbox{HSIC}}(f_{k},c)={\\mbox{tr}}({\\bar {\\mathbf {K} }}^{(k)}{\\bar {\\mathbf {L} }})}\n\n is a kernel-based independence measure called the (empirical) Hilbert-Schmidt independence criterion (HSIC), \n\n\n\n\n\ntr\n\n\n(\n\u22c5\n)\n\n\n{\\displaystyle {\\mbox{tr}}(\\cdot )}\n\n denotes the trace, \n\n\n\n\u03bb\n\n\n{\\displaystyle \\lambda }\n\n is the regularization parameter, \n\n\n\n\n\n\n\n\nK\n\n\u00af\n\n\n\n\n(\nk\n)\n\n\n=\n\n\u0393\n\n\n\nK\n\n\n(\nk\n)\n\n\n\n\u0393\n\n\n\n{\\displaystyle {\\bar {\\mathbf {K} }}^{(k)}=\\mathbf {\\Gamma } \\mathbf {K} ^{(k)}\\mathbf {\\Gamma } }\n\n and \n\n\n\n\n\n\n\nL\n\n\u00af\n\n\n\n=\n\n\u0393\n\n\nL\n\n\n\u0393\n\n\n\n{\\displaystyle {\\bar {\\mathbf {L} }}=\\mathbf {\\Gamma } \\mathbf {L} \\mathbf {\\Gamma } }\n\n are input and output centered Gram matrices, \n\n\n\n\nK\n\ni\n,\nj\n\n\n(\nk\n)\n\n\n=\nK\n(\n\nu\n\nk\n,\ni\n\n\n,\n\nu\n\nk\n,\nj\n\n\n)\n\n\n{\\displaystyle K_{i,j}^{(k)}=K(u_{k,i},u_{k,j})}\n\n and \n\n\n\n\nL\n\ni\n,\nj\n\n\n=\nL\n(\n\nc\n\ni\n\n\n,\n\nc\n\nj\n\n\n)\n\n\n{\\displaystyle L_{i,j}=L(c_{i},c_{j})}\n\n are Gram matrices, \n\n\n\nK\n(\nu\n,\n\nu\n\u2032\n\n)\n\n\n{\\displaystyle K(u,u')}\n\n and \n\n\n\nL\n(\nc\n,\n\nc\n\u2032\n\n)\n\n\n{\\displaystyle L(c,c')}\n\n are kernel functions, \n\n\n\n\n\u0393\n\n=\n\n\nI\n\n\nm\n\n\n\u2212\n\n\n1\nm\n\n\n\n\n1\n\n\nm\n\n\n\n\n1\n\n\nm\n\n\nT\n\n\n\n\n{\\displaystyle \\mathbf {\\Gamma } =\\mathbf {I} _{m}-{\\frac {1}{m}}\\mathbf {1} _{m}\\mathbf {1} _{m}^{T}}\n\n is the centering matrix, \n\n\n\n\n\nI\n\n\nm\n\n\n\n\n{\\displaystyle \\mathbf {I} _{m}}\n\n is the m-dimensional identity matrix (m: the number of samples), \n\n\n\n\n\n1\n\n\nm\n\n\n\n\n{\\displaystyle \\mathbf {1} _{m}}\n\n is the m-dimensional vector with all ones, and  \n\n\n\n\u2016\n\u22c5\n\n\u2016\n\n1\n\n\n\n\n{\\displaystyle \\|\\cdot \\|_{1}}\n\n is the \n\n\n\n\n\u2113\n\n1\n\n\n\n\n{\\displaystyle \\ell _{1}}\n\n-norm.  HSIC always takes a non-negative value, and is zero if and only if two random variables are statistically independent when a universal reproducing kernel such as the Gaussian kernel is used.\nThe HSIC Lasso can be written as\n\n\n\n\n\n\nH\nS\nI\n\nC\n\nL\na\ns\ns\no\n\n\n\n:\n\nmin\n\n\nx\n\n\n\n\n\n1\n2\n\n\n\n\n\u2016\n\n\n\n\n\nL\n\n\u00af\n\n\n\n\u2212\n\n\u2211\n\nk\n=\n1\n\n\nn\n\n\n\nx\n\nk\n\n\n\n\n\n\n\nK\n\n\u00af\n\n\n\n\n(\nk\n)\n\n\n\n\u2016\n\n\nF\n\n\n2\n\n\n+\n\u03bb\n\u2016\n\nx\n\n\n\u2016\n\n1\n\n\n,\n\n\n\ns.t.\n\n\n\u00a0\n\nx\n\n1\n\n\n,\n\u2026\n,\n\nx\n\nn\n\n\n\u2265\n0\n,\n\n\n{\\displaystyle \\mathrm {HSIC_{Lasso}} :\\min _{\\mathbf {x} }{\\frac {1}{2}}\\left\\|{\\bar {\\mathbf {L} }}-\\sum _{k=1}^{n}x_{k}{\\bar {\\mathbf {K} }}^{(k)}\\right\\|_{F}^{2}+\\lambda \\|\\mathbf {x} \\|_{1},\\quad {\\mbox{s.t.}}\\ x_{1},\\ldots ,x_{n}\\geq 0,}\n\n\nwhere \n\n\n\n\u2016\n\u22c5\n\n\u2016\n\nF\n\n\n\n\n{\\displaystyle \\|\\cdot \\|_{F}}\n\n is the Frobenius norm. The optimization problem is a Lasso problem, and thus it can be efficiently solved with a state-of-the-art Lasso solver such as the dual augmented Lagrangian method.\n\nCorrelation feature selection[edit]\nThe correlation feature selection (CFS) measure evaluates subsets of features on the basis of the following hypothesis: \"Good feature subsets contain features highly correlated with the classification, yet uncorrelated to each other\".[41][42] The following equation gives the merit of a feature subset S consisting of k features:\n\n\n\n\n\n\n\nM\ne\nr\ni\nt\n\n\n\nS\n\nk\n\n\n\n\n=\n\n\n\nk\n\n\n\nr\n\nc\nf\n\n\n\u00af\n\n\n\n\nk\n+\nk\n(\nk\n\u2212\n1\n)\n\n\n\nr\n\nf\nf\n\n\n\u00af\n\n\n\n\n\n.\n\n\n{\\displaystyle \\mathrm {Merit} _{S_{k}}={\\frac {k{\\overline {r_{cf}}}}{\\sqrt {k+k(k-1){\\overline {r_{ff}}}}}}.}\n\n\nHere, \n\n\n\n\n\n\nr\n\nc\nf\n\n\n\u00af\n\n\n\n\n{\\displaystyle {\\overline {r_{cf}}}}\n\n is the average value of all feature-classification correlations, and \n\n\n\n\n\n\nr\n\nf\nf\n\n\n\u00af\n\n\n\n\n{\\displaystyle {\\overline {r_{ff}}}}\n\n is the average value of all feature-feature correlations. The CFS criterion is defined as follows:\n\n\n\n\n\n\nC\nF\nS\n\n=\n\nmax\n\n\nS\n\nk\n\n\n\n\n\n[\n\n\n\n\nr\n\nc\n\nf\n\n1\n\n\n\n\n+\n\nr\n\nc\n\nf\n\n2\n\n\n\n\n+\n\u22ef\n+\n\nr\n\nc\n\nf\n\nk\n\n\n\n\n\n\nk\n+\n2\n(\n\nr\n\n\nf\n\n1\n\n\n\nf\n\n2\n\n\n\n\n+\n\u22ef\n+\n\nr\n\n\nf\n\ni\n\n\n\nf\n\nj\n\n\n\n\n+\n\u22ef\n+\n\nr\n\n\nf\n\nk\n\n\n\nf\n\nk\n\u2212\n1\n\n\n\n\n)\n\n\n\n]\n\n.\n\n\n{\\displaystyle \\mathrm {CFS} =\\max _{S_{k}}\\left[{\\frac {r_{cf_{1}}+r_{cf_{2}}+\\cdots +r_{cf_{k}}}{\\sqrt {k+2(r_{f_{1}f_{2}}+\\cdots +r_{f_{i}f_{j}}+\\cdots +r_{f_{k}f_{k-1}})}}}\\right].}\n\n\nThe \n\n\n\n\nr\n\nc\n\nf\n\ni\n\n\n\n\n\n\n{\\displaystyle r_{cf_{i}}}\n\n and \n\n\n\n\nr\n\n\nf\n\ni\n\n\n\nf\n\nj\n\n\n\n\n\n\n{\\displaystyle r_{f_{i}f_{j}}}\n\n variables are referred to as correlations, but are not necessarily Pearson's correlation coefficient or Spearman's \u03c1. Hall's dissertation uses neither of these, but uses three different measures of relatedness, minimum description length (MDL), symmetrical uncertainty, and relief.\nLet xi be the set membership indicator function for feature fi; then the above can be rewritten as an optimization problem:\n\n\n\n\n\n\nC\nF\nS\n\n=\n\nmax\n\nx\n\u2208\n{\n0\n,\n1\n\n}\n\nn\n\n\n\n\n\n[\n\n\n\n(\n\n\u2211\n\ni\n=\n1\n\n\nn\n\n\n\na\n\ni\n\n\n\nx\n\ni\n\n\n\n)\n\n2\n\n\n\n\n\n\u2211\n\ni\n=\n1\n\n\nn\n\n\n\nx\n\ni\n\n\n+\n\n\u2211\n\ni\n\u2260\nj\n\n\n2\n\nb\n\ni\nj\n\n\n\nx\n\ni\n\n\n\nx\n\nj\n\n\n\n\n\n]\n\n.\n\n\n{\\displaystyle \\mathrm {CFS} =\\max _{x\\in \\{0,1\\}^{n}}\\left[{\\frac {(\\sum _{i=1}^{n}a_{i}x_{i})^{2}}{\\sum _{i=1}^{n}x_{i}+\\sum _{i\\neq j}2b_{ij}x_{i}x_{j}}}\\right].}\n\n\nThe combinatorial problems above are, in fact, mixed 0\u20131 linear programming problems that can be solved by using branch-and-bound algorithms.[43]\n\nRegularized trees[edit]\nThe features from a decision tree or a tree ensemble are shown to be redundant. A recent method called regularized tree[44] can be used for feature subset selection. Regularized trees penalize using a variable similar to the variables selected at previous tree nodes for splitting the current node. Regularized trees only need build one tree model (or one tree ensemble model) and thus are computationally efficient.\nRegularized trees naturally handle numerical and categorical features, interactions and nonlinearities. They are invariant to attribute scales (units) and insensitive to outliers, and thus, require little data preprocessing such as normalization. Regularized random forest (RRF)[45] is one type of regularized trees. The guided RRF is an enhanced RRF which is guided by the importance scores from an ordinary random forest.\n\nOverview on metaheuristics methods[edit]\nA metaheuristic is a general description of an algorithm dedicated to solve difficult (typically NP-hard problem) optimization problems for which there is no classical solving methods. Generally, a metaheuristic is a stochastic algorithm tending to reach a global optimum. There are many metaheuristics, from a simple local search to a complex global search algorithm.\n\nMain principles[edit]\nThe feature selection methods are typically presented in three classes based on how they combine the selection algorithm and the model building.\n\nFilter method[edit]\nFilter Method for feature selection\nFilter type methods select variables regardless of the model. They are based only on general features like the correlation with the variable to predict. Filter methods suppress the least interesting variables. The other variables will be part of a classification or a regression model used to classify or to predict data. These methods are particularly effective in computation time and robust to overfitting.[46]\nFilter methods tend to select redundant variables when they do not consider the relationships between variables. However, more elaborate features try to minimize this problem by removing variables highly correlated to each other, such as the Fast Correlation Based Filter (FCBF) algorithm.[47]\n\nWrapper method[edit]\nWrapper Method for Feature selection\nWrapper methods evaluate subsets of variables which allows, unlike filter approaches, to detect the possible interactions amongst variables.[48] The two main disadvantages of these methods are: \n\nThe increasing overfitting risk when the number of observations is insufficient.\nThe significant computation time when the number of variables is large.\nEmbedded method[edit]\nEmbedded method for Feature selection\nEmbedded methods have been recently proposed that try to combine the advantages of both previous methods. A learning algorithm takes advantage of its own variable selection process and performs feature selection and classification simultaneously, such as the FRMT algorithm.[49]\n\nApplication of feature selection metaheuristics[edit]\nThis is a survey of the application of feature selection metaheuristics lately used in the literature. This survey was realized by J. Hammon in her 2013 thesis.[46]\n\n\n\nApplication\nAlgorithm\nApproach\nClassifier\nEvaluation Function\nReference\n\n\nSNPs\nFeature Selection using Feature Similarity\nFilter\n\nr2\nPhuong 2005[48]\n\n\nSNPs\nGenetic algorithm\nWrapper\nDecision Tree\nClassification accuracy (10-fold)\nShah 2004[50]\n\n\nSNPs\nHill climbing\nFilter + Wrapper\nNaive Bayesian\nPredicted residual sum of squares\nLong 2007[51]\n\n\nSNPs\nSimulated annealing\n\nNaive bayesian\nClassification accuracy (5-fold)\nUstunkar 2011[52]\n\n\nSegments parole\nAnt colony\nWrapper\nArtificial Neural Network\nMSE\nAl-ani 2005 [citation needed]\n\n\nMarketing\nSimulated annealing\nWrapper\nRegression\nAIC, r2\nMeiri 2006[53]\n\n\nEconomics\nSimulated annealing, genetic algorithm\nWrapper\nRegression\nBIC\nKapetanios 2007[54]\n\n\nSpectral Mass\nGenetic algorithm\nWrapper\nMultiple Linear Regression, Partial Least Squares\nroot-mean-square error of prediction\nBroadhurst et al. 1997[55]\n\n\nSpam\nBinary PSO + Mutation\nWrapper\nDecision tree\nweighted cost\nZhang 2014[24]\n\n\nMicroarray\nTabu search + PSO\nWrapper\nSupport Vector Machine, K Nearest Neighbors\nEuclidean Distance\nChuang 2009[56]\n\n\nMicroarray\nPSO + Genetic algorithm\nWrapper\nSupport Vector Machine\nClassification accuracy (10-fold)\nAlba 2007[57]\n\n\nMicroarray\nGenetic algorithm + Iterated Local Search\nEmbedded\nSupport Vector Machine\nClassification accuracy (10-fold)\nDuval 2009[58]\n\n\nMicroarray\nIterated local search\nWrapper\nRegression\nPosterior Probability\nHans 2007[59]\n\n\nMicroarray\nGenetic algorithm\nWrapper\nK Nearest Neighbors\nClassification accuracy (Leave-one-out cross-validation)\nJirapech-Umpai 2005[60]\n\n\nMicroarray\nHybrid genetic algorithm\nWrapper\nK Nearest Neighbors\nClassification accuracy (Leave-one-out cross-validation)\nOh 2004[61]\n\n\nMicroarray\nGenetic algorithm\nWrapper\nSupport Vector Machine\nSensitivity and specificity\nXuan 2011[62]\n\n\nMicroarray\nGenetic algorithm\nWrapper\nAll paired Support Vector Machine\nClassification accuracy (Leave-one-out cross-validation)\nPeng 2003[63]\n\n\nMicroarray\nGenetic algorithm\nEmbedded\nSupport Vector Machine\nClassification accuracy (10-fold)\nHernandez 2007[64]\n\n\nMicroarray\nGenetic algorithm\nHybrid\nSupport Vector Machine\nClassification accuracy (Leave-one-out cross-validation)\nHuerta 2006[65]\n\n\nMicroarray\nGenetic algorithm\n\nSupport Vector Machine\nClassification accuracy (10-fold)\nMuni 2006[66]\n\n\nMicroarray\nGenetic algorithm\nWrapper\nSupport Vector Machine\nEH-DIALL, CLUMP\nJourdan 2005[67]\n\n\nAlzheimer's disease\nWelch's t-test\nFilter\nSupport vector machine\nClassification accuracy (10-fold)\nZhang 2015[68]\n\n\nComputer vision\n\nInfinite Feature Selection\n\nFilter\n\nIndependent\n\nAverage Precision, ROC AUC\n\nRoffo 2015[69]\n\n\nMicroarrays\n\nEigenvector Centrality FS\n\nFilter\n\nIndependent\n\nAverage Precision, Accuracy, ROC AUC\n\nRoffo & Melzi 2016[70]\n\n\nXML\n\nSymmetrical Tau (ST)\n\nFilter\n\nStructural Associative Classification\n\nAccuracy, Coverage\n\nShaharanee & Hadzic 2014\n\nFeature selection embedded in learning algorithms[edit]\nSome learning algorithms perform feature selection as part of their overall operation. These include:\n\n\u2060\n\n\n\n\nl\n\n1\n\n\n\n\n{\\displaystyle l_{1}}\n\n\u2060-regularization techniques, such as sparse regression, LASSO, and \u2060\n\n\n\n\nl\n\n1\n\n\n\n\n{\\displaystyle l_{1}}\n\n\u2060-SVM\nRegularized trees,[44] e.g. regularized random forest implemented in the RRF package[45]\nDecision tree[71]\nMemetic algorithm\nRandom multinomial logit (RMNL)\nAuto-encoding networks with a bottleneck-layer\nSubmodular feature selection[72][73][74]\nLocal learning based feature selection.[75] Compared with traditional methods, it does not involve any heuristic search, can easily handle multi-class problems, and works for both linear and nonlinear problems. It is also supported by a strong theoretical foundation. Numeric experiments showed that the method can achieve a close-to-optimal solution even when data contains >1M irrelevant features.\nRecommender system based on feature selection.[76] The feature selection methods are introduced into recommender system research.\nSee also[edit]\nCluster analysis\nData mining\nDimensionality reduction\nFeature extraction\nHyperparameter optimization\nModel selection\nRelief (feature selection)\nReferences[edit]\n\n\n^ Gareth James; Daniela Witten; Trevor Hastie; Robert Tibshirani (2013). An Introduction to Statistical Learning. Springer. p.\u00a0204.\n\n^ Brank, Janez; Mladeni\u0107, Dunja; Grobelnik, Marko; Liu, Huan; Mladeni\u0107, Dunja; Flach, Peter A.; Garriga, Gemma C.; Toivonen, Hannu; Toivonen, Hannu (2011), \"Feature Selection\", in Sammut, Claude; Webb, Geoffrey I. (eds.), Encyclopedia of Machine Learning, Boston, MA: Springer US, pp.\u00a0402\u2013406, doi:10.1007/978-0-387-30164-8_306, ISBN\u00a0978-0-387-30768-8, retrieved 2021-07-13\n\n^ Kramer, Mark A. (1991). \"Nonlinear principal component analysis using autoassociative neural networks\". AIChE Journal. 37 (2): 233\u2013243. Bibcode:1991AIChE..37..233K. doi:10.1002/aic.690370209. ISSN\u00a01547-5905.\n\n^ Kratsios, Anastasis; Hyndman, Cody (2021). \"NEU: A Meta-Algorithm for Universal UAP-Invariant Feature Representation\". Journal of Machine Learning Research. 22 (92): 1\u201351. ISSN\u00a01533-7928.\n\n^ Persello, Claudio; Bruzzone, Lorenzo (July 2014). \"Relevant and invariant feature selection of hyperspectral images for domain generalization\". 2014 IEEE Geoscience and Remote Sensing Symposium (PDF). IEEE. pp.\u00a03562\u20133565. doi:10.1109/igarss.2014.6947252. ISBN\u00a0978-1-4799-5775-0. S2CID\u00a08368258.\n\n^ Hinkle, Jacob; Muralidharan, Prasanna; Fletcher, P. Thomas; Joshi, Sarang (2012). \"Polynomial Regression on Riemannian Manifolds\". In Fitzgibbon, Andrew; Lazebnik, Svetlana; Perona, Pietro; Sato, Yoichi; Schmid, Cordelia (eds.). Computer Vision \u2013 ECCV 2012. Lecture Notes in Computer Science. Vol.\u00a07574. Berlin, Heidelberg: Springer. pp.\u00a01\u201314. arXiv:1201.2395. doi:10.1007/978-3-642-33712-3_1. ISBN\u00a0978-3-642-33712-3. S2CID\u00a08849753.\n\n^ Yarotsky, Dmitry (2021-04-30). \"Universal Approximations of Invariant Maps by Neural Networks\". Constructive Approximation. 55: 407\u2013474. arXiv:1804.10306. doi:10.1007/s00365-021-09546-1. ISSN\u00a01432-0940. S2CID\u00a013745401.\n\n^ Hauberg, S\u00f8ren; Lauze, Fran\u00e7ois; Pedersen, Kim Steenstrup (2013-05-01). \"Unscented Kalman Filtering on Riemannian Manifolds\". Journal of Mathematical Imaging and Vision. 46 (1): 103\u2013120. Bibcode:2013JMIV...46..103H. doi:10.1007/s10851-012-0372-9. ISSN\u00a01573-7683. S2CID\u00a08501814.\n\n^ Kratsios, Anastasis; Hyndman, Cody (June 8, 2021). \"NEU: A Meta-Algorithm for Universal UAP-Invariant Feature Representation\". Journal of Machine Learning Research. 22: 10312. Bibcode:2015NatSR...510312B. doi:10.1038/srep10312. PMC\u00a04437376. PMID\u00a025988841.\n\n^ a b c Guyon, Isabelle; Elisseeff, Andr\u00e9 (2003). \"An Introduction to Variable and Feature Selection\". JMLR. 3.\n\n^ a b Yang, Yiming; Pedersen, Jan O. (1997). A comparative study on feature selection in text categorization (PDF). ICML.\n\n^ Urbanowicz, Ryan J.; Meeker, Melissa; LaCava, William; Olson, Randal S.; Moore, Jason H. (2018). \"Relief-Based Feature Selection: Introduction and Review\". Journal of Biomedical Informatics. 85: 189\u2013203. arXiv:1711.08421. doi:10.1016/j.jbi.2018.07.014. PMC\u00a06299836. PMID\u00a030031057.\n\n^ Forman, George (2003). \"An extensive empirical study of feature selection metrics for text classification\" (PDF). Journal of Machine Learning Research. 3: 1289\u20131305.\n\n^ Yishi Zhang; Shujuan Li; Teng Wang; Zigang Zhang (2013). \"Divergence-based feature selection for separate classes\". Neurocomputing. 101 (4): 32\u201342. doi:10.1016/j.neucom.2012.06.036.\n\n^ Guyon I.; Weston J.; Barnhill S.; Vapnik V. (2002). \"Gene selection for cancer classification using support vector machines\". Machine Learning. 46 (1\u20133): 389\u2013422. doi:10.1023/A:1012487302797.\n\n^ Bach, Francis R (2008). \"Bolasso\". Proceedings of the 25th international conference on Machine learning - ICML '08. pp.\u00a033\u201340. doi:10.1145/1390156.1390161. ISBN\u00a09781605582054. S2CID\u00a0609778.\n\n^ Zare, Habil (2013). \"Scoring relevancy of features based on combinatorial analysis of Lasso with application to lymphoma diagnosis\". BMC Genomics. 14 (Suppl 1): S14. doi:10.1186/1471-2164-14-S1-S14. PMC\u00a03549810. PMID\u00a023369194.\n\n^ Kai Han; Yunhe Wang; Chao Zhang; Chao Li; Chao Xu (2018). Autoencoder inspired unsupervised feature selection. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).\n\n^ Hazimeh, Hussein; Mazumder, Rahul; Saab, Ali (2020). \"Sparse Regression at Scale: Branch-and-Bound rooted in First-Order Optimization\". arXiv:2004.06152 [stat.CO].\n\n^ Soufan, Othman; Kleftogiannis, Dimitrios; Kalnis, Panos; Bajic, Vladimir B. (2015-02-26). \"DWFS: A Wrapper Feature Selection Tool Based on a Parallel Genetic Algorithm\". PLOS ONE. 10 (2): e0117988. Bibcode:2015PLoSO..1017988S. doi:10.1371/journal.pone.0117988. ISSN\u00a01932-6203. PMC\u00a04342225. PMID\u00a025719748.\n\n^ Figueroa, Alejandro (2015). \"Exploring effective features for recognizing the user intent behind web queries\". Computers in Industry. 68: 162\u2013169. doi:10.1016/j.compind.2015.01.005.\n\n^ Figueroa, Alejandro; Guenter Neumann (2013). Learning to Rank Effective Paraphrases from Query Logs for Community Question Answering. AAAI.\n\n^ Figueroa, Alejandro; Guenter Neumann (2014). \"Category-specific models for ranking effective paraphrases in community Question Answering\". Expert Systems with Applications. 41 (10): 4730\u20134742. doi:10.1016/j.eswa.2014.02.004. hdl:10533/196878.\n\n^ a b Zhang, Y.; Wang, S.; Phillips, P. (2014). \"Binary PSO with Mutation Operator for Feature Selection using Decision Tree applied to Spam Detection\". Knowledge-Based Systems. 64: 22\u201331. doi:10.1016/j.knosys.2014.03.015.\n\n^ F.C. Garcia-Lopez, M. Garcia-Torres, B. Melian, J.A. Moreno-Perez, J.M. Moreno-Vega. Solving feature subset selection problem by a Parallel Scatter Search, European Journal of Operational Research, vol. 169, no. 2, pp. 477\u2013489, 2006.\n\n^ Garc\u00eda-Torres, Miguel; G\u00f3mez-Vela, Francisco; Divina, Federico; Pinto-Roa, Diego P.; Noguera, Jos\u00e9 Luis V\u00e1zquez; Rom\u00e1n, Julio C. Mello (2021). \"Scatter search for high-dimensional feature selection using feature grouping\". Proceedings of the Genetic and Evolutionary Computation Conference Companion. pp.\u00a0149\u2013150. doi:10.1145/3449726.3459481. ISBN\u00a09781450383516. S2CID\u00a0235770316.\n\n^ F.C. Garcia-Lopez, M. Garcia-Torres, B. Melian, J.A. Moreno-Perez, J.M. Moreno-Vega. Solving Feature Subset Selection Problem by a Hybrid Metaheuristic. In First International Workshop on Hybrid Metaheuristics, pp. 59\u201368, 2004.\n\n^ M. Garcia-Torres, F. Gomez-Vela, B. Melian, J.M. Moreno-Vega. High-dimensional feature selection via feature grouping: A Variable Neighborhood Search approach, Information Sciences, vol. 326, pp. 102-118, 2016.\n\n^ Kraskov, Alexander; St\u00f6gbauer, Harald; Andrzejak, Ralph G; Grassberger, Peter (2003). \"Hierarchical Clustering Based on Mutual Information\". arXiv:q-bio/0311039. Bibcode:2003q.bio....11039K. {{cite journal}}: Cite journal requires |journal= (help)\n\n^ Akaike, H. (1985), \"Prediction and entropy\", in Atkinson, A. C.; Fienberg, S. E. (eds.), A Celebration of Statistics (PDF), Springer, pp.\u00a01\u201324, archived (PDF) from the original on August 30, 2019.\n\n^ Burnham, K. P.; Anderson, D. R. (2002), Model Selection and Multimodel Inference: A practical information-theoretic approach (2nd\u00a0ed.), Springer-Verlag, ISBN\u00a09780387953649.\n\n^ Einicke, G. A. (2018). \"Maximum-Entropy Rate Selection of Features for Classifying Changes in Knee and Ankle Dynamics During Running\". IEEE Journal of Biomedical and Health Informatics. 28 (4): 1097\u20131103. doi:10.1109/JBHI.2017.2711487. hdl:10810/68978. PMID\u00a029969403. S2CID\u00a049555941.\n\n^ Aliferis, Constantin (2010). \"Local causal and markov blanket induction for causal discovery and feature selection for classification part I: Algorithms and empirical evaluation\" (PDF). Journal of Machine Learning Research. 11: 171\u2013234.\n\n^ a b c d Brown, Gavin; Pocock, Adam; Zhao, Ming-Jie; Luj\u00e1n, Mikel (2012). \"Conditional Likelihood Maximisation: A Unifying Framework for Information Theoretic Feature Selection\". Journal of Machine Learning Research. 13: 27\u201366.[1]\n\n^ Peng, H. C.; Long, F.; Ding, C. (2005). \"Feature selection based on mutual information: criteria of max-dependency, max-relevance, and min-redundancy\". IEEE Transactions on Pattern Analysis and Machine Intelligence. 27 (8): 1226\u20131238. CiteSeerX\u00a010.1.1.63.5765. doi:10.1109/TPAMI.2005.159. PMID\u00a016119262. S2CID\u00a0206764015. Program\n\n^ Nguyen, H., Franke, K., Petrovic, S. (2010). \"Towards a Generic Feature-Selection Measure for Intrusion Detection\", In Proc. International Conference on Pattern Recognition (ICPR), Istanbul, Turkey. [2]\n\n^ Rodriguez-Lujan, I.; Huerta, R.; Elkan, C.; Santa Cruz, C. (2010). \"Quadratic programming feature selection\" (PDF). JMLR. 11: 1491\u20131516.\n\n^ a b Nguyen X. Vinh, Jeffrey Chan, Simone Romano and James Bailey, \"Effective Global Approaches for Mutual Information based Feature Selection\". Proceedings of the 20th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD'14), August 24\u201327, New York City, 2014. \"[3]\"\n\n^ Yang, Howard Hua; Moody, John (2000). \"Data visualization and feature selection: New algorithms for nongaussian data\" (PDF). Advances in Neural Information Processing Systems: 687\u2013693.\n\n^ Yamada, M.; Jitkrittum, W.; Sigal, L.; Xing, E. P.; Sugiyama, M. (2014). \"High-Dimensional Feature Selection by Feature-Wise Non-Linear Lasso\". Neural Computation. 26 (1): 185\u2013207. arXiv:1202.0515. doi:10.1162/NECO_a_00537. PMID\u00a024102126. S2CID\u00a02742785.\n\n^ Hall, M. (1999). Correlation-based Feature Selection for Machine Learning (PDF) (PhD thesis). University of Waikato.\n\n^ Senliol, Baris; et\u00a0al. (2008). \"Fast Correlation Based Filter (FCBF) with a different search strategy\". 2008 23rd International Symposium on Computer and Information Sciences. pp.\u00a01\u20134. doi:10.1109/ISCIS.2008.4717949. ISBN\u00a0978-1-4244-2880-9. S2CID\u00a08398495.\n\n^ Nguyen, Hai; Franke, Katrin; Petrovic, Slobodan (December 2009). \"Optimizing a class of feature selection measures\". Proceedings of the NIPS 2009 Workshop on Discrete Optimization in Machine Learning: Submodularity, Sparsity & Polyhedra (DISCML). Vancouver, Canada.\n\n^ a b H. Deng, G. Runger, \"Feature Selection via Regularized Trees\", Proceedings of the 2012 International Joint Conference on Neural Networks (IJCNN), IEEE, 2012\n\n^ a b RRF: Regularized Random Forest, R package on CRAN\n\n^ a b Hamon, Julie (November 2013). Optimisation combinatoire pour la s\u00e9lection de variables en r\u00e9gression en grande dimension: Application en g\u00e9n\u00e9tique animale (Thesis) (in French). Lille University of Science and Technology.\n\n^ Yu, Lei; Liu, Huan (August 2003). \"Feature selection for high-dimensional data: a fast correlation-based filter solution\" (PDF). ICML'03: Proceedings of the Twentieth International Conference on International Conference on Machine Learning: 856\u2013863.\n\n^ a b T. M. Phuong, Z. Lin et R. B. Altman. Choosing SNPs using feature selection. Archived 2016-09-13 at the Wayback Machine Proceedings / IEEE Computational Systems Bioinformatics Conference, CSB. IEEE Computational Systems Bioinformatics Conference, pages 301-309, 2005. PMID\u00a016447987.\n\n^ Saghapour, E.; Kermani, S.; Sehhati, M. (2017). \"A novel feature ranking method for prediction of cancer stages using proteomics data\". PLOS ONE. 12 (9): e0184203. Bibcode:2017PLoSO..1284203S. doi:10.1371/journal.pone.0184203. PMC\u00a05608217. PMID\u00a028934234.\n\n^ Shah, S. C.; Kusiak, A. (2004). \"Data mining and genetic algorithm based gene/SNP selection\". Artificial Intelligence in Medicine. 31 (3): 183\u2013196. doi:10.1016/j.artmed.2004.04.002. PMID\u00a015302085.\n\n^ Long, N.; Gianola, D.; Weigel, K. A (2011). \"Dimension reduction and variable selection for genomic selection: application to predicting milk yield in Holsteins\". Journal of Animal Breeding and Genetics. 128 (4): 247\u2013257. doi:10.1111/j.1439-0388.2011.00917.x. PMID\u00a021749471.\n\n^ \u00dcst\u00fcnkar, G\u00fcrkan; \u00d6z\u00f6\u011f\u00fcr-Aky\u00fcz, S\u00fcreyya; Weber, Gerhard W.; Friedrich, Christoph M.; Ayd\u0131n Son, Ye\u015fim (2012). \"Selection of representative SNP sets for genome-wide association studies: A metaheuristic approach\". Optimization Letters. 6 (6): 1207\u20131218. doi:10.1007/s11590-011-0419-7. S2CID\u00a08075318.\n\n^ Meiri, R.; Zahavi, J. (2006). \"Using simulated annealing to optimize the feature selection problem in marketing applications\". European Journal of Operational Research. 171 (3): 842\u2013858. doi:10.1016/j.ejor.2004.09.010.\n\n^ Kapetanios, G. (2007). \"Variable Selection in Regression Models using Nonstandard Optimisation of Information Criteria\". Computational Statistics & Data Analysis. 52 (1): 4\u201315. doi:10.1016/j.csda.2007.04.006.\n\n^ Broadhurst, D.; Goodacre, R.; Jones, A.; Rowland, J. J.; Kell, D. B. (1997). \"Genetic algorithms as a method for variable selection in multiple linear regression and partial least squares regression, with applications to pyrolysis mass spectrometry\". Analytica Chimica Acta. 348 (1\u20133): 71\u201386. Bibcode:1997AcAC..348...71B. doi:10.1016/S0003-2670(97)00065-2.\n\n^ Chuang, L.-Y.; Yang, C.-H. (2009). \"Tabu search and binary particle swarm optimization for feature selection using microarray data\". Journal of Computational Biology. 16 (12): 1689\u20131703. doi:10.1089/cmb.2007.0211. PMID\u00a020047491.\n\n^ E. Alba, J. Garia-Nieto, L. Jourdan et E.-G. Talbi. Gene Selection in Cancer Classification using PSO-SVM and GA-SVM Hybrid Algorithms. Archived 2016-08-18 at the Wayback Machine Congress on Evolutionary Computation, Singapore: Singapore (2007), 2007\n\n^ B. Duval, J.-K. Hao et J. C. Hernandez Hernandez. A memetic algorithm for gene selection and molecular classification of an cancer. In Proceedings of the 11th Annual conference on Genetic and evolutionary computation, GECCO '09, pages 201-208, New York, NY, USA, 2009. ACM.\n\n^ C. Hans, A. Dobra et M. West. Shotgun stochastic search for 'large p' regression. Journal of the American Statistical Association, 2007.\n\n^ Aitken, S. (2005). \"Feature selection and classification for microarray data analysis: Evolutionary methods for identifying predictive genes\". BMC Bioinformatics. 6 (1): 148. doi:10.1186/1471-2105-6-148. PMC\u00a01181625. PMID\u00a015958165.\n\n^ Oh, I. S.; Moon, B. R. (2004). \"Hybrid genetic algorithms for feature selection\". IEEE Transactions on Pattern Analysis and Machine Intelligence. 26 (11): 1424\u20131437. CiteSeerX\u00a010.1.1.467.4179. doi:10.1109/tpami.2004.105. PMID\u00a015521491.\n\n^ Xuan, P.; Guo, M. Z.; Wang, J.; Liu, X. Y.; Liu, Y. (2011). \"Genetic algorithm-based efficient feature selection for classification of pre-miRNAs\". Genetics and Molecular Research. 10 (2): 588\u2013603. doi:10.4238/vol10-2gmr969. PMID\u00a021491369.\n\n^ Peng, S. (2003). \"Molecular classification of cancer types from microarray data using the combination of genetic algorithms and support vector machines\". FEBS Letters. 555 (2): 358\u2013362. Bibcode:2003FEBSL.555..358P. doi:10.1016/s0014-5793(03)01275-4. PMID\u00a014644442.\n\n^ Hernandez, J. C. H.; Duval, B.; Hao, J.-K. (2007). \"A Genetic Embedded Approach for Gene Selection and Classification of Microarray Data\". Evolutionary Computation, Machine Learning and Data Mining in Bioinformatics. EvoBIO 2007. Lecture Notes in Computer Science. Vol.\u00a04447. Berlin: Springer Verlag. pp.\u00a090\u2013101. doi:10.1007/978-3-540-71783-6_9. ISBN\u00a0978-3-540-71782-9.\n\n^ Huerta, E. B.; Duval, B.; Hao, J.-K. (2006). \"A Hybrid GA/SVM Approach for Gene Selection and Classification of Microarray Data\". Applications of Evolutionary Computing. EvoWorkshops 2006. Lecture Notes in Computer Science. Vol.\u00a03907. pp.\u00a034\u201344. doi:10.1007/11732242_4. ISBN\u00a0978-3-540-33237-4.\n\n^ Muni, D. P.; Pal, N. R.; Das, J. (2006). \"Genetic programming for simultaneous feature selection and classifier design\". IEEE Transactions on Systems, Man, and Cybernetics - Part B: Cybernetics. 36 (1): 106\u2013117. doi:10.1109/TSMCB.2005.854499. PMID\u00a016468570. S2CID\u00a02073035.\n\n^ Jourdan, L.; Dhaenens, C.; Talbi, E.-G. (2005). \"Linkage disequilibrium study with a parallel adaptive GA\". International Journal of Foundations of Computer Science. 16 (2): 241\u2013260. doi:10.1142/S0129054105002978.\n\n^ Zhang, Y.; Dong, Z.; Phillips, P.; Wang, S. (2015). \"Detection of subjects and brain regions related to Alzheimer's disease using 3D MRI scans based on eigenbrain and machine learning\". Frontiers in Computational Neuroscience. 9: 66. doi:10.3389/fncom.2015.00066. PMC\u00a04451357. PMID\u00a026082713.\n\n^ Roffo, G.; Melzi, S.; Cristani, M. (2015-12-01). \"Infinite Feature Selection\". 2015 IEEE International Conference on Computer Vision (ICCV). pp.\u00a04202\u20134210. doi:10.1109/ICCV.2015.478. ISBN\u00a0978-1-4673-8391-2. S2CID\u00a03223980.\n\n^ Roffo, Giorgio; Melzi, Simone (September 2016). \"Features Selection via Eigenvector Centrality\" (PDF). NFmcp2016. Retrieved 12 November 2016.\n\n^ R. Kohavi and G. John, \"Wrappers for feature subset selection\", Artificial intelligence 97.1-2 (1997): 273-324\n\n^ Das, Abhimanyu; Kempe, David (2011). \"Submodular meets Spectral: Greedy Algorithms for Subset Selection, Sparse Approximation and Dictionary Selection\". arXiv:1102.3975 [stat.ML].\n\n^ Liu et al., Submodular feature selection for high-dimensional acoustic score spaces Archived 2015-10-17 at the Wayback Machine\n\n^ Zheng et al., Submodular Attribute Selection for Action Recognition in Video Archived 2015-11-18 at the Wayback Machine\n\n^ Sun, Y.; Todorovic, S.; Goodison, S. (2010). \"Local-Learning-Based Feature Selection for High-Dimensional Data Analysis\". IEEE Transactions on Pattern Analysis and Machine Intelligence. 32 (9): 1610\u20131626. doi:10.1109/tpami.2009.190. PMC\u00a03445441. PMID\u00a020634556.\n\n^ D.H. Wang, Y.C. Liang, D.Xu, X.Y. Feng, R.C. Guan(2018), \"A content-based recommender system for computer science publications\", Knowledge-Based Systems, 157: 1-9\n\n\nFurther reading[edit]\nGuyon, Isabelle; Elisseeff, Andre (2003). \"An Introduction to Variable and Feature Selection\". Journal of Machine Learning Research. 3: 1157\u20131182.\nHarrell, F. (2001). Regression Modeling Strategies. Springer. ISBN\u00a00-387-95232-2.\nLiu, Huan; Motoda, Hiroshi (1998). Feature Selection for Knowledge Discovery and Data Mining. Springer. ISBN\u00a00-7923-8198-X.\nLiu, Huan; Yu, Lei (2005). \"Toward Integrating Feature Selection Algorithms for Classification and Clustering\". IEEE Transactions on Knowledge and Data Engineering. 17 (4): 491\u2013502. doi:10.1109/TKDE.2005.66. S2CID\u00a01607600.\nExternal links[edit]\nFeature Selection Package, Arizona State University (Matlab Code)\nNIPS challenge 2003 (see also NIPS)\nNaive Bayes implementation with feature selection in Visual Basic Archived 2009-02-14 at the Wayback Machine (includes executable and source code)\nMinimum-redundancy-maximum-relevance (mRMR) feature selection program\nFEAST (Open source Feature Selection algorithms in C and MATLAB)\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Feature_selection&oldid=1256689439\""}, {"url": "https://en.wikipedia.org/wiki/Algorithm_selection", "content": "Meta-algorithmic technique to choose an algorithm\n\nAlgorithm selection (sometimes also called per-instance algorithm selection or offline algorithm selection) is a meta-algorithmic technique to choose an algorithm from a portfolio on an instance-by-instance basis. It is motivated by the observation that on many practical problems, different algorithms have different performance characteristics. That is, while one algorithm performs well in some scenarios, it performs poorly in others and vice versa for another algorithm. If we can identify when to use which algorithm, we can optimize for each scenario and improve overall performance. This is what algorithm selection aims to do. The only prerequisite for applying algorithm selection techniques is that there exists (or that there can be constructed) a set of complementary algorithms.\n\n\nDefinition[edit]\nGiven a portfolio \n\n\n\n\n\nP\n\n\n\n\n{\\displaystyle {\\mathcal {P}}}\n\n of algorithms \n\n\n\n\n\nA\n\n\n\u2208\n\n\nP\n\n\n\n\n{\\displaystyle {\\mathcal {A}}\\in {\\mathcal {P}}}\n\n, a set of instances \n\n\n\ni\n\u2208\n\n\nI\n\n\n\n\n{\\displaystyle i\\in {\\mathcal {I}}}\n\n and a cost metric \n\n\n\nm\n:\n\n\nP\n\n\n\u00d7\n\n\nI\n\n\n\u2192\n\nR\n\n\n\n{\\displaystyle m:{\\mathcal {P}}\\times {\\mathcal {I}}\\to \\mathbb {R} }\n\n, the algorithm selection problem consists of finding a mapping \n\n\n\ns\n:\n\n\nI\n\n\n\u2192\n\n\nP\n\n\n\n\n{\\displaystyle s:{\\mathcal {I}}\\to {\\mathcal {P}}}\n\n from instances \n\n\n\n\n\nI\n\n\n\n\n{\\displaystyle {\\mathcal {I}}}\n\n to algorithms \n\n\n\n\n\nP\n\n\n\n\n{\\displaystyle {\\mathcal {P}}}\n\n such that the cost \n\n\n\n\n\u2211\n\ni\n\u2208\n\n\nI\n\n\n\n\nm\n(\ns\n(\ni\n)\n,\ni\n)\n\n\n{\\displaystyle \\sum _{i\\in {\\mathcal {I}}}m(s(i),i)}\n\n across all instances is optimized.[1][2]\n\nExamples[edit]\nBoolean satisfiability problem (and other hard combinatorial problems)[edit]\nA well-known application of algorithm selection is the Boolean satisfiability problem. Here, the portfolio of algorithms is a set of (complementary) SAT solvers, the instances are Boolean formulas, the cost metric is for example average runtime or number of unsolved instances. So, the goal is to select a well-performing SAT solver for each individual instance. In the same way, algorithm selection can be applied to many other \n\n\n\n\n\nN\nP\n\n\n\n\n{\\displaystyle {\\mathcal {NP}}}\n\n-hard problems (such as mixed integer programming, CSP, AI planning, TSP, MAXSAT, QBF and answer set programming). Competition-winning systems in SAT are SATzilla,[3] 3S[4] and CSHC[5]\n\nMachine learning[edit]\nIn machine learning, algorithm selection is better known as meta-learning. The portfolio of algorithms consists of machine learning algorithms (e.g., Random Forest, SVM, DNN), the instances are data sets and the cost metric is for example the error rate. So, the goal is to predict which machine learning algorithm will have a small error on each data set.\n\nInstance features[edit]\nThe algorithm selection problem is mainly solved with machine learning techniques. By representing the problem instances by numerical features \n\n\n\nf\n\n\n{\\displaystyle f}\n\n, algorithm selection can be seen as a multi-class classification problem by learning a mapping \n\n\n\n\nf\n\ni\n\n\n\u21a6\n\n\nA\n\n\n\n\n{\\displaystyle f_{i}\\mapsto {\\mathcal {A}}}\n\n for a given instance \n\n\n\ni\n\n\n{\\displaystyle i}\n\n.\nInstance features are numerical representations of instances. For example, we can count the number of variables, clauses, average clause length for Boolean formulas,[6] or number of samples, features, class balance for ML data sets to get an impression about their characteristics.\n\nStatic vs. probing features[edit]\nWe distinguish between two kinds of features: \n\nStatic features are in most cases some counts and statistics (e.g., clauses-to-variables ratio in SAT). These features ranges from very cheap features (e.g. number of variables) to very complex features (e.g., statistics about variable-clause graphs).\nProbing features (sometimes also called landmarking features) are computed by running some analysis of algorithm behavior on an instance (e.g., accuracy of a cheap decision tree algorithm on an ML data set, or running for a short time a stochastic local search solver on a Boolean formula). These feature often cost more than simple static features.\nFeature costs[edit]\nDepending on the used performance metric \n\n\n\nm\n\n\n{\\displaystyle m}\n\n, feature computation can be associated with costs.\nFor example, if we use running time as performance metric, we include the time to compute our instance features into the performance of an algorithm selection system.\nSAT solving is a concrete example, where such feature costs cannot be neglected, since instance features for CNF formulas can be either very cheap (e.g., to get the number of variables can be done in constant time for CNFs in the DIMACs format) or very expensive (e.g., graph features which can cost tens or hundreds of seconds).\nIt is important to take the overhead of feature computation into account in practice in such scenarios; otherwise a misleading impression of the performance of the algorithm selection approach is created. For example, if the decision which algorithm to choose can be made with perfect accuracy, but the features are the running time of the portfolio algorithms, there is no benefit to the portfolio approach. This would not be obvious if feature costs were omitted.\n\nApproaches[edit]\nRegression approach[edit]\nOne of the first successful algorithm selection approaches predicted the performance of each algorithm \n\n\n\n\n\n\n\nm\n^\n\n\n\n\n\nA\n\n\n\n:\n\n\nI\n\n\n\u2192\n\nR\n\n\n\n{\\displaystyle {\\hat {m}}_{\\mathcal {A}}:{\\mathcal {I}}\\to \\mathbb {R} }\n\n and selected the algorithm with the best predicted performance \n\n\n\na\nr\ng\n\nmin\n\n\n\nA\n\n\n\u2208\n\n\nP\n\n\n\n\n\n\n\n\nm\n^\n\n\n\n\n\nA\n\n\n\n(\ni\n)\n\n\n{\\displaystyle arg\\min _{{\\mathcal {A}}\\in {\\mathcal {P}}}{\\hat {m}}_{\\mathcal {A}}(i)}\n\n for an instance \n\n\n\ni\n\n\n{\\displaystyle i}\n\n.[3]\n\nClustering approach[edit]\nA common assumption is that the given set of instances \n\n\n\n\n\nI\n\n\n\n\n{\\displaystyle {\\mathcal {I}}}\n\n can be clustered into homogeneous subsets \nand for each of these subsets, there is one well-performing algorithm for all instances in there.\nSo, the training consists of identifying the homogeneous clusters via an unsupervised clustering approach and associating an algorithm with each cluster.\nA new instance is assigned to a cluster and the associated algorithm selected.[7]\nA more modern approach is cost-sensitive hierarchical clustering[5] using supervised learning to identify the homogeneous instance subsets.\n\nPairwise cost-sensitive classification approach[edit]\nA common approach for multi-class classification is to learn pairwise models between every pair of classes (here algorithms) \nand choose the class that was predicted most often by the pairwise models.\nWe can weight the instances of the pairwise prediction problem by the performance difference between the two algorithms.\nThis is motivated by the fact that we care most about getting predictions with large differences correct, but the penalty for an incorrect prediction is small if there is almost no performance difference.\nTherefore, each instance \n\n\n\ni\n\n\n{\\displaystyle i}\n\n for training a classification model \n\n\n\n\n\n\nA\n\n\n\n1\n\n\n\n\n{\\displaystyle {\\mathcal {A}}_{1}}\n\n vs \n\n\n\n\n\n\nA\n\n\n\n2\n\n\n\n\n{\\displaystyle {\\mathcal {A}}_{2}}\n\n is associated with a cost \n\n\n\n\n|\n\nm\n(\n\n\n\nA\n\n\n\n1\n\n\n,\ni\n)\n\u2212\nm\n(\n\n\n\nA\n\n\n\n2\n\n\n,\ni\n)\n\n|\n\n\n\n{\\displaystyle |m({\\mathcal {A}}_{1},i)-m({\\mathcal {A}}_{2},i)|}\n\n.[8]\n\nRequirements[edit]\nClustering of SAT solvers from SAT12-INDU ASlib scenario according to the correlation coefficient of spearman.\nShapley values for complementary analysis on SAT12-INDU ASlib Scenario[9]\nThe algorithm selection problem can be effectively applied under the following assumptions:\n\nThe portfolio \n\n\n\n\n\nP\n\n\n\n\n{\\displaystyle {\\mathcal {P}}}\n\n of algorithms is complementary with respect to the instance set \n\n\n\n\n\nI\n\n\n\n\n{\\displaystyle {\\mathcal {I}}}\n\n, i.e.,  there is no single algorithm \n\n\n\n\n\nA\n\n\n\u2208\n\n\nP\n\n\n\n\n{\\displaystyle {\\mathcal {A}}\\in {\\mathcal {P}}}\n\n that dominates the performance of all other algorithms over \n\n\n\n\n\nI\n\n\n\n\n{\\displaystyle {\\mathcal {I}}}\n\n (see figures to the right for examples on complementary analysis).\nIn some application, the computation of instance features is associated with a cost. For example, if the cost metric is running time, we have also to consider the time to compute the instance features. In such cases, the cost to compute features should not be larger than the performance gain through algorithm selection.\nApplication domains[edit]\nAlgorithm selection is not limited to single domains but can be applied to any kind of algorithm if the above requirements are satisfied.\nApplication domains include:\n\nhard combinatorial problems:[10] SAT, Mixed Integer Programming, CSP, AI Planning, TSP, MAXSAT, QBF and Answer Set Programming\ncombinatorial auctions\nin machine learning, the problem is known as meta-learning\nsoftware design\nblack-box optimization\nmulti-agent systems\nnumerical optimization\nlinear algebra, differential equations\nevolutionary algorithms\nvehicle routing problem\npower systems\nFor an extensive list of literature about algorithm selection, we refer to a literature overview.\n\nVariants of algorithm selection[edit]\nOnline selection[edit]\nOnline algorithm selection refers to switching between different algorithms during the solving process.  This is useful as a hyper-heuristic. In contrast, offline algorithm selection selects an algorithm for a given instance only once and before the solving process.\n\nComputation of schedules[edit]\nAn extension of algorithm selection is the per-instance algorithm scheduling problem, in which we do not select only one solver, but we select a time budget for each algorithm on a per-instance base. This approach improves the performance of selection systems in particular if the instance features are not very informative and a wrong selection of a single solver is likely.[11]\n\nSelection of parallel portfolios[edit]\nGiven the increasing importance of parallel computation,\nan extension of algorithm selection for parallel computation is parallel portfolio selection,\nin which we select a subset of the algorithms to simultaneously run in a parallel portfolio.[12]\n\nExternal links[edit]\nAlgorithm Selection Library (ASlib)\nAlgorithm selection literature\nReferences[edit]\n\n\n^ Rice, John R. (1976). \"The Algorithm Selection Problem\". Advances in Computers. Vol.\u00a015. pp.\u00a065\u2013118. doi:10.1016/S0065-2458(08)60520-3. ISBN\u00a09780120121151.\n\n^ Bischl, Bernd; Kerschke, Pascal; Kotthoff, Lars; Lindauer, Marius; Malitsky, Yuri; Fr\u00e9chette, Alexandre; Hoos, Holger; Hutter, Frank; Leyton-Brown, Kevin; Tierney, Kevin; Vanschoren, Joaquin (2016). \"ASlib: A benchmark library for algorithm selection\". Artificial Intelligence. 237: 41\u201358. arXiv:1506.02465. doi:10.1016/j.artint.2016.04.003. S2CID\u00a0261945.\n\n^ a b L. Xu; F. Hutter; H. Hoos & K. Leyton-Brown (2008). \"SATzilla: Portfolio-based Algorithm Selection for SAT\". Journal of Artificial Intelligence Research. 32: 565\u2013606. arXiv:1111.2249. doi:10.1613/jair.2490. S2CID\u00a010987043.\n\n^ S. Kadioglu; Y. Malitsky; A. Sabharwal; H. Samulowitz; M. Sellmann (2011). \"Algorithm Selection and Scheduling\". In Lee, J. (ed.). Principles and Practice of Constraint Programming. Lecture Notes in Computer Science. Vol.\u00a06876. pp.\u00a0454\u2013469. CiteSeerX\u00a010.1.1.211.1807. doi:10.1007/978-3-642-23786-7_35. ISBN\u00a0978-3-642-23785-0.\n\n^ a b Y. Malitsky; A. Sabharwal; H. Samulowitz; M. Sellmann (2013). \"Algorithm Portfolios Based on Cost-Sensitive Hierarchical Clustering\". Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence. AAAI Press. pp.\u00a0608\u2013614. ISBN\u00a0978-1-57735-633-2.\n\n^ E. Nudelman; K. Leyton-Brown; H. Hoos; A. Devkar; Y. Shoham (2004). \"Understanding Random SAT: Beyond the Clauses-to-Variables Ratio\" (PDF). Proceedings of CP.\n\n^ S. Kadioglu; Y. Malitsky; M. Sellmann; K. Tierney (2010). \"ISAC \u2013 Instance-Specific Algorithm Configuration\" (PDF). Proceedings of the European Conference on Artificial Intelligence.\n\n^ L. Xu; F. Hutter; J. Shen; H. Hoos; K. Leyton-Brown (2012). \"SATzilla2012: Improved Algorithm Selection Based on Cost-sensitive Classification Models\" (PDF). Proceedings of the SAT Challenge 2012: Solver and Benchmark Descriptions.\n\n^ A. Frechette; L. Kotthoff; T. Michalak; T. Rahwan; H. Hoos & K. Leyton-Brown (2016). \"Using the Shapley Value to Analyze Algorithm Portfolios\". Proceedings of the AAAI Conference on Artificial Intelligence. 30. doi:10.1609/aaai.v30i1.10440. S2CID\u00a06676831.\n\n^ Kotthoff, Lars. \"Algorithm selection for combinatorial search problems: A survey.\" Data Mining and Constraint Programming. Springer, Cham, 2016. 149-190.\n\n^ M. Lindauer; R. Bergdoll; F. Hutter (2016). \"An Empirical Study of Per-instance Algorithm Scheduling\". Learning and Intelligent Optimization (PDF). Lecture Notes in Computer Science. Vol.\u00a010079. pp.\u00a0253\u2013259. doi:10.1007/978-3-319-50349-3_20. ISBN\u00a0978-3-319-50348-6.\n\n^ M. Lindauer; H. Hoos & F. Hutter (2015). \"From Sequential Algorithm Selection to Parallel Portfolio Selection\". Learning and Intelligent Optimization (PDF). Lecture Notes in Computer Science. Vol.\u00a08994. pp.\u00a01\u201316. doi:10.1007/978-3-319-19084-6_1. ISBN\u00a0978-3-319-19083-9.\n\n\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Algorithm_selection&oldid=1217120227\""}, {"url": "https://en.wikipedia.org/wiki/Data_science", "content": "Field of study to extract insights from data\nNot to be confused with information science or computer science.\n\n\nThe existence of Comet NEOWISE (here depicted as a series of red dots) was discovered by analyzing astronomical survey data acquired by a space telescope, the Wide-field Infrared Survey Explorer.\nData science is an interdisciplinary academic field[1] that uses statistics, scientific computing, scientific methods, processing, scientific visualization, algorithms and systems to extract or extrapolate knowledge and insights from potentially noisy, structured, or unstructured data.[2]\nData science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine).[3] Data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.[4]\nData science is \"a concept to unify statistics, data analysis, informatics, and their related methods\" to \"understand and analyze actual phenomena\" with data.[5] It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge.[6] However, data science is different from computer science and information science. Turing Award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational, and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.[7][8]\nA data scientist is a professional who creates programming code and combines it with statistical knowledge to create insights from data.[9]\n\n\nFoundations[edit]\nData science is an interdisciplinary field[10] focused on extracting knowledge from typically large data sets and applying the knowledge and insights from that data to solve problems in a wide range of application domains. The field encompasses preparing data for analysis, formulating data science problems, analyzing data, developing data-driven solutions, and presenting findings to inform high-level decisions in a broad range of application domains. As such, it incorporates skills from computer science, statistics, information science, mathematics, data visualization, information visualization, data sonification, data integration, graphic design, complex systems, communication and business.[11][12] Statistician Nathan Yau, drawing on Ben Fry, also links data science to human\u2013computer interaction: users should be able to intuitively control and explore data.[13][14] In 2015, the American Statistical Association identified database management, statistics and machine learning, and distributed and parallel systems as the three emerging foundational professional communities.[15]\n\nRelationship to statistics[edit]\nMany statisticians, including Nate Silver, have argued that data science is not a new field, but rather another name for statistics.[16] Others argue that data science is distinct from statistics because it focuses on problems and techniques unique to digital data.[17] Vasant Dhar writes that statistics emphasizes quantitative data and description. In contrast, data science deals with quantitative and qualitative data (e.g., from images, text, sensors, transactions, customer information, etc.) and emphasizes prediction and action.[18] Andrew Gelman of Columbia University has described statistics as a non-essential part of data science.[19]\nStanford professor David Donoho writes that data science is not distinguished from statistics by the size of datasets or use of computing and that many graduate programs misleadingly advertise their analytics and statistics training as the essence of a data-science program. He describes data science as an applied field growing out of traditional statistics.[20]\n\nEtymology[edit]\nEarly usage[edit]\nIn 1962, John Tukey described a field he called \"data analysis\", which resembles modern data science.[20] In 1985, in a lecture given to the Chinese Academy of Sciences in Beijing, C.\u00a0F. Jeff Wu used the term \"data science\" for the first time as an alternative name for statistics.[21] Later, attendees at a 1992 statistics symposium at the University of Montpellier\u00a0 II acknowledged the emergence of a new discipline focused on data of various origins and forms, combining established concepts and principles of statistics and data analysis with computing.[22][23]\nThe term \"data science\" has been traced back to 1974, when Peter Naur proposed it as an alternative name to computer science.[6] In 1996, the International Federation of Classification Societies became the first conference to specifically feature data science as a topic.[6] However, the definition was still in flux. After the 1985 lecture at the Chinese Academy of Sciences in Beijing, in 1997 C.\u00a0F. Jeff Wu again suggested that statistics should be renamed data science. He reasoned that a new name would help statistics shed inaccurate stereotypes, such as being synonymous with accounting or limited to describing data.[24] In 1998, Hayashi Chikio argued for data science as a new, interdisciplinary concept, with three aspects: data design, collection, and analysis.[23]\nDuring the 1990s, popular terms for the process of finding patterns in datasets (which were increasingly large) included \"knowledge discovery\" and \"data mining\".[6][25]\n\nModern usage[edit]\nIn 2012, technologists Thomas H. Davenport and DJ Patil declared \"Data Scientist: The Sexiest Job of the 21st Century\",[26] a catchphrase that was picked up even by major-city newspapers like the New York Times[27] and the Boston Globe.[28] A decade later, they reaffirmed it, stating that \"the job is more in demand than ever with employers\".[29]\nThe modern conception of data science as an independent discipline is sometimes attributed to William S. Cleveland.[30] In a 2001 paper, he advocated an expansion of statistics beyond theory into technical areas; because this would significantly change the field, it warranted a new name.[25] \"Data science\" became more widely used in the next few years: in 2002, the Committee on Data for Science and Technology launched the Data Science Journal. In 2003, Columbia University launched The Journal of Data Science.[25] In 2014, the American Statistical Association's Section on Statistical Learning and Data Mining changed its name to the Section on Statistical Learning and Data Science, reflecting the ascendant popularity of data science.[31]\nThe professional title of \"data scientist\" has been attributed to DJ Patil and Jeff Hammerbacher in 2008.[32] Though it was used by the National Science Board in their 2005 report \"Long-Lived Digital Data Collections: Enabling Research and Education in the 21st Century\", it referred broadly to any key role in managing a digital data collection.[33]\nThere is still no consensus on the definition of data science, and it is considered by some to be a buzzword.[34] Big data is a related marketing term.[35] Data scientists are responsible for breaking down big data into usable information and creating software and algorithms that help companies and organizations determine optimal operations.[36]\n\nData science and data analysis[edit]\nExample for the usefulness of exploratory data analysis as demonstrated using the Datasaurus dozen data set\nData science and data analysis are both important disciplines in the field of data management and analysis, but they differ in several key ways. While both fields involve working with data, data science is more of an interdisciplinary field that involves the application of statistical, computational, and machine learning methods to extract insights from data and make predictions, while data analysis is more focused on the examination and interpretation of data to identify patterns and trends.[37][38]\nData analysis typically involves working with smaller, structured datasets to answer specific questions or solve specific problems. This can involve tasks such as data cleaning, data visualization, and exploratory data analysis to gain insights into the data and develop hypotheses about relationships between variables. Data analysts typically use statistical methods to test these hypotheses and draw conclusions from the data. For example, a data analyst might analyze sales data to identify trends in customer behavior and make recommendations for marketing strategies.[37]\nData science, on the other hand, is a more complex and iterative process that involves working with larger, more complex datasets that often require advanced computational and statistical methods to analyze. Data scientists often work with unstructured data such as text or images and use machine learning algorithms to build predictive models and make data-driven decisions. In addition to statistical analysis, data science often involves tasks such as data preprocessing, feature engineering, and model selection. For instance, a data scientist might develop a recommendation system for an e-commerce platform by analyzing user behavior patterns and using machine learning algorithms to predict user preferences.[38][39]\nWhile data analysis focuses on extracting insights from existing data, data science goes beyond that by incorporating the development and implementation of predictive models to make informed decisions. Data scientists are often responsible for collecting and cleaning data, selecting appropriate analytical techniques, and deploying models in real-world scenarios. They work at the intersection of mathematics, computer science, and domain expertise to solve complex problems and uncover hidden patterns in large datasets.[38]\nDespite these differences, data science and data analysis are closely related fields and often require similar skill sets. Both fields require a solid foundation in statistics, programming, and data visualization, as well as the ability to communicate findings effectively to both technical and non-technical audiences. Both fields benefit from critical thinking and domain knowledge, as understanding the context and nuances of the data is essential for accurate analysis and modeling.[37][38]\nIn summary, data analysis and data science are distinct yet interconnected disciplines within the broader field of data management and analysis. Data analysis focuses on extracting insights and drawing conclusions from structured data, while data science involves a more comprehensive approach that combines statistical analysis, computational methods, and machine learning to extract insights, build predictive models, and drive data-driven decision-making. Both fields use data to understand patterns, make informed decisions, and solve complex problems across various domains.\n\nCloud computing for data science[edit]\nA cloud-based architecture for enabling big data analytics. Data flows from various sources, such as personal computers, laptops, and smart phones, through cloud services for processing and analysis, finally leading to various big data applications.\nCloud computing can offer access to large amounts of computational power and storage.[40] In big data, where volumes of information are continually generated and processed, these platforms can be used to handle complex and resource-intensive analytical tasks.[41]\nSome distributed computing frameworks are designed to handle big data workloads. These frameworks can enable data scientists to process and analyze large datasets in parallel, which can reducing processing times.[42]\n\nEthical consideration in data science[edit]\nData science involve collecting, processing, and analyzing data which often including personal and sensitive information. Ethical concerns include potential privacy violations, bias perpetuation, and negative societal impacts [43][44]\nMachine learning models can amplify existing biases present in training data, leading to discriminatory or unfair outcomes.[45][46]\n\nSee also[edit]\nPython (programming language)\nR (programming language)\nData engineering\nBig data\nMachine learning\nReferences[edit]\n\n\n^ Donoho, David (2017). \"50 Years of Data Science\". Journal of Computational and Graphical Statistics. 26 (4): 745\u2013766. doi:10.1080/10618600.2017.1384734. S2CID\u00a0114558008.\n\n^ Dhar, V. (2013). \"Data science and prediction\". Communications of the ACM. 56 (12): 64\u201373. doi:10.1145/2500499. S2CID\u00a06107147. Archived from the original on 9 November 2014. Retrieved 2 September 2015.\n\n^ Danyluk, A.; Leidig, P. (2021). Computing Competencies for Undergraduate Data Science Curricula (PDF). ACM Data Science Task Force Final Report (Report).\n\n^ Mike, Koby; Hazzan, Orit (20 January 2023). \"What is Data Science?\". Communications of the ACM. 66 (2): 12\u201313. doi:10.1145/3575663. ISSN\u00a00001-0782.\n\n^ Hayashi, Chikio (1 January 1998). \"What is Data Science\u00a0? Fundamental Concepts and a Heuristic Example\". In Hayashi, Chikio; Yajima, Keiji; Bock, Hans-Hermann; Ohsumi, Noboru; Tanaka, Yutaka; Baba, Yasumasa (eds.). Data Science, Classification, and Related Methods. Studies in Classification, Data Analysis, and Knowledge Organization. Springer Japan. pp.\u00a040\u201351. doi:10.1007/978-4-431-65950-1_3. ISBN\u00a09784431702085.\n\n^ a b c d Cao, Longbing (29 June 2017). \"Data Science: A Comprehensive Overview\". ACM Computing Surveys. 50 (3): 43:1\u201343:42. arXiv:2007.03606. doi:10.1145/3076253. ISSN\u00a00360-0300. S2CID\u00a0207595944.\n\n^ Tony Hey; Stewart Tansley; Kristin Michele Tolle (2009). The Fourth Paradigm: Data-intensive Scientific Discovery. Microsoft Research. ISBN\u00a0978-0-9825442-0-4. Archived from the original on 20 March 2017.\n\n^ Bell, G.; Hey, T.; Szalay, A. (2009). \"Computer Science: Beyond the Data Deluge\". Science. 323 (5919): 1297\u20131298. doi:10.1126/science.1170411. ISSN\u00a00036-8075. PMID\u00a019265007. S2CID\u00a09743327.\n\n^ Davenport, Thomas H.; Patil, D. J. (October 2012). \"Data Scientist: The Sexiest Job of the 21st Century\". Harvard Business Review. 90 (10): 70\u201376, 128. PMID\u00a023074866. Retrieved 18 January 2016.\n\n^ Emmert-Streib, Frank; Dehmer, Matthias (2018). \"Defining data science by a data-driven quantification of the community\". Machine Learning and Knowledge Extraction. 1: 235\u2013251. doi:10.3390/make1010015.\n\n^ \"1. Introduction: What Is Data Science?\". Doing Data Science [Book]. O\u2019Reilly. Retrieved 3 April 2020.\n\n^ \"the three sexy skills of data geeks\". m.e.driscoll: data utopian. 27 May 2009. Retrieved 3 April 2020.\n\n^ Yau, Nathan (4 June 2009). \"Rise of the Data Scientist\". FlowingData. Retrieved 3 April 2020.\n\n^ \"Basic Example\". benfry.com. Retrieved 3 April 2020.\n\n^ \"ASA Statement on the Role of Statistics in Data Science\". AmStatNews. American Statistical Association. 1 October 2015. Archived from the original on 20 June 2019. Retrieved 29 May 2019.\n\n^ \"Nate Silver: What I need from statisticians\". Statistics Views. 23 August 2013. Retrieved 3 April 2020.\n\n^ \"What's the Difference Between Data Science and Statistics?\". Priceonomics. 13 October 2015. Retrieved 3 April 2020.\n\n^ Vasant Dhar (1 December 2013). \"Data science and prediction\". Communications of the ACM. 56 (12): 64\u201373. doi:10.1145/2500499. S2CID\u00a06107147.\n\n^ \"Statistics is the least important part of data science \u00ab\u00a0Statistical Modeling, Causal Inference, and Social Science\". statmodeling.stat.columbia.edu. Retrieved 3 April 2020.\n\n^ a b Donoho, David (18 September 2015). \"50 years of Data Science\" (PDF). Retrieved 2 April 2020.\n\n^ Wu, C. F. Jeff (1986). \"Future directions of statistical research in China: a historical perspective\" (PDF). Application of Statistics and Management. 1: 1\u20137. Retrieved 29 November 2020.\n\n^ Escoufier, Yves; Hayashi, Chikio; Fichet, Bernard, eds. (1995). Data science and its applications. Tokyo: Academic Press/Harcourt Brace. ISBN\u00a00-12-241770-4. OCLC\u00a0489990740.\n\n^ a b Murtagh, Fionn; Devlin, Keith (2018). \"The Development of Data Science: Implications for Education, Employment, Research, and the Data Revolution for Sustainable Development\". Big Data and Cognitive Computing. 2 (2): 14. doi:10.3390/bdcc2020014.\n\n^ Wu, C.\u00a0F. Jeff. \"Statistics=Data Science?\" (PDF). Retrieved 2 April 2020.\n\n^ a b c Press, Gil. \"A Very Short History of Data Science\". Forbes. Retrieved 3 April 2020.\n\n^ Davenport, Thomas (1 October 2012). \"Data Scientist: The Sexiest Job of the 21st Century\". Harvard Business Review. Retrieved 10 October 2022.\n\n^ Miller, Claire (4 April 2013). \"Data Science: The Numbers of Our Lives\". New York Times. New York City. Retrieved 10 October 2022.\n\n^ Borchers, Callum (11 November 2015). \"Behind the scenes of the 'sexiest job of the 21st century'\". Boston Globe. Boston. Retrieved 10 October 2022.\n\n^ Davenport, Thomas (15 July 2022). \"Is Data Scientist Still the Sexiest Job of the 21st Century?\". Harvard Business Review. Retrieved 10 October 2022.\n\n^ Gupta, Shanti (11 December 2015). \"William S. Cleveland\". Retrieved 2 April 2020.\n\n^ Talley, Jill (1 June 2016). \"ASA Expands Scope, Outreach to Foster Growth, Collaboration in Data Science\". Amstat News. American Statistical Association.. In 2013 the first European Conference on Data Analysis (ECDA2013) started in Luxembourg the process which founded the European Association for Data Science (EuADS) www.euads.org in Luxembourg in 2015. \n\n^ Davenport, Thomas H.; Patil, D. J. (1 October 2012). \"Data Scientist: The Sexiest Job of the 21st Century\". Harvard Business Review. No.\u00a0October 2012. ISSN\u00a00017-8012. Retrieved 3 April 2020.\n\n^ \"US NSF \u2013 NSB-05-40, Long-Lived Digital Data Collections Enabling Research and Education in the 21st Century\". www.nsf.gov. Retrieved 3 April 2020.\n\n^ Press, Gil. \"Data Science: What's The Half-Life of a Buzzword?\". Forbes. Retrieved 3 April 2020.\n\n^ Pham, Peter. \"The Impacts of Big Data That You May Not Have Heard Of\". Forbes. Retrieved 3 April 2020.\n\n^ Martin, Sophia (20 September 2019). \"How Data Science will Impact Future of Businesses?\" (PDF). Medium. Retrieved 3 April 2020.\n\n^ a b c James, Gareth; Witten, Daniela; Hastie, Trevor; Tibshirani, Robert (29 September 2017). An Introduction to Statistical Learning: with Applications in R. Springer.\n\n^ a b c d Provost, Foster; Tom Fawcett (1 August 2013). \"Data Science for Business: What You Need to Know about Data Mining and Data-Analytic Thinking\". O'Reilly Media, Inc.\n\n^ Han, Kamber; Pei (2011). Data Mining: Concepts and Techniques. ISBN\u00a09780123814791.\n\n^ Hashem, Ibrahim Abaker Targio; Yaqoob, Ibrar; Anuar, Nor Badrul; Mokhtar, Salimah; Gani, Abdullah; Ullah Khan, Samee (2015). \"The rise of \"big data\" on cloud computing: Review and open research issues\". Information Systems. 47: 98\u2013115. doi:10.1016/j.is.2014.07.006.\n\n^ Qiu, Junfei; Wu, Qihui; Ding, Guoru; Xu, Yuhua; Feng, Shuo (2016). \"A survey of machine learning for big data processing\". EURASIP Journal on Advances in Signal Processing. 2016 (1). doi:10.1186/s13634-016-0355-x. ISSN\u00a01687-6180.\n\n^ Armbrust, Michael; Xin, Reynold S.; Lian, Cheng; Huai, Yin; Liu, Davies; Bradley, Joseph K.; Meng, Xiangrui; Kaftan, Tomer; Franklin, Michael J.; Ghodsi, Ali; Zaharia, Matei (27 May 2015). \"Spark SQL: Relational Data Processing in Spark\". Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data. ACM. pp.\u00a01383\u20131394. doi:10.1145/2723372.2742797. ISBN\u00a0978-1-4503-2758-9.\n\n^ Floridi, Luciano; Taddeo, Mariarosaria (28 December 2016). \"What is data ethics?\". Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences. 374 (2083): 20160360. Bibcode:2016RSPTA.37460360F. doi:10.1098/rsta.2016.0360. ISSN\u00a01364-503X. PMC\u00a05124072. PMID\u00a028336805.\n\n^ Mittelstadt, Brent Daniel; Floridi, Luciano (2016). \"The Ethics of Big Data: Current and Foreseeable Issues in Biomedical Contexts\". Science and Engineering Ethics. 22 (2): 303\u2013341. doi:10.1007/s11948-015-9652-2. ISSN\u00a01353-3452. PMID\u00a026002496.\n\n^ Barocas, Solon; Selbst, Andrew D (2016). \"Big Data's Disparate Impact\". California Law Review. doi:10.15779/Z38BG31 \u2013 via Berkeley Law Library Catalog.\n\n^ Caliskan, Aylin; Bryson, Joanna J.; Narayanan, Arvind (14 April 2017). \"Semantics derived automatically from language corpora contain human-like biases\". Science. 356 (6334): 183\u2013186. arXiv:1608.07187. Bibcode:2017Sci...356..183C. doi:10.1126/science.aal4230. ISSN\u00a00036-8075.\n\n\nvteData\nAcquisition\nAugmentation\nAnalysis\nArchaeology\nBig\nCleansing\nCollection\nCompression\nCorruption\nCuration\nDegradation\nEcosystem\nEditing\nETL/ELT\nExtract\nTransform\nLoad\nEthics\nFarming\nFormat management\nFusion\nGovernance\nCooperatives\nInfrastructure\nIntegration\nIntegrity\nLibrary\nLineage\nLoss\nManagement\nMigration\nMining\nPhilanthropy\nPre-processing\nPreservation\nProcessing\nProtection (privacy)\nPublishing\nOpen data\nRecovery\nReduction\nRetention\nQuality\nScience\nScraping\nScrubbing\nSecurity\nStewardship\nStorage\nSynchronization\nType\nValidation\nWarehouse\nWrangling/munging\n\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Data_science&oldid=1256180306\""}, {"url": "https://en.wikipedia.org/wiki/Data_preparation", "content": "Manipulating raw data into a form that can be readily analysed\nThis article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources:\u00a0\"Data preparation\"\u00a0\u2013\u00a0news\u00a0\u00b7 newspapers\u00a0\u00b7 books\u00a0\u00b7 scholar\u00a0\u00b7 JSTOR (February 2019) (Learn how and when to remove this message)\nData preparation is the act of manipulating (or pre-processing) raw data (which may come from disparate data sources) into a form that can readily and accurately be analysed, e.g. for business purposes.[1]\nData preparation is the first step in data analytics projects and can include many discrete tasks such as loading data or data ingestion, data fusion, data cleaning, data augmentation, and data delivery.[2]\nThe issues to be dealt with fall into two main categories: \n\nsystematic errors involving large numbers of data records, probably because they have come from different sources;\nindividual errors affecting small numbers of data records, probably due to errors in the original data entry.\n\nData specification[edit]\nThe first step is to set out a full and detailed specification of the format of each data field and what the entries mean. This should take careful account of:\n\nmost importantly, consultation with the users of the data\nany available specification of the system which will use the data to perform the analysis\na full understanding of the information available, and any gaps, in the source data.\nSee also data definition specification.\n\nExample[edit]\nSuppose there is a two-character alphabetic field that indicates geographical location. It is possible that in one data source a code \"EE\" means \"Europe\" and in another data source the same code means \"Estonia\". One would need to devise an unambiguous set of codes and amend the code in one set of records accordingly.\nFurthermore, the \"geographical area\" might refer to any of e.g. delivery address, billing address, address from which goods supplied, billing currency, or applicable national regulations. All these matters must be covered in the specification.\nThere could be some records with \"X\" or \"555\" in that field. Clearly, this is invalid data as it does not conform to the specification. If there are only small numbers of such records, one would either correct them manually or if precision is not important, simply delete those records from the file. Another possibility would be to create a \"not known\" category.\n\nOther examples of invalid data requiring correction[edit]\nTelephone numbers are in the correct format and have the correct values for the territory indicated in the geographical location field. The country code may be present in some records and not in others: it should either be removed or inserted (based on the geographical location) depending on the data specification. Similarly, the formats of dates and units of measurement (weights, lengths) may be inconsistent.\nIn some cases missing data should be supplied from external sources (e.g. finding the ZIP/postal code of an address via an external data source)\nData should be consistent between different but related data records (e.g. the same individual might have different birthdates in different records or datasets).\nWhere possible and economic, data should be verified against an authoritative source (e.g. business information is referenced against a D&B database to ensure accuracy).[3][4]\nGiven the variety of data sources (e.g. databases, business applications) that provide data and formats that data can arrive in, data preparation can be quite involved and complex. There are many tools and technologies[5] that are used for data preparation. The cost of cleaning the data should always be balanced against the value of the improved accuracy.\n\nSelf-service data preparation[edit]\nTraditional tools and technologies, such as scripting languages or extract, transform, load (ETL) and data quality tools are not meant for business users. They typically require programming or IT skills that most business users don\u2019t have.[citation needed]\nSeveral companies, such as Paxata, Trifacta, Alteryx, Talend, and Ataccama provide visual interfaces that display the data and allow the user to directly explore, structure, clean, augment, and update sample data provided by the user.  \nOnce the preparation work is complete, the underlying steps can be run on other datasets to perform the same operations. This reuse provides a significant productivity boost when compared to more traditional manual and hand-coding methods for data preparation.\n\nSee also[edit]\nData editing, correcting errors in a corpus of data\nData pre-processing, a step of cleaning data in data mining for analysis purposes\nData mining, finds patterns and insights within data sets\nData transmission\nReferences[edit]\n\n\n^ Friedland, David (September 7, 2016). \"A Fresh Look at Data Preparation\". IRI (Blog Article). IRI, The CoSort Company.\n\n^ Pyle, Dorian (April 5, 1999). Data Preparation for Data Mining. Morgan Kaufmann. ISBN\u00a09781558605299 \u2013 via Google Books.\n\n^ \"salesify\".\n\n^ Data Preparation Article[permanent dead link\u200d]\n\n^ \"Tools / Languages for Data Cleaning\". www.kdnuggets.com (Poll).\n\n\nvteData\nAcquisition\nAugmentation\nAnalysis\nArchaeology\nBig\nCleansing\nCollection\nCompression\nCorruption\nCuration\nDegradation\nEcosystem\nEditing\nETL/ELT\nExtract\nTransform\nLoad\nEthics\nFarming\nFormat management\nFusion\nGovernance\nCooperatives\nInfrastructure\nIntegration\nIntegrity\nLibrary\nLineage\nLoss\nManagement\nMigration\nMining\nPhilanthropy\nPre-processing\nPreservation\nProcessing\nProtection (privacy)\nPublishing\nOpen data\nRecovery\nReduction\nRetention\nQuality\nScience\nScraping\nScrubbing\nSecurity\nStewardship\nStorage\nSynchronization\nType\nValidation\nWarehouse\nWrangling/munging\n\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Data_preparation&oldid=1233853753\""}, {"url": "https://en.wikipedia.org/wiki/Statistical_data_type", "content": "This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources:\u00a0\"Statistical data type\"\u00a0\u2013\u00a0news\u00a0\u00b7 newspapers\u00a0\u00b7 books\u00a0\u00b7 scholar\u00a0\u00b7 JSTOR (June 2014) (Learn how and when to remove this message)\nIn statistics, data can have any of various statistical data types, e.g. categorical data (e.g. country), directional data (angles or directions, e.g. wind measurements), count data (a whole number of events), or real interval (e.g. measures of temperature). The data type is a fundamental concept in statistics, and controls what sorts of probability distributions can logically be used to describe the variable, the permissible operations on the variable, the type of regression analysis used to predict the variable, etc. The concept of data type is similar to the concept of level of measurement, but more specific. For example, count data requires a different distribution (e.g. a Poisson distribution or binomial distribution) than non-negative real-valued data require, but both fall under the same level of measurement (a ratio scale).\nVarious attempts have been made to produce a taxonomy of levels of measurement. The psychophysicist Stanley Smith Stevens defined nominal, ordinal, interval, and ratio scales. Nominal measurements do not have meaningful rank order among values, and permit any one-to-one transformation. Ordinal measurements have imprecise differences between consecutive values, but have a meaningful order to those values, and permit any order-preserving transformation. Interval measurements have meaningful distances between measurements defined, but the zero value is arbitrary (as in the case with longitude and temperature measurements in degree Celsius or degree Fahrenheit), and permit any linear transformation. Ratio measurements have both a meaningful zero value and the distances between different measurements defined, and permit any rescaling transformation.\nBecause variables conforming only to nominal or ordinal measurements cannot be reasonably measured numerically, sometimes they are grouped together as categorical variables, whereas ratio and interval measurements are grouped together as quantitative variables, which can be either discrete or continuous, due to their numerical nature. Such distinctions can often be loosely correlated with data type in computer science, in that dichotomous categorical variables may be represented with the Boolean data type, polytomous categorical variables with arbitrarily assigned integers in the integral data type, and continuous variables with the real data type involving floating point computation. But the mapping of computer science data types to statistical data types depends on which categorization of the latter is being implemented. \nOther categorizations have been proposed. For example, Mosteller and Tukey (1977)[1] distinguished grades, ranks, counted fractions, counts, amounts, and balances. Nelder (1990)[2] described continuous counts, continuous ratios, count ratios, and categorical modes of data. See also Chrisman (1998),[3] van den Berg (1991).[4]\nThe issue of whether or not it is appropriate to apply different kinds of statistical methods to data obtained from different kinds of measurement procedures is complicated by issues concerning the transformation of variables and the precise interpretation of research questions. \"The relationship between the data and what they describe merely reflects the fact that certain kinds of statistical statements may have truth values which are not invariant under some transformations. Whether or not a transformation is sensible to contemplate depends on the question one is trying to answer\" (Hand, 2004, p.\u00a082).[5]\n\nSimple data types[edit]\nThe following table classifies the various simple data types, associated distributions, permissible operations, etc.  Regardless of the logical possible values, all of these data types are generally coded using real numbers, because the theory of random variables often explicitly assumes that they hold real numbers.\n\n\n\nData Type\nPossible values\nExample usage\nLevel ofmeasurement\nCommon\nDistributions\n\n\nScale ofrelativedifferences\nPermissible statistics\nCommon model\n\n\nbinary\n\n0, 1 (arbitrary labels)\n\nbinary outcome (\"yes/no\", \"true/false\", \"success/failure\", etc.)\n\nnominal scale\n\nBernoulli\n\nincomparable\n\nmode, chi-squared\n\nlogistic, probit\n\n\ncategorical\n\n\"name1\", \"name2\", \"name3\", ... \"nameK\" (arbitrary labels)\n\ncategorical outcome with names or places like \"Rome\", \"Amsterdam\", \"Madrid\", \"London\", \"Washington\" (specific blood type, political party, word, etc.)\n\ncategorical\n\nmultinomial logit, multinomial probit\n\n\nordinal\n\nordering categories or integer or real number (arbitrary scale)\n\nOrdering adverbs like \"Small\", \"Medium\", \"Large\", relative score, significant only for creating a ranking\n\nordinal scale\n\ncategorical\n\nrelativecomparison\n\n\n\nordinal regression (ordered logit, ordered probit)\n\n\nbinomial\n\n0, 1, ..., N\n\nnumber of successes (e.g. yes votes) out of N possible\n\ninterval scale\n\nbinomial, beta-binomial\n\nadditive\n\nmean, median, mode, standard deviation, correlation\n\nbinomial regression (logistic, probit)\n\n\ncount\n\nnonnegative integers (0, 1, ...)\n\nnumber of items (telephone calls, people, molecules, births, deaths, etc.) in given interval/area/volume\n\nratio scale\n\nPoisson, negative binomial\n\nmultiplicative\n\nAll statistics permitted for interval scales plus the following: geometric mean, harmonic mean, coefficient of variation\n\nPoisson, negative binomial regression\n\n\nreal-valuedadditive\n\nreal number\n\ntemperature in degree Celsius or degree Fahrenheit, relative distance, location parameter, etc. (or approximately, anything not varying over a large scale)\n\ninterval scale\n\nnormal, etc. (usually symmetric about the mean)\n\nadditive\n\nmean, median, mode, standard deviation, correlation\n\nstandard linear regression\n\n\nreal-valuedmultiplicative\n\npositive real number\n\ntemperature in kelvin, price, income, size, scale parameter, etc. (especially when varying over a large scale)\n\nratio scale\n\nlog-normal, gamma, exponential, etc. (usually a skewed distribution)\n\nmultiplicative\n\nAll statistics permitted for interval scales plus the following: geometric mean, harmonic mean, coefficient of variation\n\ngeneralized linear model with logarithmic link\n\nMultivariate data types[edit]\nData that cannot be described using a single number are often shoehorned into random vectors of real-valued random variables, although there is an increasing tendency to treat them on their own.  Some examples:\n\nRandom vectors.  The individual elements may or may not be correlated.  Examples of distributions used to describe correlated random vectors are the multivariate normal distribution and multivariate t-distribution.  In general, there may be arbitrary correlations between any elements and any others; however, this often becomes unmanageable above a certain size, requiring further restrictions on the correlated elements.\nRandom matrices.  Random matrices can be laid out linearly and treated as random vectors; however, this may not be an efficient way of representing the correlations between different elements.  Some probability distributions are specifically designed for random matrices, e.g. the matrix normal distribution and Wishart distribution.\nRandom sequences.  These are sometimes considered to be the same as random vectors, but in other cases the term is applied specifically to cases where each random variable is only correlated with nearby variables (as in a Markov model).  This is a particular case of a Bayes network and often used for very long sequences, e.g. gene sequences or lengthy text documents.  A number of models are specifically designed for such sequences, e.g. hidden Markov models.\nRandom processes.  These are similar to random sequences, but where the length of the sequence is indefinite or infinite and the elements in the sequence are processed one-by-one.  This is often used for data that can be described as a time series, e.g. the price of a stock on successive days.  Random processes are also used to model values that vary continuously (e.g. the temperature at successive moments in time), rather than at discrete intervals.\nBayes networks.  These correspond to aggregates of random variables described using graphical models, where individual random variables are linked in a graph structure with conditional distributions relating variables to nearby variables.\nMultilevel models are subclasses of Bayes networks that can be thought of as having multiple levels of linear regression.\nRandom trees.  These are a subclass of Bayes network, where the variables are linked in a tree structure.  An example is the problem of parsing a sentence, when statistical parsing techniques are used, such as probabilistic context-free grammars (PCFG's).\nRandom fields.  These represent the extension of random processes to multiple dimensions, and are common in physics, where they are used in statistical mechanics to describe properties such as force or electric field that can vary continuously over three dimensions (or four dimensions, when time is included).\nThese concepts originate in various scientific fields and frequently overlap in usage.  As a result, it is very often the case that multiple concepts could potentially be applied to the same problem.\n\nReferences[edit]\n\n\n^ Mosteller, F.; Tukey, J.W. (1977). Data analysis and regression. Addison-Wesley. ISBN\u00a0978-0-201-04854-4.\n\n^ Nelder, J.A. (1990). \"The knowledge needed to computerise the analysis and interpretation of statistical information\". Expert systems and artificial intelligence: the need for information about data. London: Library Association. OCLC\u00a027042489.\n\n^ Chrisman, Nicholas R. (1998). \"Rethinking Levels of Measurement for Cartography\". Cartography and Geographic Information Science. 25 (4): 231\u2013242. Bibcode:1998CGISy..25..231C. doi:10.1559/152304098782383043.\n\n^ van den Berg, G. (1991). Choosing an analysis method. Leiden: DSWO Press. ISBN\u00a0978-90-6695-062-7.\n\n^ Hand, D.J. (2004). Measurement theory and practice: The world through quantification. Wiley. p.\u00a082. ISBN\u00a0978-0-470-68567-9.\n\n\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Statistical_data_type&oldid=1245718543\""}, {"url": "https://en.wikipedia.org/wiki/Transfer_learning", "content": "Machine learning technique\nIllustration of transfer learning\nTransfer learning (TL) is a technique in machine learning (ML) in which knowledge learned from a task is re-used in order to boost performance on a related task.[1] For example, for image classification, knowledge gained while learning to recognize cars could be applied when trying to recognize trucks. This topic is related to the psychological literature on transfer of learning, although practical ties between the two fields are limited. Reusing/transferring information from previously learned tasks to new tasks has the potential to significantly improve learning efficiency.[2]\nSince transfer learning makes use of training with multiple objective functions it is related to cost-sensitive machine learning and multi-objective optimization.[3]\n\n\nHistory[edit]\nIn 1976, Bozinovski and Fulgosi published a paper addressing transfer learning in neural network training.[4][5] The paper gives a mathematical and geometrical model of the topic. In 1981, a report considered the application of transfer learning to a dataset of images representing letters of computer terminals, experimentally demonstrating positive and negative transfer learning.[6]\nIn 1992, Lorien Pratt formulated the discriminability-based transfer (DBT) algorithm.[7]\nBy 1998, the field had advanced to include multi-task learning,[8] along with more formal theoretical foundations.[9] Influential publications on transfer learning include the book Learning to Learn in 1998,[10] a 2009 survey[11] and a 2019 survey.[12]\nNg said in his NIPS 2016 tutorial[13][14] that TL would become the next driver of machine learning commercial success after supervised learning.\nIn the 2020 paper, \"Rethinking Pre-Training and self-training\",[15] Zoph et al. reported that pre-training can hurt accuracy, and advocate self-training instead.\n\nDefinition[edit]\nThe definition of transfer learning is given in terms of domains and tasks. A domain \n\n\n\n\n\nD\n\n\n\n\n{\\displaystyle {\\mathcal {D}}}\n\n consists of: a feature space \n\n\n\n\n\nX\n\n\n\n\n{\\displaystyle {\\mathcal {X}}}\n\n and a marginal probability distribution \n\n\n\nP\n(\nX\n)\n\n\n{\\displaystyle P(X)}\n\n, where \n\n\n\nX\n=\n{\n\nx\n\n1\n\n\n,\n.\n.\n.\n,\n\nx\n\nn\n\n\n}\n\u2208\n\n\nX\n\n\n\n\n{\\displaystyle X=\\{x_{1},...,x_{n}\\}\\in {\\mathcal {X}}}\n\n. Given a specific domain, \n\n\n\n\n\nD\n\n\n=\n{\n\n\nX\n\n\n,\nP\n(\nX\n)\n}\n\n\n{\\displaystyle {\\mathcal {D}}=\\{{\\mathcal {X}},P(X)\\}}\n\n, a task consists of two components: a label space \n\n\n\n\n\nY\n\n\n\n\n{\\displaystyle {\\mathcal {Y}}}\n\n and an objective predictive function \n\n\n\nf\n:\n\n\nX\n\n\n\u2192\n\n\nY\n\n\n\n\n{\\displaystyle f:{\\mathcal {X}}\\rightarrow {\\mathcal {Y}}}\n\n. The function \n\n\n\nf\n\n\n{\\displaystyle f}\n\n is used to predict the corresponding label \n\n\n\nf\n(\nx\n)\n\n\n{\\displaystyle f(x)}\n\n of a new instance \n\n\n\nx\n\n\n{\\displaystyle x}\n\n. This task, denoted by \n\n\n\n\n\nT\n\n\n=\n{\n\n\nY\n\n\n,\nf\n(\nx\n)\n}\n\n\n{\\displaystyle {\\mathcal {T}}=\\{{\\mathcal {Y}},f(x)\\}}\n\n, is learned from the training data consisting of pairs \n\n\n\n{\n\nx\n\ni\n\n\n,\n\ny\n\ni\n\n\n}\n\n\n{\\displaystyle \\{x_{i},y_{i}\\}}\n\n, where \n\n\n\n\nx\n\ni\n\n\n\u2208\n\n\nX\n\n\n\n\n{\\displaystyle x_{i}\\in {\\mathcal {X}}}\n\n and \n\n\n\n\ny\n\ni\n\n\n\u2208\n\n\nY\n\n\n\n\n{\\displaystyle y_{i}\\in {\\mathcal {Y}}}\n\n.[16]\nGiven a source domain \n\n\n\n\n\n\nD\n\n\n\nS\n\n\n\n\n{\\displaystyle {\\mathcal {D}}_{S}}\n\n and learning task \n\n\n\n\n\n\nT\n\n\n\nS\n\n\n\n\n{\\displaystyle {\\mathcal {T}}_{S}}\n\n, a target domain \n\n\n\n\n\n\nD\n\n\n\nT\n\n\n\n\n{\\displaystyle {\\mathcal {D}}_{T}}\n\nand learning task \n\n\n\n\n\n\nT\n\n\n\nT\n\n\n\n\n{\\displaystyle {\\mathcal {T}}_{T}}\n\n, where \n\n\n\n\n\n\nD\n\n\n\nS\n\n\n\u2260\n\n\n\nD\n\n\n\nT\n\n\n\n\n{\\displaystyle {\\mathcal {D}}_{S}\\neq {\\mathcal {D}}_{T}}\n\n, or \n\n\n\n\n\n\nT\n\n\n\nS\n\n\n\u2260\n\n\n\nT\n\n\n\nT\n\n\n\n\n{\\displaystyle {\\mathcal {T}}_{S}\\neq {\\mathcal {T}}_{T}}\n\n, transfer learning aims to help improve the learning of the target predictive function \n\n\n\n\nf\n\nT\n\n\n(\n\u22c5\n)\n\n\n{\\displaystyle f_{T}(\\cdot )}\n\n in \n\n\n\n\n\n\nD\n\n\n\nT\n\n\n\n\n{\\displaystyle {\\mathcal {D}}_{T}}\n\n using the knowledge in \n\n\n\n\n\n\nD\n\n\n\nS\n\n\n\n\n{\\displaystyle {\\mathcal {D}}_{S}}\n\n and \n\n\n\n\n\n\nT\n\n\n\nS\n\n\n\n\n{\\displaystyle {\\mathcal {T}}_{S}}\n\n.[16]\n\nApplications[edit]\nAlgorithms are available for transfer learning in Markov logic networks[17] and Bayesian networks.[18] Transfer learning has been applied to cancer subtype discovery,[19] building utilization,[20][21] general game playing,[22] text classification,[23][24] digit recognition,[25] medical imaging and spam filtering.[26]\nIn 2020, it was discovered that, due to their similar physical natures, transfer learning is possible between electromyographic (EMG) signals from the muscles and classifying the behaviors of electroencephalographic (EEG) brainwaves, from the gesture recognition domain to the mental state recognition domain. It was noted that this relationship worked in both directions, showing that electroencephalographic can likewise be used to classify EMG.[27] The experiments noted that the accuracy of neural networks and convolutional neural networks were improved[28] through transfer learning both prior to any learning (compared to standard random weight distribution) and at the end of the learning process (asymptote). That is, results are improved by exposure to another domain. Moreover, the end-user of a pre-trained model can change the structure of fully-connected layers to improve performance.[29]\n\nSoftware[edit]\nTransfer learning and domain adaptation \nSeveral compilations of transfer learning and domain adaptation algorithms have been implemented:\n\nADAPT[30] (Python)\nTLlib[31] (Python)\nDomain-Adaptation-Toolbox[32] (Matlab)\nSee also[edit]\nCrossover (genetic algorithm)\nDomain adaptation\nGeneral game playing\nMulti-task learning\nMultitask optimization\nTransfer of learning in educational psychology\nZero-shot learning\nFeature learning\nexternal validity\nReferences[edit]\n\n\n^ West, Jeremy; Ventura, Dan; Warnick, Sean (2007). \"Spring Research Presentation: A Theoretical Foundation for Inductive Transfer\". Brigham Young University, College of Physical and Mathematical Sciences. Archived from the original on 2007-08-01. Retrieved 2007-08-05.\n\n^ George Karimpanal, Thommen; Bouffanais, Roland (2019). \"Self-organizing maps for storage and transfer of knowledge in reinforcement learning\". Adaptive Behavior. 27 (2): 111\u2013126. arXiv:1811.08318. doi:10.1177/1059712318818568. ISSN\u00a01059-7123. S2CID\u00a053774629.\n\n^  Cost-Sensitive Machine Learning.\u00a0(2011).\u00a0USA:\u00a0CRC Press, Page 63, https://books.google.com/books?id=8TrNBQAAQBAJ&pg=PA63\n\n^ Stevo. Bozinovski and Ante Fulgosi (1976). \"The influence of pattern similarity and transfer learning on the base perceptron training.\" (original in Croatian) Proceedings of Symposium Informatica 3-121-5, Bled.\n\n^ Stevo Bozinovski (2020) \"Reminder of the first paper on transfer learning in neural networks, 1976\". Informatica 44: 291\u2013302.\n\n^ S. Bozinovski (1981). \"Teaching space: A representation concept for adaptive pattern classification.\" COINS Technical Report, the University of Massachusetts at Amherst, No 81-28 [available online: UM-CS-1981-028.pdf]\n\n^ Pratt, L. Y. (1992). \"Discriminability-based transfer between neural networks\" (PDF). NIPS Conference: Advances in Neural Information Processing Systems 5. Morgan Kaufmann Publishers. pp.\u00a0204\u2013211.\n\n^ Caruana, R., \"Multitask Learning\", pp. 95-134 in Thrun & Pratt 2012\n\n^ Baxter, J., \"Theoretical Models of Learning to Learn\", pp. 71-95 Thrun & Pratt 2012\n\n^ Thrun & Pratt 2012.\n\n^ Pan, Sinno Jialin; Yang, Qiang (2009). \"A Survey on Transfer Learning\" (PDF). IEEE.\n\n^ Zhuang, Fuzhen; Qi, Zhiyuan; Duan, Keyu; Xi, Dongbo; Zhu, Yongchun; Zhu, Hengshu; Xiong, Hui; He, Qing (2019). \"A Comprehensive Survey on Transfer Learning\". IEEE. arXiv:1911.02685.\n\n^ NIPS 2016 tutorial: \"Nuts and bolts of building AI applications using Deep Learning\" by Andrew Ng, 6 May 2018, archived from the original on 2021-12-19, retrieved 2019-12-28\n\n^ \"Nuts and bolts of building AI applications using Deep Learning, slides\" (PDF).\n\n^ Zoph, Barret (2020). \"Rethinking pre-training and self-training\" (PDF). Advances in Neural Information Processing Systems. 33: 3833\u20133845. arXiv:2006.06882. Retrieved 2022-12-20.\n\n^ a b Lin, Yuan-Pin; Jung, Tzyy-Ping (27 June 2017). \"Improving EEG-Based Emotion Classification Using Conditional Transfer Learning\". Frontiers in Human Neuroscience. 11: 334. doi:10.3389/fnhum.2017.00334. PMC\u00a05486154. PMID\u00a028701938.  Material was copied from this source, which is available under a Creative Commons Attribution 4.0 International License.\n\n^ Mihalkova, Lilyana; Huynh, Tuyen; Mooney, Raymond J. (July 2007), \"Mapping and Revising Markov Logic Networks for Transfer\" (PDF), Learning Proceedings of the 22nd AAAI Conference on Artificial Intelligence (AAAI-2007), Vancouver, BC, pp.\u00a0608\u2013614, retrieved 2007-08-05{{citation}}:  CS1 maint: location missing publisher (link)\n\n^ Niculescu-Mizil, Alexandru; Caruana, Rich (March 21\u201324, 2007), \"Inductive Transfer for Bayesian Network Structure Learning\" (PDF), Proceedings of the Eleventh International Conference on Artificial Intelligence and Statistics (AISTATS 2007), retrieved 2007-08-05\n\n^ Hajiramezanali, E. & Dadaneh, S. Z. & Karbalayghareh, A. & Zhou, Z. & Qian, X. Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data. 32nd Conference on Neural Information Processing Systems (NeurIPS 2018), Montr\u00e9al, Canada. arXiv:1810.09433\n\n^ Arief-Ang, I.B.; Salim, F.D.; Hamilton, M. (2017-11-08). DA-HOC: semi-supervised domain adaptation for room occupancy prediction using CO2 sensor data. 4th ACM International Conference on Systems for Energy-Efficient Built Environments (BuildSys). Delft, Netherlands. pp.\u00a01\u201310. doi:10.1145/3137133.3137146. ISBN\u00a0978-1-4503-5544-5.\n\n^ Arief-Ang, I.B.; Hamilton, M.; Salim, F.D. (2018-12-01). \"A Scalable Room Occupancy Prediction with Transferable Time Series Decomposition of CO2 Sensor Data\". ACM Transactions on Sensor Networks. 14 (3\u20134): 21:1\u201321:28. doi:10.1145/3217214. S2CID\u00a054066723.\n\n^ Banerjee, Bikramjit, and Peter Stone. \"General Game Learning Using Knowledge Transfer.\" IJCAI. 2007.\n\n^ Do, Chuong B.; Ng, Andrew Y. (2005). \"Transfer learning for text classification\". Neural Information Processing Systems Foundation, NIPS*2005 (PDF). Retrieved 2007-08-05.\n\n^ Rajat, Raina; Ng, Andrew Y.; Koller, Daphne (2006). \"Constructing Informative Priors using Transfer Learning\". Twenty-third International Conference on Machine Learning (PDF). Retrieved 2007-08-05.\n\n^ Maitra, D. S.; Bhattacharya, U.; Parui, S. K. (August 2015). \"CNN based common approach to handwritten character recognition of multiple scripts\". 2015 13th International Conference on Document Analysis and Recognition (ICDAR). pp.\u00a01021\u20131025. doi:10.1109/ICDAR.2015.7333916. ISBN\u00a0978-1-4799-1805-8. S2CID\u00a025739012.\n\n^ Bickel, Steffen (2006). \"ECML-PKDD Discovery Challenge 2006 Overview\". ECML-PKDD Discovery Challenge Workshop (PDF). Retrieved 2007-08-05.\n\n^ Bird, Jordan J.; Kobylarz, Jhonatan; Faria, Diego R.; Ekart, Aniko; Ribeiro, Eduardo P. (2020). \"Cross-Domain MLP and CNN Transfer Learning for Biological Signal Processing: EEG and EMG\". IEEE Access. 8. Institute of Electrical and Electronics Engineers (IEEE): 54789\u201354801. Bibcode:2020IEEEA...854789B. doi:10.1109/access.2020.2979074. ISSN\u00a02169-3536.\n\n^ Maitra, Durjoy Sen; Bhattacharya, Ujjwal; Parui, Swapan K. (August 2015). \"CNN based common approach to handwritten character recognition of multiple scripts\". 2015 13th International Conference on Document Analysis and Recognition (ICDAR). pp.\u00a01021\u20131025. doi:10.1109/ICDAR.2015.7333916. ISBN\u00a0978-1-4799-1805-8. S2CID\u00a025739012.\n\n^ Kabir, H. M. Dipu; Abdar, Moloud; Jalali, Seyed Mohammad Jafar; Khosravi, Abbas; Atiya, Amir F.; Nahavandi, Saeid; Srinivasan, Dipti (January 7, 2022). \"SpinalNet: Deep Neural Network with Gradual Input\". IEEE Transactions on Artificial Intelligence. 4 (5): 1165\u20131177. arXiv:2007.03347. doi:10.1109/TAI.2022.3185179. S2CID\u00a0220381239.\n\n^ de Mathelin, Antoine and Deheeger, Fran\u00e7ois and Richard, Guillaume and Mougeot, Mathilde and Vayatis, Nicolas (2020) \"ADAPT: Awesome Domain Adaptation Python Toolbox\"\n\n^ Mingsheng Long Junguang Jiang, Bo Fu. (2020) \"Transfer-learning-library\"\n\n^ Ke Yan. (2016) \"Domain adaptation toolbox\"\n\n\nSources[edit]\nThrun, Sebastian; Pratt, Lorien (6 December 2012). Learning to Learn. Springer Science & Business Media. ISBN\u00a0978-1-4615-5529-2.\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Transfer_learning&oldid=1254066456\""}, {"url": "https://en.wikipedia.org/wiki/Ensemble_learning", "content": "Statistics and machine learning technique\n\nPart of a series onMachine learningand data mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\n\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\n\nSupervised learning(classification\u00a0\u2022 regression) \nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\n\nClustering\nBIRCH\nCURE\nHierarchical\nk-means\nFuzzy\nExpectation\u2013maximization (EM)\nDBSCAN\nOPTICS\nMean shift\n\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\n\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\n\nAnomaly detection\nRANSAC\nk-NN\nLocal outlier factor\nIsolation forest\n\nArtificial neural network\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural radiance field\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM (ECRAM)\n\nReinforcement learning\nQ-learning\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\n\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nRLHF\n\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\n\nMathematical foundations\nKernel machines\nBias\u2013variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\n\nJournals and conferences\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\n\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nvte\nIn statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone.[1][2][3]\nUnlike a statistical ensemble in statistical mechanics, which is usually infinite, a machine learning ensemble consists of only a concrete finite set of alternative models, but typically allows for much more flexible structure to exist among those alternatives.\n\n\nOverview[edit]\nSupervised learning algorithms search through a hypothesis space to find a suitable hypothesis that will make good predictions with a particular problem.[4] Even if this space contains hypotheses that are very well-suited for a particular problem, it may be very difficult to find a good one. Ensembles combine multiple hypotheses to form one which should be theoretically better.\nEnsemble learning trains two or more machine learning algorithms on a specific classification or regression task. The algorithms within the ensemble model are generally referred as \"base models\", \"base learners\", or \"weak learners\" in literature. These base models can be constructed using a single modelling algorithm, or several different algorithms. The idea is to train a diverse set of weak models on the same modelling task, such that the outputs of each weak learner have poor predictive ability (i.e., high bias), and among all weak learners, the outcome and error values exhibit high variance. Fundamentally, an ensemble learning model trains at least two high-bias (weak) and high-variance (diverse) models to be combined into a better-performing model. The set of weak models \u2014 which would not produce satisfactory predictive results individually \u2014 are combined or averaged to produce a single, high performing, accurate, and low-variance model to fit the task as required.\nEnsemble learning typically refers to bagging (bootstrap aggregating), boosting or stacking/blending techniques to induce high variance among the base models. Bagging creates diversity by generating random samples from the training observations and fitting the same model to each different sample \u2014 also known as homogeneous parallel ensembles. Boosting follows an iterative process by sequentially training each base model on the up-weighted errors of the previous base model, producing an additive model to reduce the final model errors \u2014 also known as sequential ensemble learning. Stacking or blending consists of different base models, each trained independently (i.e. diverse/high variance) to be combined into the ensemble model \u2014 producing a heterogeneous parallel ensemble. Common applications of ensemble learning include random forests (an extension of bagging), Boosted Tree models, and Gradient Boosted Tree Models. Models in applications of stacking are generally more task-specific \u2014 such as combining clustering techniques with other parametric and/or non-parametric techniques.[5]\nThe broader term of multiple classifier systems also covers hybridization of hypotheses that are not induced by the same base learner.[citation needed]\nEvaluating the prediction of an ensemble typically requires more computation than evaluating the prediction of a single model. In one sense, ensemble learning may be thought of as a way to compensate for poor learning algorithms by performing a lot of extra computation. On the other hand, the alternative is to do a lot more learning with one non-ensemble model. An ensemble may be more efficient at improving overall accuracy for the same increase in compute, storage, or communication resources by using that increase on two or more methods, than would have been improved by increasing resource use for a single method. Fast algorithms such as decision trees are commonly used in ensemble methods (e.g., random forests), although slower algorithms can benefit from ensemble techniques as well.\nBy analogy, ensemble techniques have been used also in unsupervised learning scenarios, for example in consensus clustering or in anomaly detection.\n\nEnsemble theory[edit]\nEmpirically, ensembles tend to yield better results when there is a significant diversity among the models.[6][7] Many ensemble methods, therefore, seek to promote diversity among the models they combine.[8][9] Although perhaps non-intuitive, more random algorithms (like random decision trees) can be used to produce a stronger ensemble than very deliberate algorithms (like entropy-reducing decision trees).[10] Using a variety of strong learning algorithms, however, has been shown to be more effective than using techniques that attempt to dumb-down the models in order to promote diversity.[11] It is possible to increase diversity in the training stage of the model using correlation for regression tasks [12] or using information measures such as cross entropy for classification tasks.[13]\n\nAn ensemble of classifiers usually has smaller classification error than base models.\nTheoretically, one can justify the diversity concept because the lower bound of the error rate of an ensemble system can be decomposed into accuracy, diversity, and the other term.[14]\n\nThe geometric framework[edit]\nEnsemble learning, including both regression and classification tasks, can be explained using a geometric framework.[15] Within this framework, the output of each individual classifier or regressor for the entire dataset can be viewed as a point in a multi-dimensional space. Additionally, the target result is also represented as a point in this space, referred to as the \"ideal point.\"\nThe Euclidean distance is used as the metric to measure both the performance of a single classifier or regressor (the distance between its point and the ideal point) and the dissimilarity between two classifiers or regressors (the distance between their respective points). This perspective transforms ensemble learning into a deterministic problem.\nFor example, within this geometric framework, it can be proved that the averaging of the outputs (scores) of all base classifiers or regressors can lead to equal or better results than the average of all the individual models. It can also be proved that if the optimal weighting scheme is used, then a weighted averaging approach can outperform any of the individual classifiers or regressors that make up the ensemble or as good as the best performer at least.\n\nEnsemble size[edit]\nWhile the number of component classifiers of an ensemble has a great impact on the accuracy of prediction, there is a limited number of studies addressing this problem. A priori determining of ensemble size and the volume and velocity of big data streams make this even more crucial for online ensemble classifiers. Mostly statistical tests were used for determining the proper number of components. More recently, a theoretical framework suggested that there is an ideal number of component classifiers for an ensemble such that having more or less than this number of classifiers would deteriorate the accuracy. It is called \"the law of diminishing returns in ensemble construction.\" Their theoretical framework shows that using the same number of independent component classifiers as class labels gives the highest accuracy.[16][17]\n\nCommon types of ensembles[edit]\nBayes optimal classifier[edit]\nMain article: Bayes classifier\nThe Bayes optimal classifier is a classification technique. It is an ensemble of all the hypotheses in the hypothesis space. On average, no other ensemble can outperform it.[18] The Naive Bayes classifier is a version of this that assumes that the data is conditionally independent on the class and makes the computation more feasible. Each hypothesis is given a vote proportional to the likelihood that the training dataset would be sampled from a system if that hypothesis were true. To facilitate training data of finite size, the vote of each hypothesis is also multiplied by the prior probability of that hypothesis. The Bayes optimal classifier can be expressed with the following equation:\n\n\n\n\n\ny\n=\n\n\n\na\nr\ng\nm\na\nx\n\n\n\nc\n\nj\n\n\n\u2208\nC\n\n\n\n\n\u2211\n\n\nh\n\ni\n\n\n\u2208\nH\n\n\n\nP\n(\n\nc\n\nj\n\n\n\n|\n\n\nh\n\ni\n\n\n)\nP\n(\nT\n\n|\n\n\nh\n\ni\n\n\n)\nP\n(\n\nh\n\ni\n\n\n)\n\n\n\n{\\displaystyle y={\\underset {c_{j}\\in C}{\\mathrm {argmax} }}\\sum _{h_{i}\\in H}{P(c_{j}|h_{i})P(T|h_{i})P(h_{i})}}\n\n\nwhere \n\n\n\ny\n\n\n{\\displaystyle y}\n\n is the predicted class, \n\n\n\nC\n\n\n{\\displaystyle C}\n\n is the set of all possible classes, \n\n\n\nH\n\n\n{\\displaystyle H}\n\n is the hypothesis space, \n\n\n\nP\n\n\n{\\displaystyle P}\n\n refers to a probability, and \n\n\n\nT\n\n\n{\\displaystyle T}\n\n is the training data. As an ensemble, the Bayes optimal classifier represents a hypothesis that is not necessarily in \n\n\n\nH\n\n\n{\\displaystyle H}\n\n. The hypothesis represented by the Bayes optimal classifier, however, is the optimal hypothesis in ensemble space (the space of all possible ensembles consisting only of hypotheses in \n\n\n\nH\n\n\n{\\displaystyle H}\n\n).\nThis formula can be restated using Bayes' theorem, which says that the posterior is proportional to the likelihood times the prior:\n\n\n\n\n\nP\n(\n\nh\n\ni\n\n\n\n|\n\nT\n)\n\u221d\nP\n(\nT\n\n|\n\n\nh\n\ni\n\n\n)\nP\n(\n\nh\n\ni\n\n\n)\n\n\n{\\displaystyle P(h_{i}|T)\\propto P(T|h_{i})P(h_{i})}\n\n\nhence,\n\n\n\n\n\ny\n=\n\n\n\na\nr\ng\nm\na\nx\n\n\n\nc\n\nj\n\n\n\u2208\nC\n\n\n\n\n\u2211\n\n\nh\n\ni\n\n\n\u2208\nH\n\n\n\nP\n(\n\nc\n\nj\n\n\n\n|\n\n\nh\n\ni\n\n\n)\nP\n(\n\nh\n\ni\n\n\n\n|\n\nT\n)\n\n\n\n{\\displaystyle y={\\underset {c_{j}\\in C}{\\mathrm {argmax} }}\\sum _{h_{i}\\in H}{P(c_{j}|h_{i})P(h_{i}|T)}}\n\n\nBootstrap aggregating (bagging)[edit]\nMain article: Bootstrap aggregatingThree datasets bootstrapped from an original set. Example A occurs twice in set 1 because these are chosen with replacement.Bootstrap aggregation (bagging) involves training an ensemble on bootstrapped data sets. A bootstrapped set is created by selecting from original training data set with replacement. Thus, a bootstrap set may contain a given example zero, one, or multiple times. Ensemble members can also have limits on the features (e.g., nodes of a decision tree), to encourage exploring of diverse features.[19] The variance of local information in the bootstrap sets and feature considerations promote diversity in the ensemble, and can strengthen the ensemble.[20] To reduce overfitting, a member can be validated using the out-of-bag set (the examples that are not in its bootstrap set).[21]\nInference is done by voting of predictions of ensemble members, called aggregation. It is illustrated below with an ensemble of four decision trees. The query example is classified by each tree. Because three of the four predict the positive class, the ensemble's overall classification is positive. Random forests like the one shown are a common application of bagging.\n\nAn example of the aggregation process for an ensemble of decision trees. Individual classifications are aggregated, and an overall classification is derived.\nBoosting[edit]\nMain article: Boosting (meta-algorithm)\nBoosting involves training successive models by emphasizing training data mis-classified by previously learned models. Initially, all data (D1) has equal weight and is used to learn a base model M1. The examples mis-classified by M1 are assigned a weight greater than correctly classified examples. This boosted data (D2) is used to train a second base model M2, and so on. Inference is done by voting.\nIn some cases, boosting has yielded better accuracy than bagging, but tends to over-fit more. The most common implementation of boosting is Adaboost, but some newer algorithms are reported to achieve better results.[citation needed]\n\nBayesian model averaging[edit]\nBayesian model averaging (BMA) makes predictions by averaging the predictions of models weighted by their posterior probabilities given the data.[22] BMA is known to generally give better answers than a single model, obtained, e.g., via stepwise regression, especially where very different models have nearly identical performance in the training set but may otherwise perform quite differently.\nThe question with any use of Bayes' theorem is the prior, i.e., the probability (perhaps subjective) that each model is the best to use for a given purpose.  Conceptually, BMA can be used with any prior.  R packages ensembleBMA[23] and BMA[24] use the prior implied by the Bayesian information criterion, (BIC), following Raftery (1995).[25] R package BAS supports the use of the priors implied by Akaike information criterion (AIC) and other criteria over the alternative models as well as priors over the coefficients.[26]\nThe difference between BIC and AIC is the strength of preference for parsimony.  BIC's penalty for model complexity is \n\n\n\nln\n\u2061\n(\nn\n)\nk\n\n\n{\\displaystyle \\ln(n)k}\n\n , while AIC's is \n\n\n\n2\nk\n\n\n{\\displaystyle 2k}\n\n. Large-sample asymptotic theory establishes that if there is a best model, then with increasing sample sizes, BIC is strongly consistent, i.e., will almost certainly find it, while AIC may not, because AIC may continue to place excessive posterior probability on models that are more complicated than they need to be. On the other hand, AIC and AICc are asymptotically \"efficient\" (i.e., minimum mean square prediction error), while BIC is not .[27]\nHaussler et al. (1994) showed that when BMA is used for classification, its expected error is at most twice the expected error of the Bayes optimal classifier.[28] Burnham and Anderson (1998, 2002) contributed greatly to introducing a wider audience to the basic ideas of Bayesian model averaging and popularizing the methodology.[29] The availability of software, including other free open-source packages for R beyond those mentioned above, helped make the methods accessible to a wider audience.[30]\n\nBayesian model combination[edit]\nBayesian model combination (BMC) is an algorithmic correction to Bayesian model averaging (BMA). Instead of sampling each model in the ensemble individually, it samples from the space of possible ensembles (with model weights drawn randomly from a Dirichlet distribution having uniform parameters). This modification overcomes the tendency of BMA to converge toward giving all the weight to a single model. Although BMC is somewhat more computationally expensive than BMA, it tends to yield dramatically better results. BMC has been shown to be better on average (with statistical significance) than BMA and bagging.[31]\nUse of Bayes' law to compute model weights requires computing the probability of the data given each model. Typically, none of the models in the ensemble are exactly the distribution from which the training data were generated, so all of them correctly receive a value close to zero for this term. This would work well if the ensemble were big enough to sample the entire model-space, but this is rarely possible. Consequently, each pattern in the training data will cause the ensemble weight to shift toward the model in the ensemble that is closest to the distribution of the training data. It essentially reduces to an unnecessarily complex method for doing model selection.\nThe possible weightings for an ensemble can be visualized as lying on a simplex. At each vertex of the simplex, all of the weight is given to a single model in the ensemble. BMA converges toward the vertex that is closest to the distribution of the training data. By contrast, BMC converges toward the point where this distribution projects onto the simplex. In other words, instead of selecting the one model that is closest to the generating distribution, it seeks the combination of models that is closest to the generating distribution.\nThe results from BMA can often be approximated by using cross-validation to select the best model from a bucket of models. Likewise, the results from BMC may be approximated by using cross-validation to select the best ensemble combination from a random sampling of possible weightings.\n\nBucket of models[edit]\nA \"bucket of models\" is an ensemble technique in which a model selection algorithm is used to choose the best model for each problem. When tested with only one problem, a bucket of models can produce no better results than the best model in the set, but when evaluated across many problems, it will typically produce much better results, on average, than any model in the set.\nThe most common approach used for model-selection is cross-validation selection (sometimes called a \"bake-off contest\"). It is described with the following pseudo-code:\n\nFor each model m in the bucket:\n    Do c times: (where 'c' is some constant)\n        Randomly divide the training dataset into two sets: A and B\n        Train m with A\n        Test m with B\nSelect the model that obtains the highest average score\n\nCross-Validation Selection can be summed up as: \"try them all with the training set, and pick the one that works best\".[32]\nGating is a generalization of Cross-Validation Selection. It involves training another learning model to decide which of the models in the bucket is best-suited to solve the problem. Often, a perceptron is used for the gating model. It can be used to pick the \"best\" model, or it can be used to give a linear weight to the predictions from each model in the bucket.\nWhen a bucket of models is used with a large set of problems, it may be desirable to avoid training some of the models that take a long time to train. Landmark learning is a meta-learning approach that seeks to solve this problem. It involves training only the fast (but imprecise) algorithms in the bucket, and then using the performance of these algorithms to help determine which slow (but accurate) algorithm is most likely to do best.[33]\n\nAmended Cross-Entropy Cost: An Approach for Encouraging Diversity in Classification Ensemble[edit]\nThe most common approach for training classifier is using Cross-entropy cost function. However, one would like to train an ensemble of models that have diversity so when we combine them it would provide best results.[34][35]\nAssuming we use a simple ensemble of averaging \n\n\n\nK\n\n\n{\\displaystyle K}\n\n classifiers. Then the Amended Cross-Entropy Cost is\n\n\n\n\n\n\ne\n\nk\n\n\n=\nH\n(\np\n,\n\nq\n\nk\n\n\n)\n\u2212\n\n\n\u03bb\nK\n\n\n\n\u2211\n\nj\n\u2260\nk\n\n\nH\n(\n\nq\n\nj\n\n\n,\n\nq\n\nk\n\n\n)\n\n\n{\\displaystyle e^{k}=H(p,q^{k})-{\\frac {\\lambda }{K}}\\sum _{j\\neq k}H(q^{j},q^{k})}\n\n\nwhere \n\n\n\n\ne\n\nk\n\n\n\n\n{\\displaystyle e^{k}}\n\n is the cost function of the \n\n\n\n\nk\n\nt\nh\n\n\n\n\n{\\displaystyle k^{th}}\n\n classifier, \n\n\n\n\nq\n\nk\n\n\n\n\n{\\displaystyle q^{k}}\n\n is the probability of the \n\n\n\n\nk\n\nt\nh\n\n\n\n\n{\\displaystyle k^{th}}\n\n classifier, \n\n\n\np\n\n\n{\\displaystyle p}\n\n is the true probability that we need to estimate and \n\n\n\n\u03bb\n\n\n{\\displaystyle \\lambda }\n\n is a parameter between 0 and 1 that define the diversity that we would like to establish. When \n\n\n\n\u03bb\n=\n0\n\n\n{\\displaystyle \\lambda =0}\n\n we want each classifier to do its best regardless of the ensemble and when \n\n\n\n\u03bb\n=\n1\n\n\n{\\displaystyle \\lambda =1}\n\n we would like the classifier to be as diverse as possible.\n\nStacking[edit]\nStacking (sometimes called stacked generalization) involves training a model to combine the predictions of several other learning algorithms. First, all of the other algorithms are trained using the available data, then a combiner algorithm (final estimator) is trained to make a final prediction using all the predictions of the other algorithms (base estimators) as additional inputs or using cross-validated predictions from the base estimators which can prevent overfitting.[36] If an arbitrary combiner algorithm is used, then stacking can theoretically represent any of the ensemble techniques described in this article, although, in practice, a logistic regression model is often used as the combiner.\nStacking typically yields performance better than any single one of the trained models.[37] It has been successfully used on both supervised learning tasks (regression,[38] classification and distance learning [39]) and unsupervised learning (density estimation).[40] It has also been used to estimate bagging's error rate.[3][41] It has been reported to out-perform Bayesian model-averaging.[42] The two top-performers in the Netflix competition utilized blending, which may be considered a form of stacking.[43]\n\nVoting[edit]\nVoting is another form of ensembling. See e.g. Weighted majority algorithm (machine learning).\n\nImplementations in statistics packages[edit]\nR: at least three packages offer Bayesian model averaging tools,[44] including the BMS (an acronym for Bayesian Model Selection) package,[45] the BAS (an acronym for Bayesian Adaptive Sampling) package,[46] and the BMA package.[47]\nPython: scikit-learn, a package for machine learning in Python offers packages for ensemble learning including packages for bagging, voting and averaging methods.\nMATLAB: classification ensembles are implemented in Statistics and Machine Learning Toolbox.[48]\nEnsemble learning applications[edit]\nIn recent years, due to growing computational power, which allows for training in large ensemble learning in a reasonable time frame, the number of ensemble learning applications has grown increasingly.[49] Some of the applications of ensemble classifiers include:\n\nRemote sensing[edit]\nMain article: Remote sensing\nLand cover mapping[edit]\nLand cover mapping is one of the major applications of Earth observation satellite sensors, using remote sensing and geospatial data, to identify the materials and objects which are located on the surface of target areas. Generally, the classes of target materials include roads, buildings, rivers, lakes, and vegetation.[50] Some different ensemble learning approaches based on artificial neural networks,[51] kernel principal component analysis (KPCA),[52] decision trees with boosting,[53] random forest[50][54] and automatic design of multiple classifier systems,[55] are proposed to efficiently identify land cover objects.\n\nChange detection[edit]\nChange detection is an image analysis problem, consisting of the identification of places where the land cover has changed over time. Change detection is widely used in fields such as urban growth, forest and vegetation dynamics, land use and disaster monitoring.[56]\nThe earliest applications of ensemble classifiers in change detection are designed with the majority voting,[57] Bayesian model averaging,[58] and the maximum posterior probability.[59] Given the growth of satellite data over time, the past decade sees more use of time series methods for continuous change detection from image stacks.[60] One example is a Bayesian ensemble changepoint detection method called BEAST, with the software available as a package Rbeast in R, Python, and Matlab.[61]\n\nComputer security[edit]\nDistributed denial of service[edit]\nDistributed denial of service is one of the most threatening cyber-attacks that may happen to an internet service provider.[49] By combining the output of single classifiers, ensemble classifiers reduce the total error of detecting and discriminating such attacks from legitimate flash crowds.[62]\n\nMalware Detection[edit]\nClassification of malware codes such as computer viruses, computer worms, trojans, ransomware and spywares with the usage of machine learning techniques, is inspired by the document categorization problem.[63] Ensemble learning systems have shown a proper efficacy in this area.[64][65]\n\nIntrusion detection[edit]\nAn intrusion detection system monitors computer network or computer systems to identify intruder codes like an anomaly detection process. Ensemble learning successfully aids such monitoring systems to reduce their total error.[66][67]\n\nFace recognition[edit]\nMain article: Face recognition\nFace recognition, which recently has become one of the most popular research areas of pattern recognition, copes with identification or verification of a person by their digital images.[68]\nHierarchical ensembles based on Gabor Fisher classifier and independent component analysis preprocessing techniques are some of the earliest ensembles employed in this field.[69][70][71]\n\nEmotion recognition[edit]\nMain article: Emotion recognition\nWhile speech recognition is mainly based on deep learning because most of the industry players in this field like Google, Microsoft and IBM reveal that the core technology of their speech recognition is based on this approach, speech-based emotion recognition can also have a satisfactory performance with ensemble learning.[72][73]\nIt is also being successfully used in facial emotion recognition.[74][75][76]\n\nFraud detection[edit]\nMain article: Fraud detection\nFraud detection deals with the identification of bank fraud, such as money laundering, credit card fraud and telecommunication fraud, which have vast domains of research and applications of machine learning. Because ensemble learning improves the robustness of the normal behavior modelling, it has been proposed as an efficient technique to detect such fraudulent cases and activities in banking and credit card systems.[77][78]\n\nFinancial decision-making[edit]\nThe accuracy of prediction of business failure is a very crucial issue in financial decision-making. Therefore, different ensemble classifiers are proposed to predict financial crises and financial distress.[79] Also, in the trade-based manipulation problem, where traders attempt to manipulate stock prices by buying and selling activities, ensemble classifiers are required to analyze the changes in the stock market data and detect suspicious symptom of stock price manipulation.[79]\n\nMedicine[edit]\nEnsemble classifiers have been successfully applied in neuroscience, proteomics and medical diagnosis like in neuro-cognitive disorder (i.e. Alzheimer or myotonic dystrophy) detection based on MRI datasets,[80][81][82] and cervical cytology classification.[83][84]\n\nSee also[edit]\nEnsemble averaging (machine learning)\nBayesian structural time series (BSTS)\nReferences[edit]\n\n\n^ Opitz, D.; Maclin, R. (1999). \"Popular ensemble methods: An empirical study\". Journal of Artificial Intelligence Research. 11: 169\u2013198. arXiv:1106.0257. doi:10.1613/jair.614.\n\n^ Polikar, R. (2006). \"Ensemble based systems in decision making\". IEEE Circuits and Systems Magazine. 6 (3): 21\u201345. doi:10.1109/MCAS.2006.1688199. S2CID\u00a018032543.\n\n^ a b Rokach, L. (2010). \"Ensemble-based classifiers\". Artificial Intelligence Review. 33 (1\u20132): 1\u201339. doi:10.1007/s10462-009-9124-7. hdl:11323/1748. S2CID\u00a011149239.\n\n^ Blockeel H. (2011). \"Hypothesis Space\". Encyclopedia of Machine Learning. pp.\u00a0511\u2013513. doi:10.1007/978-0-387-30164-8_373. ISBN\u00a0978-0-387-30768-8.\n\n^ Ibomoiye Domor Mienye, Yanxia Sun (2022). A Survey of Ensemble Learning: Concepts, Algorithms, Applications and Prospects.\n\n^ Kuncheva, L. and Whitaker, C., Measures of diversity in classifier ensembles, Machine Learning, 51, pp. 181-207, 2003\n\n^ Sollich, P. and Krogh, A., Learning with ensembles: How overfitting can be useful, Advances in Neural Information Processing Systems, volume 8, pp. 190-196, 1996.\n\n^ Brown, G. and Wyatt, J. and Harris, R. and Yao, X., Diversity creation methods: a survey and categorisation., Information Fusion, 6(1), pp.5-20, 2005.\n\n^ Adeva, J. J. Garc\u00eda; Cervi\u00f1o, Ulises; Calvo, R. (December 2005). \"Accuracy and Diversity in Ensembles of Text Categorisers\" (PDF). CLEI Journal. 8 (2): 1:1\u20131:12. doi:10.19153/cleiej.8.2.1 (inactive 1 November 2024).{{cite journal}}:  CS1 maint: DOI inactive as of November 2024 (link)\n\n^ Ho, T., Random Decision Forests, Proceedings of the Third International Conference on Document Analysis and Recognition, pp. 278-282, 1995.\n\n^ Gashler, M.; Giraud-Carrier, C.; Martinez, T. (2008). \"Decision Tree Ensemble: Small Heterogeneous is Better Than Large Homogeneous\" (PDF). 2008 Seventh International Conference on Machine Learning and Applications. Vol.\u00a02008. pp.\u00a0900\u2013905. doi:10.1109/ICMLA.2008.154. ISBN\u00a0978-0-7695-3495-4. S2CID\u00a0614810.\n\n^ Liu, Y.; Yao, X. (December 1999). \"Ensemble learning via negative correlation\". Neural Networks. 12 (10): 1399\u20131404. doi:10.1016/S0893-6080(99)00073-8. ISSN\u00a00893-6080. PMID\u00a012662623.\n\n^ Shoham, Ron; Permuter, Haim (2019). \"Amended Cross-Entropy Cost: An Approach for Encouraging Diversity in Classification Ensemble (Brief Announcement)\". Cyber Security Cryptography and Machine Learning. Lecture Notes in Computer Science. Vol.\u00a011527. pp.\u00a0202\u2013207. doi:10.1007/978-3-030-20951-3_18. ISBN\u00a0978-3-030-20950-6. S2CID\u00a0189926552.\n\n^ Terufumi Morishita et al, Rethinking Fano\u2019s Inequality in Ensemble Learning, International Conference on Machine Learning, 2022\n\n^ Wu, S., Li, J., & Ding, W. (2023) A geometric framework for multiclass ensemble classifiers, Machine Learning, 112(12), pp. 4929-4958. doi:10.1007/S10994-023-06406-W\n\n^ R. Bonab, Hamed; Can, Fazli (2016). A Theoretical Framework on the Ideal Number of Classifiers for Online Ensembles in Data Streams. CIKM. USA: ACM. p.\u00a02053.\n\n^ Bonab, Hamed; Can, Fazli (2017). \"Less is More: A Comprehensive Framework for the Number of Components of Ensemble Classifiers\". arXiv:1709.02925 [cs.LG].\n\n^ Tom M. Mitchell, Machine Learning, 1997, pp. 175\n\n^ Salman, R., Alzaatreh, A., Sulieman, H., & Faisal, S. (2021). A Bootstrap Framework for Aggregating within and between Feature Selection Methods. Entropy (Basel, Switzerland), 23(2), 200. doi:10.3390/e23020200\n\n^ Breiman, L., Bagging Predictors, Machine Learning, 24(2), pp.123-140, 1996. doi:10.1007/BF00058655\n\n^ Brodeur, Z. P., Herman, J. D., & Steinschneider, S. (2020). Bootstrap aggregation and cross-validation methods to reduce overfitting in reservoir control policy search. Water Resources Research, 56, e2020WR027184. doi:10.1029/2020WR027184\n\n^ e.g., Jennifer A. Hoeting; David Madigan; Adrian Raftery; Chris Volinsky (1999). \"Bayesian Model Averaging: A Tutorial\". Statistical Science. ISSN\u00a00883-4237. Wikidata\u00a0Q98974344.\n\n^ Chris Fraley; Adrian Raftery; J. McLean Sloughter; Tilmann Gneiting, ensembleBMA: Probabilistic Forecasting using Ensembles and Bayesian Model Averaging, Wikidata\u00a0Q98972500\n\n^ Adrian Raftery; Jennifer A. Hoeting; Chris Volinsky; Ian Painter; Ka Yee Yeung, BMA: Bayesian Model Averaging, Wikidata\u00a0Q91674106.\n\n^ Adrian Raftery (1995). \"Bayesian model selection in social research\". Sociological Methodology: 111\u2013196. doi:10.2307/271063. ISSN\u00a00081-1750. Wikidata\u00a0Q91670340.\n\n^ Merlise A. Clyde; Michael L. Littman; Quanli Wang; Joyee Ghosh; Yingbo Li; Don van den Bergh, BAS: Bayesian Variable Selection and Model Averaging using Bayesian Adaptive Sampling, Wikidata\u00a0Q98974089.\n\n^ Gerda Claeskens; Nils Lid Hjort (2008), Model selection and model averaging, Cambridge University Press, Wikidata\u00a0Q62568358, ch. 4.\n\n^ Haussler, David; Kearns, Michael; Schapire, Robert E. (1994). \"Bounds on the sample complexity of Bayesian learning using information theory and the VC dimension\". Machine Learning. 14: 83\u2013113. doi:10.1007/bf00993163.\n\n^ Kenneth P. Burnham; David R. Anderson (1998), Model Selection and Inference: A practical information-theoretic approach, Springer Science+Business Media, Wikidata\u00a0Q62670082 and Kenneth P. Burnham; David R. Anderson (2002), Model Selection and Multimodel Inference: A practical information-theoretic approach, Springer Science+Business Media, Wikidata\u00a0Q76889160.\n\n^ The Wikiversity article on Searching R Packages mentions several ways to find available packages for something like this.  For example, \"sos::findFn('{Bayesian model averaging}')\" from within R will search for help files in contributed packages that includes the search term and open two tabs in the default browser.  The first will list all the help files found sorted by package.  The second summarizes the packages found, sorted by the apparent strength of the match.\n\n^ Monteith, Kristine; Carroll, James; Seppi, Kevin; Martinez, Tony. (2011). Turning Bayesian Model Averaging into Bayesian Model Combination (PDF). Proceedings of the International Joint Conference on Neural Networks IJCNN'11. pp.\u00a02657\u20132663.\n\n^ Saso Dzeroski, Bernard Zenko, Is Combining Classifiers Better than Selecting the Best One, Machine Learning, 2004, pp. 255-273\n\n^ Bensusan, Hilan; Giraud-Carrier, Christophe (2000). \"Discovering Task Neighbourhoods through Landmark Learning Performances\" (PDF). Principles of Data Mining and Knowledge Discovery. Lecture Notes in Computer Science. Vol.\u00a01910. pp.\u00a0325\u2013330. doi:10.1007/3-540-45372-5_32. ISBN\u00a0978-3-540-41066-9.\n\n^ Shoham, Ron; Permuter, Haim (2019). \"Amended Cross-Entropy Cost: An Approach for Encouraging Diversity in Classification Ensemble (Brief Announcement)\". Cyber Security Cryptography and Machine Learning. Lecture Notes in Computer Science. Vol.\u00a011527. pp.\u00a0202\u2013207. doi:10.1007/978-3-030-20951-3_18. ISBN\u00a0978-3-030-20950-6.\n\n^ Shoham, Ron; Permuter, Haim (2020). \"Amended Cross Entropy Cost: Framework For Explicit Diversity Encouragement\". arXiv:2007.08140 [cs.LG].\n\n^ \"1.11. Ensemble methods\".\n\n^ Wolpert (1992). \"Stacked Generalization\". Neural Networks. 5 (2): 241\u2013259. doi:10.1016/s0893-6080(05)80023-1.\n\n^ Breiman, Leo (1996). \"Stacked regressions\". Machine Learning. 24: 49\u201364. doi:10.1007/BF00117832.\n\n^ Ozay, M.; Yarman Vural, F. T. (2013). \"A New Fuzzy Stacked Generalization Technique and Analysis of its Performance\". arXiv:1204.0171 [cs.LG].\n\n^ Smyth, Padhraic; Wolpert, David (1999). \"Linearly Combining Density Estimators via Stacking\" (PDF). Machine Learning. 36 (1): 59\u201383. doi:10.1023/A:1007511322260. S2CID\u00a016006860.\n\n^ Wolpert, David H.; MacReady, William G. (1999). \"An Efficient Method to Estimate Bagging's Generalization Error\" (PDF). Machine Learning. 35 (1): 41\u201355. doi:10.1023/A:1007519102914. S2CID\u00a014357246.\n\n^ Clarke, B., Bayes model averaging and stacking when model approximation error cannot be ignored, Journal of Machine Learning Research, pp 683-712, 2003\n\n^ Sill, J.; Takacs, G.; Mackey, L.; Lin, D. (2009). \"Feature-Weighted Linear Stacking\". arXiv:0911.0460 [cs.LG].\n\n^ Amini, Shahram M.; Parmeter, Christopher F. (2011). \"Bayesian model averaging in R\" (PDF). Journal of Economic and Social Measurement. 36 (4): 253\u2013287. doi:10.3233/JEM-2011-0350.\n\n^ \"BMS: Bayesian Model Averaging Library\". The Comprehensive R Archive Network. 2015-11-24. Retrieved September 9, 2016.\n\n^ \"BAS: Bayesian Model Averaging using Bayesian Adaptive Sampling\". The Comprehensive R Archive Network. Retrieved September 9, 2016.\n\n^ \"BMA: Bayesian Model Averaging\". The Comprehensive R Archive Network. Retrieved September 9, 2016.\n\n^ \"Classification Ensembles\". MATLAB & Simulink. Retrieved June 8, 2017.\n\n^ a b Wo\u017aniak, Micha\u0142; Gra\u00f1a, Manuel; Corchado, Emilio (March 2014). \"A survey of multiple classifier systems as hybrid systems\". Information Fusion. 16: 3\u201317. doi:10.1016/j.inffus.2013.04.006. hdl:10366/134320. S2CID\u00a011632848.\n\n^ a b Rodriguez-Galiano, V.F.; Ghimire, B.; Rogan, J.; Chica-Olmo, M.; Rigol-Sanchez, J.P. (January 2012). \"An assessment of the effectiveness of a random forest classifier for land-cover classification\". ISPRS Journal of Photogrammetry and Remote Sensing. 67: 93\u2013104. Bibcode:2012JPRS...67...93R. doi:10.1016/j.isprsjprs.2011.11.002.\n\n^ Giacinto, Giorgio; Roli, Fabio (August 2001). \"Design of effective neural network ensembles for image classification purposes\". Image and Vision Computing. 19 (9\u201310): 699\u2013707. CiteSeerX\u00a010.1.1.11.5820. doi:10.1016/S0262-8856(01)00045-2.\n\n^ Xia, Junshi; Yokoya, Naoto; Iwasaki, Yakira (March 2017). \"A novel ensemble classifier of hyperspectral and LiDAR data using morphological features\". 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). pp.\u00a06185\u20136189. doi:10.1109/ICASSP.2017.7953345. ISBN\u00a0978-1-5090-4117-6. S2CID\u00a040210273.\n\n^ Mochizuki, S.; Murakami, T. (November 2012). \"Accuracy comparison of land cover mapping using the object-oriented image classification with machine learning algorithms\". 33rd Asian Conference on Remote Sensing 2012, ACRS 2012. 1: 126\u2013133.\n\n^ Liu, Dan; Toman, Elizabeth; Fuller, Zane; Chen, Gang; Londo, Alexis; Xuesong, Zhang; Kaiguang, Zhao (2018). \"Integration of historical map and aerial imagery to characterize long-term land-use change and landscape dynamics: An object-based analysis via Random Forests\" (PDF). Ecological Indicators. 95 (1): 595\u2013605. Bibcode:2018EcInd..95..595L. doi:10.1016/j.ecolind.2018.08.004. S2CID\u00a092025959.\n\n^ Giacinto, G.; Roli, F.; Fumera, G. (September 2000). \"Design of effective multiple classifier systems by clustering of classifiers\". Proceedings 15th International Conference on Pattern Recognition. ICPR-2000. Vol.\u00a02. pp.\u00a0160\u2013163. CiteSeerX\u00a010.1.1.11.5328. doi:10.1109/ICPR.2000.906039. ISBN\u00a0978-0-7695-0750-7. S2CID\u00a02625643.\n\n^ Du, Peijun; Liu, Sicong; Xia, Junshi; Zhao, Yindi (January 2013). \"Information fusion techniques for change detection from multi-temporal remote sensing images\". Information Fusion. 14 (1): 19\u201327. doi:10.1016/j.inffus.2012.05.003.\n\n^ Defined by Bruzzone et al. (2002) as \"The data class that receives the largest number of votes is taken as the class of the input pattern\", this is simple majority, more accurately described as plurality voting.\n\n^ Zhao, Kaiguang; Wulder, Michael A; Hu, Tongx; Bright, Ryan; Wu, Qiusheng; Qin, Haiming; Li, Yang (2019). \"Detecting change-point, trend, and seasonality in satellite time series data to track abrupt changes and nonlinear dynamics: A Bayesian ensemble algorithm\". Remote Sensing of Environment. 232: 111181. Bibcode:2019RSEnv.23211181Z. doi:10.1016/j.rse.2019.04.034. hdl:11250/2651134. S2CID\u00a0201310998.\n\n^ Bruzzone, Lorenzo; Cossu, Roberto; Vernazza, Gianni (December 2002). \"Combining parametric and non-parametric algorithms for a partially unsupervised classification of multitemporal remote-sensing images\" (PDF). Information Fusion. 3 (4): 289\u2013297. doi:10.1016/S1566-2535(02)00091-X.\n\n^ Theodomir, Mugiraneza; Nascetti, Andrea; Ban., Yifang (2020). \"Continuous monitoring of urban land cover change trajectories with landsat time series and landtrendr-google earth engine cloud computing\". Remote Sensing. 12 (18): 2883. Bibcode:2020RemS...12.2883M. doi:10.3390/rs12182883.\n\n^ Li, Yang; Zhao, Kaiguang; Hu, Tongxi; Zhang, Xuesong. \"BEAST: A Bayesian Ensemble Algorithm for Change-Point Detection and Time Series Decomposition\". GitHub.\n\n^ Raj Kumar, P. Arun; Selvakumar, S. (July 2011). \"Distributed denial of service attack detection using an ensemble of neural classifier\". Computer Communications. 34 (11): 1328\u20131341. doi:10.1016/j.comcom.2011.01.012.\n\n^ Shabtai, Asaf; Moskovitch, Robert; Elovici, Yuval; Glezer, Chanan (February 2009). \"Detection of malicious code by applying machine learning classifiers on static features: A state-of-the-art survey\". Information Security Technical Report. 14 (1): 16\u201329. doi:10.1016/j.istr.2009.03.003.\n\n^ Zhang, Boyun; Yin, Jianping; Hao, Jingbo; Zhang, Dingxing; Wang, Shulin (2007). \"Malicious Codes Detection Based on Ensemble Learning\". Autonomic and Trusted Computing. Lecture Notes in Computer Science. Vol.\u00a04610. pp.\u00a0468\u2013477. doi:10.1007/978-3-540-73547-2_48. ISBN\u00a0978-3-540-73546-5.\n\n^ Menahem, Eitan; Shabtai, Asaf; Rokach, Lior; Elovici, Yuval (February 2009). \"Improving malware detection by applying multi-inducer ensemble\". Computational Statistics & Data Analysis. 53 (4): 1483\u20131494. CiteSeerX\u00a010.1.1.150.2722. doi:10.1016/j.csda.2008.10.015.\n\n^ Locasto, Michael E.; Wang, Ke; Keromytis, Angeles D.; Salvatore, J. Stolfo (2005). \"FLIPS: Hybrid Adaptive Intrusion Prevention\". Recent Advances in Intrusion Detection. Lecture Notes in Computer Science. Vol.\u00a03858. pp.\u00a082\u2013101. CiteSeerX\u00a010.1.1.60.3798. doi:10.1007/11663812_5. ISBN\u00a0978-3-540-31778-4.\n\n^ Giacinto, Giorgio; Perdisci, Roberto; Del Rio, Mauro; Roli, Fabio (January 2008). \"Intrusion detection in computer networks by a modular ensemble of one-class classifiers\". Information Fusion. 9 (1): 69\u201382. CiteSeerX\u00a010.1.1.69.9132. doi:10.1016/j.inffus.2006.10.002.\n\n^ Mu, Xiaoyan; Lu, Jiangfeng; Watta, Paul; Hassoun, Mohamad H. (July 2009). \"Weighted voting-based ensemble classifiers with application to human face recognition and voice recognition\". 2009 International Joint Conference on Neural Networks. pp.\u00a02168\u20132171. doi:10.1109/IJCNN.2009.5178708. ISBN\u00a0978-1-4244-3548-7. S2CID\u00a018850747.\n\n^ Yu, Su; Shan, Shiguang; Chen, Xilin; Gao, Wen (April 2006). \"Hierarchical ensemble of Gabor Fisher classifier for face recognition\". 7th International Conference on Automatic Face and Gesture Recognition (FGR06). pp.\u00a091\u201396. doi:10.1109/FGR.2006.64. ISBN\u00a0978-0-7695-2503-7. S2CID\u00a01513315.\n\n^ Su, Y.; Shan, S.; Chen, X.; Gao, W. (September 2006). \"Patch-Based Gabor Fisher Classifier for Face Recognition\". 18th International Conference on Pattern Recognition (ICPR'06). Vol.\u00a02. pp.\u00a0528\u2013531. doi:10.1109/ICPR.2006.917. ISBN\u00a0978-0-7695-2521-1. S2CID\u00a05381806.\n\n^ Liu, Yang; Lin, Yongzheng; Chen, Yuehui (July 2008). \"Ensemble Classification Based on ICA for Face Recognition\". 2008 Congress on Image and Signal Processing. pp.\u00a0144\u2013148. doi:10.1109/CISP.2008.581. ISBN\u00a0978-0-7695-3119-9. S2CID\u00a016248842.\n\n^ Rieger, Steven A.; Muraleedharan, Rajani; Ramachandran, Ravi P. (2014). \"Speech based emotion recognition using spectral feature extraction and an ensemble of KNN classifiers\". The 9th International Symposium on Chinese Spoken Language Processing. pp.\u00a0589\u2013593. doi:10.1109/ISCSLP.2014.6936711. ISBN\u00a0978-1-4799-4219-0. S2CID\u00a031370450.\n\n^ Krajewski, Jarek; Batliner, Anton; Kessel, Silke (October 2010). \"Comparing Multiple Classifiers for Speech-Based Detection of Self-Confidence - A Pilot Study\". 2010 20th International Conference on Pattern Recognition (PDF). pp.\u00a03716\u20133719. doi:10.1109/ICPR.2010.905. ISBN\u00a0978-1-4244-7542-1. S2CID\u00a015431610.\n\n^ Rani, P. Ithaya; Muneeswaran, K. (25 May 2016). \"Recognize the facial emotion in video sequences using eye and mouth temporal Gabor features\". Multimedia Tools and Applications. 76 (7): 10017\u201310040. doi:10.1007/s11042-016-3592-y. S2CID\u00a020143585.\n\n^ Rani, P. Ithaya; Muneeswaran, K. (August 2016). \"Facial Emotion Recognition Based on Eye and Mouth Regions\". International Journal of Pattern Recognition and Artificial Intelligence. 30 (7): 1655020. doi:10.1142/S021800141655020X.\n\n^ Rani, P. Ithaya; Muneeswaran, K (28 March 2018). \"Emotion recognition based on facial components\". S\u0101dhan\u0101. 43 (3). doi:10.1007/s12046-018-0801-6.\n\n^ Louzada, Francisco; Ara, Anderson (October 2012). \"Bagging k-dependence probabilistic networks: An alternative powerful fraud detection tool\". Expert Systems with Applications. 39 (14): 11583\u201311592. doi:10.1016/j.eswa.2012.04.024.\n\n^ Sundarkumar, G. Ganesh; Ravi, Vadlamani (January 2015). \"A novel hybrid undersampling method for mining unbalanced datasets in banking and insurance\". Engineering Applications of Artificial Intelligence. 37: 368\u2013377. doi:10.1016/j.engappai.2014.09.019.\n\n^ a b Kim, Yoonseong; Sohn, So Young (August 2012). \"Stock fraud detection using peer group analysis\". Expert Systems with Applications. 39 (10): 8986\u20138992. doi:10.1016/j.eswa.2012.02.025.\n\n^ Savio, A.; Garc\u00eda-Sebasti\u00e1n, M.T.; Chyzyk, D.; Hernandez, C.; Gra\u00f1a, M.; Sistiaga, A.; L\u00f3pez de Munain, A.; Villan\u00faa, J. (August 2011). \"Neurocognitive disorder detection based on feature vectors extracted from VBM analysis of structural MRI\". Computers in Biology and Medicine. 41 (8): 600\u2013610. doi:10.1016/j.compbiomed.2011.05.010. PMID\u00a021621760.\n\n^ Ayerdi, B.; Savio, A.; Gra\u00f1a, M. (June 2013). \"Meta-ensembles of Classifiers for Alzheimer's Disease Detection Using Independent ROI Features\". Natural and Artificial Computation in Engineering and Medical Applications. Lecture Notes in Computer Science. Vol.\u00a07931. pp.\u00a0122\u2013130. doi:10.1007/978-3-642-38622-0_13. ISBN\u00a0978-3-642-38621-3.\n\n^ Gu, Quan; Ding, Yong-Sheng; Zhang, Tong-Liang (April 2015). \"An ensemble classifier based prediction of G-protein-coupled receptor classes in low homology\". Neurocomputing. 154: 110\u2013118. doi:10.1016/j.neucom.2014.12.013.\n\n^ Xue, Dan; Zhou, Xiaomin; Li, Chen; Yao, Yudong; Rahaman, Md Mamunur; Zhang, Jinghua; Chen, Hao; Zhang, Jinpeng; Qi, Shouliang; Sun, Hongzan (2020). \"An Application of Transfer Learning and Ensemble Learning Techniques for Cervical Histopathology Image Classification\". IEEE Access. 8: 104603\u2013104618. Bibcode:2020IEEEA...8j4603X. doi:10.1109/ACCESS.2020.2999816. ISSN\u00a02169-3536. S2CID\u00a0219689893.\n\n^ Manna, Ankur; Kundu, Rohit; Kaplun, Dmitrii; Sinitca, Aleksandr; Sarkar, Ram (December 2021). \"A fuzzy rank-based ensemble of CNN models for classification of cervical cytology\". Scientific Reports. 11 (1): 14538. Bibcode:2021NatSR..1114538M. doi:10.1038/s41598-021-93783-8. ISSN\u00a02045-2322. PMC\u00a08282795. PMID\u00a034267261.\n\n\nFurther reading[edit]\nZhou Zhihua (2012). Ensemble Methods: Foundations and Algorithms. Chapman and Hall/CRC. ISBN\u00a0978-1-439-83003-1.\nRobert Schapire; Yoav Freund (2012). Boosting: Foundations and Algorithms. MIT. ISBN\u00a0978-0-262-01718-3.\nExternal links[edit]\nRobi Polikar (ed.). \"Ensemble learning\". Scholarpedia.\nThe Waffles (machine learning) toolkit contains implementations of Bagging, Boosting, Bayesian Model Averaging, Bayesian Model Combination, Bucket-of-models, and other ensemble techniques\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Ensemble_learning&oldid=1254901523\""}, {"url": "https://en.wikipedia.org/wiki/Neural_architecture_search", "content": "Machine learning-powered structure design\n\nPart of a series onMachine learningand data mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\n\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\n\nSupervised learning(classification\u00a0\u2022 regression) \nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\n\nClustering\nBIRCH\nCURE\nHierarchical\nk-means\nFuzzy\nExpectation\u2013maximization (EM)\nDBSCAN\nOPTICS\nMean shift\n\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\n\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\n\nAnomaly detection\nRANSAC\nk-NN\nLocal outlier factor\nIsolation forest\n\nArtificial neural network\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural radiance field\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM (ECRAM)\n\nReinforcement learning\nQ-learning\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\n\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nRLHF\n\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\n\nMathematical foundations\nKernel machines\nBias\u2013variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\n\nJournals and conferences\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\n\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nvte\nNeural architecture search (NAS)[1][2] is a technique for automating the design of artificial neural networks (ANN), a widely used model in the field of machine learning. NAS has been used to design networks that are on par with or outperform hand-designed architectures.[3][4] Methods for NAS can be categorized according to the search space, search strategy and performance estimation strategy used:[1]\n\nThe search space defines the type(s) of ANN that can be designed and optimized.\nThe search strategy defines the approach used to explore the search space.\nThe performance estimation strategy evaluates the performance of a possible ANN from its design (without constructing and training it).\nNAS is closely related to hyperparameter optimization[5] and meta-learning[6] and is a subfield of automated machine learning (AutoML).[7]\n\n\nReinforcement learning[edit]\nReinforcement learning (RL) can underpin a NAS search strategy. Barret Zoph and Quoc Viet Le[3] applied NAS with RL targeting the CIFAR-10 dataset and achieved a network architecture that rivals the best manually-designed architecture for accuracy, with an error rate of 3.65, 0.09 percent better and 1.05x faster than a related hand-designed model. On the Penn Treebank dataset, that model composed a recurrent cell that outperforms LSTM, reaching a test set perplexity of 62.4, or 3.6 perplexity better than the prior leading system. On the PTB character language modeling task it achieved bits per character of 1.214.[3]\nLearning a model architecture directly on a large dataset can be a lengthy process. NASNet[4][8] addressed this issue by transferring a building block designed for a small dataset to a larger dataset. The design was constrained to use two types of convolutional cells to return feature maps that serve two main functions when convoluting an input feature map: normal cells that return maps of the same extent (height and width) and reduction cells in which the returned feature map height and width is reduced by a factor of two. For the reduction cell, the initial operation applied to the cell's inputs uses a stride of two (to reduce the height and width).[4] The learned aspect of the design included elements such as which lower layer(s) each higher layer took as input, the transformations applied at that layer and to merge multiple outputs at each layer. In the studied example, the best convolutional layer (or \"cell\") was designed for the CIFAR-10 dataset and then applied to the ImageNet dataset by stacking copies of this cell, each with its own parameters. The approach yielded accuracy of 82.7% top-1 and 96.2% top-5. This exceeded the best human-invented architectures at a cost of 9 billion fewer FLOPS\u2014a reduction of 28%. The system continued to exceed the manually-designed alternative at varying computation levels. The image features learned from image classification can be transferred to other computer vision problems. E.g., for object detection, the learned cells integrated with the Faster-RCNN framework improved performance by 4.0% on the COCO dataset.[4]\nIn the so-called Efficient Neural Architecture Search (ENAS), a controller discovers architectures by learning to search for an optimal subgraph within a large graph. The controller is trained with policy gradient to select a subgraph that maximizes the validation set's expected reward. The model corresponding to the subgraph is trained to minimize a canonical cross entropy loss. Multiple child models share parameters, ENAS requires fewer GPU-hours than other approaches and 1000-fold less than \"standard\" NAS. On CIFAR-10, the ENAS design achieved a test error of 2.89%, comparable to NASNet. On Penn Treebank, the ENAS design reached test perplexity of 55.8.[9]\n\nEvolution[edit]\nAn alternative approach to NAS is based on evolutionary algorithms, which has been employed by several groups.[10][11][12][13][14][15][16] An Evolutionary Algorithm for Neural Architecture Search generally performs the following procedure.[17] First a pool consisting of different candidate architectures along with their validation scores (fitness) is initialised. At each step the architectures in the candidate pool are mutated (e.g.: 3x3 convolution instead of a 5x5 convolution). Next the new architectures are trained from scratch for a few epochs and their validation scores are obtained. This is followed by replacing the lowest scoring architectures in the candidate pool with the better, newer architectures. This procedure is repeated multiple times and thus the candidate pool is refined over time. Mutations in the context of evolving ANNs are operations such as adding or removing a layer, which include changing the type of a layer (e.g., from convolution to pooling), changing the hyperparameters of a layer, or changing the training hyperparameters. On CIFAR-10 and ImageNet, evolution and RL performed comparably, while both slightly outperformed random search.[13][12]\n\nBayesian optimization[edit]\nBayesian Optimization (BO), which has proven to be an efficient method for hyperparameter optimization, can also be applied to NAS. In this context, the objective function maps an architecture to its validation error after being trained for a number of epochs. At each iteration, BO uses a surrogate to model this objective function based on previously obtained architectures and their validation errors. One then chooses the next architecture to evaluate by maximizing an acquisition function, such as expected improvement, which provides a balance between exploration and exploitation. Acquisition function maximization and objective function evaluation are often computationally expensive for NAS, and make the application of BO challenging in this context. Recently, BANANAS[18] has achieved promising results in this direction by introducing a high-performing instantiation of BO coupled to a neural predictor.\n\nHill-climbing[edit]\nAnother group used a hill climbing procedure that applies network morphisms, followed by short cosine-annealing optimization runs. The approach yielded competitive results, requiring resources on the same order of magnitude as training a single network. E.g., on CIFAR-10, the method designed and trained a network with an error rate below 5% in 12 hours on a single GPU.[19]\n\nMulti-objective search[edit]\nWhile most approaches solely focus on finding architecture with maximal predictive performance, for most practical applications other objectives are relevant, such as memory consumption, model size or inference time (i.e., the time required to obtain a prediction). Because of that, researchers created a multi-objective search.[16][20]\nLEMONADE[16] is an evolutionary algorithm that adopted Lamarckism to efficiently optimize multiple objectives. In every generation, child networks are generated to improve the Pareto frontier with respect to the current population of ANNs.\nNeural Architect[20] is claimed to be a resource-aware multi-objective RL-based NAS with network embedding and performance prediction. Network embedding encodes an existing network to a trainable embedding vector. Based on the embedding, a controller network generates transformations of the target network. A multi-objective reward function considers network accuracy, computational resource and training time. The reward is predicted by multiple performance simulation networks that are pre-trained or co-trained with the controller network. The controller network is trained via policy gradient. Following a modification, the resulting candidate network is evaluated by both an accuracy network and a training time network. The results are combined by a reward engine that passes its output back to the controller network.\n\nOne-shot models[edit]\nRL or evolution-based NAS require thousands of GPU-days of searching/training to achieve state-of-the-art computer vision results as described in the NASNet, mNASNet and MobileNetV3 papers.[4][21][22]\nTo reduce computational cost, many recent NAS methods rely on the weight-sharing idea.[23][24] In this approach, a single overparameterized supernetwork (also known as the one-shot model) is defined. A supernetwork is a very large Directed Acyclic Graph (DAG) whose subgraphs are different candidate neural networks. Thus, in a supernetwork, the weights are shared among a large number of different sub-architectures that have edges in common, each of which is considered as a path within the supernet. The essential idea is to train one supernetwork that spans many options for the final design rather than generating and training thousands of networks independently. In addition to the learned parameters, a set of architecture parameters are learnt to depict preference for one module over another. Such methods reduce the required computational resources to only a few GPU days.\nMore recent works further combine this weight-sharing paradigm, with a continuous relaxation of the search space,[25][26][27][28] which enables the use of gradient-based optimization methods. These approaches are generally referred to as differentiable NAS and have proven very efficient in exploring the search space of neural architectures. One of the most popular algorithms amongst the gradient-based methods for NAS is DARTS.[27] However, DARTS faces problems such as performance collapse due to an inevitable aggregation of skip connections and poor generalization which were tackled by many future algorithms.[29][30][31][32] Methods like [30][31] aim at robustifying DARTS and making the validation accuracy landscape smoother by introducing a Hessian norm based regularisation and random smoothing/adversarial attack respectively. The cause of performance degradation is later analyzed from the architecture selection aspect.[33]\nDifferentiable NAS has shown to produce competitive results using a fraction of the search-time required by RL-based search methods. For example, FBNet (which is short for Facebook Berkeley Network) demonstrated that supernetwork-based search produces networks that outperform the speed-accuracy tradeoff curve of mNASNet and MobileNetV2 on the ImageNet image-classification dataset. FBNet accomplishes this using over 400x less search time than was used for mNASNet.[34][35][36] Further, SqueezeNAS demonstrated that supernetwork-based NAS produces neural networks that outperform the speed-accuracy tradeoff curve of MobileNetV3 on the Cityscapes semantic segmentation dataset, and SqueezeNAS uses over 100x less search time than was used in the MobileNetV3 authors' RL-based search.[37][38]\n\nNeural architecture search benchmarks[edit]\nNeural architecture search often requires large computational resources, due to its expensive training and evaluation phases. This further leads to a large carbon footprint required for the evaluation of these methods.  To overcome this limitation, NAS benchmarks[39][40][41][42] have been introduced, from which one can either query or predict the final performance of neural architectures in seconds. A NAS benchmark is defined as a dataset with a fixed train-test split, a search space, and a fixed training pipeline (hyperparameters). There are primarily two types of NAS benchmarks: a surrogate NAS benchmark and a tabular NAS benchmark. A surrogate benchmark uses a  surrogate model (e.g.: a neural network) to predict the performance of an architecture from the search space. On the other hand, a tabular benchmark queries the actual performance of an architecture trained up to convergence. Both of these benchmarks are queryable and can be used to efficiently simulate many NAS algorithms using only a CPU to query the benchmark instead of training an architecture from scratch.\n\nSee also[edit]\nNeural Network Intelligence\nAutomated Machine Learning\nHyperparameter Optimization\nFurther reading[edit]\nSurvey articles.\n\nWistuba, Martin; Rawat, Ambrish; Pedapati, Tejaswini (2019-05-04). \"A Survey on Neural Architecture Search\". arXiv:1905.01392 [cs.LG].\nElsken, Thomas; Metzen, Jan Hendrik; Hutter, Frank (August 8, 2019). \"Neural Architecture Search: A Survey\". Journal of Machine Learning Research. 20 (55): 1\u201321. arXiv:1808.05377.\nLiu, Yuqiao; Sun, Yanan; Xue, Bing; Zhang, Mengjie; Yen, Gary G; Tan, Kay Chen (2021). \"A Survey on Evolutionary Neural Architecture Search\". IEEE Transactions on Neural Networks and Learning Systems. 34 (2): 1\u201321. arXiv:2008.10937. doi:10.1109/TNNLS.2021.3100554. PMID\u00a034357870. S2CID\u00a0221293236.\nWhite, Colin; Safari, Mahmoud; Sukthanker, Rhea; Ru, Binxin; Elsken, Thomas; Zela, Arber; Dey, Debadeepta; Hutter, Frank (2023-01-25). \"Neural Architecture Search: Insights from 1000 Papers\". arXiv:2301.08727 [cs.LG].\nReferences[edit]\n\n\n^ a b Elsken, Thomas; Metzen, Jan Hendrik; Hutter, Frank (August 8, 2019). \"Neural Architecture Search: A Survey\". Journal of Machine Learning Research. 20 (55): 1\u201321. arXiv:1808.05377.\n\n^ Wistuba, Martin; Rawat, Ambrish; Pedapati, Tejaswini (2019-05-04). \"A Survey on Neural Architecture Search\". arXiv:1905.01392 [cs.LG].\n\n^ a b c Zoph, Barret; Le, Quoc V. (2016-11-04). \"Neural Architecture Search with Reinforcement Learning\". arXiv:1611.01578 [cs.LG].\n\n^ a b c d e Zoph, Barret; Vasudevan, Vijay; Shlens, Jonathon; Le, Quoc V. (2017-07-21). \"Learning Transferable Architectures for Scalable Image Recognition\". arXiv:1707.07012 [cs.CV].\n\n^ Matthias Feurer and Frank Hutter. Hyperparameter optimization. In: AutoML: Methods, Systems, Challenges, pages 3\u201338.\n\n^ Vanschoren, Joaquin (2019). \"Meta-Learning\". Automated Machine Learning. The Springer Series on Challenges in Machine Learning. pp.\u00a035\u201361. doi:10.1007/978-3-030-05318-5_2. ISBN\u00a0978-3-030-05317-8. S2CID\u00a0239362577.\n\n^ Salehin, Imrus; Islam, Md. Shamiul; Saha, Pritom; Noman, S. M.; Tuni, Azra; Hasan, Md. Mehedi; Baten, Md. Abu (2024-01-01). \"AutoML: A systematic review on automated machine learning with neural architecture search\". Journal of Information and Intelligence. 2 (1): 52\u201381. doi:10.1016/j.jiixd.2023.10.002. ISSN\u00a02949-7159.\n\n^ Zoph, Barret; Vasudevan, Vijay; Shlens, Jonathon; Le, Quoc V. (November 2, 2017). \"AutoML for large scale image classification and object detection\". Research Blog. Retrieved 2018-02-20.\n\n^ Pham, Hieu; Guan, Melody Y.; Zoph, Barret; Le, Quoc V.; Dean, Jeff (2018-02-09). \"Efficient Neural Architecture Search via Parameter Sharing\". arXiv:1802.03268 [cs.LG].\n\n^ Real, Esteban; Moore, Sherry; Selle, Andrew; Saxena, Saurabh; Suematsu, Yutaka Leon; Tan, Jie; Le, Quoc; Kurakin, Alex (2017-03-03). \"Large-Scale Evolution of Image Classifiers\". arXiv:1703.01041 [cs.NE].\n\n^ Suganuma, Masanori; Shirakawa, Shinichi; Nagao, Tomoharu (2017-04-03). \"A Genetic Programming Approach to Designing Convolutional Neural Network Architectures\". arXiv:1704.00764v2 [cs.NE].\n\n^ a b Liu, Hanxiao; Simonyan, Karen; Vinyals, Oriol; Fernando, Chrisantha; Kavukcuoglu, Koray (2017-11-01). \"Hierarchical Representations for Efficient Architecture Search\". arXiv:1711.00436v2 [cs.LG].\n\n^ a b Real, Esteban; Aggarwal, Alok; Huang, Yanping; Le, Quoc V. (2018-02-05). \"Regularized Evolution for Image Classifier Architecture Search\". arXiv:1802.01548 [cs.NE].\n\n^ Miikkulainen, Risto; Liang, Jason; Meyerson, Elliot; Rawal, Aditya; Fink, Dan; Francon, Olivier; Raju, Bala; Shahrzad, Hormoz; Navruzyan, Arshak; Duffy, Nigel; Hodjat, Babak (2017-03-04). \"Evolving Deep Neural Networks\". arXiv:1703.00548 [cs.NE].\n\n^ Xie, Lingxi; Yuille, Alan (2017). \"Genetic CNN\". 2017 IEEE International Conference on Computer Vision (ICCV). pp.\u00a01388\u20131397. arXiv:1703.01513. doi:10.1109/ICCV.2017.154. ISBN\u00a0978-1-5386-1032-9. S2CID\u00a0206770867.\n\n^ a b c Elsken, Thomas; Metzen, Jan Hendrik; Hutter, Frank (2018-04-24). \"Efficient Multi-objective Neural Architecture Search via Lamarckian Evolution\". arXiv:1804.09081 [stat.ML].\n\n^ Liu, Yuqiao; Sun, Yanan; Xue, Bing; Zhang, Mengjie; Yen, Gary G; Tan, Kay Chen (2021). \"A Survey on Evolutionary Neural Architecture Search\". IEEE Transactions on Neural Networks and Learning Systems. 34 (2): 1\u201321. arXiv:2008.10937. doi:10.1109/TNNLS.2021.3100554. PMID\u00a034357870. S2CID\u00a0221293236.\n\n^ White, Colin; Neiswanger, Willie; Savani, Yash (2020-11-02). \"BANANAS: Bayesian Optimization with Neural Architectures for Neural Architecture Search\". arXiv:1910.11858 [cs.LG].\n\n^ Thomas, Elsken; Jan Hendrik, Metzen; Frank, Hutter (2017-11-13). \"Simple And Efficient Architecture Search for Convolutional Neural Networks\". arXiv:1711.04528 [stat.ML].\n\n^ a b Zhou, Yanqi; Diamos, Gregory. \"Neural Architect: A Multi-objective Neural Architecture Search with Performance Prediction\" (PDF). Baidu. Archived from the original (PDF) on 2019-09-27. Retrieved 2019-09-27.\n\n^ Tan, Mingxing; Chen, Bo; Pang, Ruoming; Vasudevan, Vijay; Sandler, Mark; Howard, Andrew; Le, Quoc V. (2018). \"MnasNet: Platform-Aware Neural Architecture Search for Mobile\". arXiv:1807.11626 [cs.CV].\n\n^ Howard, Andrew; Sandler, Mark; Chu, Grace; Chen, Liang-Chieh; Chen, Bo; Tan, Mingxing; Wang, Weijun; Zhu, Yukun; Pang, Ruoming; Vasudevan, Vijay; Le, Quoc V.; Adam, Hartwig (2019-05-06). \"Searching for MobileNetV3\". arXiv:1905.02244 [cs.CV].\n\n^ Pham, Hieu; Guan, Melody Y.; Zoph, Barret; Le, Quoc V.; Dean, Jeff (2018). \"Efficient Neural Architecture Search via Parameter Sharing\". arXiv:1802.03268 [cs.LG].\n\n^ Li, Liam; Talwalkar, Ameet (2019). \"Random Search and Reproducibility for Neural Architecture Search\". arXiv:1902.07638 [cs.LG].\n\n^ Cai, Han; Zhu, Ligeng; Han, Song (2018). \"ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware\". arXiv:1812.00332 [cs.LG].\n\n^ Dong, Xuanyi; Yang, Yi (2019). \"Searching for a Robust Neural Architecture in Four GPU Hours\". arXiv:1910.04465 [cs.CV].\n\n^ a b Liu, Hanxiao; Simonyan, Karen; Yang, Yiming (2018). \"DARTS: Differentiable Architecture Search\". arXiv:1806.09055 [cs.LG].\n\n^ Xie, Sirui; Zheng, Hehui; Liu, Chunxiao; Lin, Liang (2018). \"SNAS: Stochastic Neural Architecture Search\". arXiv:1812.09926 [cs.LG].\n\n^ Chu, Xiangxiang; Zhou, Tianbao; Zhang, Bo; Li, Jixiang (2019). \"Fair DARTS: Eliminating Unfair Advantages in Differentiable Architecture Search\". arXiv:1911.12126 [cs.LG].\n\n^ a b Zela, Arber; Elsken, Thomas; Saikia, Tonmoy; Marrakchi, Yassine; Brox, Thomas; Hutter, Frank (2019). \"Understanding and Robustifying Differentiable Architecture Search\". arXiv:1909.09656 [cs.LG].\n\n^ a b Chen, Xiangning; Hsieh, Cho-Jui (2020). \"Stabilizing Differentiable Architecture Search via Perturbation-based Regularization\". arXiv:2002.05283 [cs.LG].\n\n^ Xu, Yuhui; Xie, Lingxi; Zhang, Xiaopeng; Chen, Xin; Qi, Guo-Jun; Tian, Qi; Xiong, Hongkai (2019). \"PC-DARTS: Partial Channel Connections for Memory-Efficient Architecture Search\". arXiv:1907.05737 [cs.CV].\n\n^ Wang, Ruochen; Cheng, Minhao; Chen, Xiangning; Tang, Xiaocheng; Hsieh, Cho-Jui (2021). \"Rethinking Architecture Selection in Differentiable NAS\". arXiv:2108.04392 [cs.LG].\n\n^ Wu, Bichen; Dai, Xiaoliang; Zhang, Peizhao; Wang, Yanghan; Sun, Fei; Wu, Yiming; Tian, Yuandong; Vajda, Peter; Jia, Yangqing; Keutzer, Kurt (24 May 2019). \"FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search\". arXiv:1812.03443 [cs.CV].\n\n^ Sandler, Mark; Howard, Andrew; Zhu, Menglong; Zhmoginov, Andrey; Chen, Liang-Chieh (2018). \"MobileNetV2: Inverted Residuals and Linear Bottlenecks\". arXiv:1801.04381 [cs.CV].\n\n^ Keutzer, Kurt (2019-05-22). \"Co-Design of DNNs and NN Accelerators\" (PDF). IEEE. Retrieved 2019-09-26.\n\n^ Shaw, Albert; Hunter, Daniel; Iandola, Forrest; Sidhu, Sammy (2019). \"SqueezeNAS: Fast neural architecture search for faster semantic segmentation\". arXiv:1908.01748 [cs.CV].\n\n^ Yoshida, Junko (2019-08-25). \"Does Your AI Chip Have Its Own DNN?\". EE Times. Retrieved 2019-09-26.\n\n^ Ying, Chris; Klein, Aaron; Real, Esteban; Christiansen, Eric; Murphy, Kevin; Hutter, Frank (2019). \"NAS-Bench-101: Towards Reproducible Neural Architecture Search\". arXiv:1902.09635 [cs.LG].\n\n^ Zela, Arber; Siems, Julien; Hutter, Frank (2020). \"NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search\". arXiv:2001.10422 [cs.LG].\n\n^ Dong, Xuanyi; Yang, Yi (2020). \"NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search\". arXiv:2001.00326 [cs.CV].\n\n^ Zela, Arber; Siems, Julien; Zimmer, Lucas; Lukasik, Jovita; Keuper, Margret; Hutter, Frank (2020). \"Surrogate NAS Benchmarks: Going Beyond the Limited Search Spaces of Tabular NAS Benchmarks\". arXiv:2008.09777 [cs.LG].\n\n\nvteDifferentiable computingGeneral\nDifferentiable programming\nInformation geometry\nStatistical manifold\nAutomatic differentiation\nNeuromorphic engineering\nPattern recognition\nTensor calculus\nComputational learning theory\nInductive bias\nHardware\nIPU\nTPU\nVPU\nMemristor\nSpiNNaker\nSoftware libraries\nTensorFlow\nPyTorch\nKeras\nscikit-learn\nTheano\nJAX\nFlux.jl\nMindSpore\n\n Portals\nComputer programming\nTechnology\n\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Neural_architecture_search&oldid=1250234727\""}, {"url": "https://en.wikipedia.org/wiki/Leakage_(machine_learning)", "content": "Concept in machine learning\n\nPart of a series onMachine learningand data mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\n\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\n\nSupervised learning(classification\u00a0\u2022 regression) \nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\n\nClustering\nBIRCH\nCURE\nHierarchical\nk-means\nFuzzy\nExpectation\u2013maximization (EM)\nDBSCAN\nOPTICS\nMean shift\n\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\n\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\n\nAnomaly detection\nRANSAC\nk-NN\nLocal outlier factor\nIsolation forest\n\nArtificial neural network\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural radiance field\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM (ECRAM)\n\nReinforcement learning\nQ-learning\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\n\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nRLHF\n\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\n\nMathematical foundations\nKernel machines\nBias\u2013variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\n\nJournals and conferences\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\n\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nvte\n\"Data leakage\" redirects here. For the unauthorized exposure, disclosure, or loss of personal information, see Data breach.\nIn statistics and machine learning, leakage (also known as data leakage or target leakage) is the use of information in the model training process which would not be expected to be available at prediction time, causing the predictive scores (metrics) to overestimate the model's utility when run in a production environment.[1]\nLeakage is often subtle and indirect, making it hard to detect and eliminate. Leakage can cause a statistician or modeler to select a suboptimal model, which could be outperformed by a leakage-free model.[1]\n\n\nLeakage modes[edit]\nLeakage can occur in many steps in the machine learning process. The leakage causes can be sub-classified into two possible sources of leakage for a model: features and training examples.[1]\n\nFeature leakage[edit]\nFeature or column-wise leakage is caused by the inclusion of columns which are one of the following: a duplicate label, a proxy for the label, or the label itself. These features, known as anachronisms, will not be available when the model is used for predictions, and result in leakage if included when the model is trained.[2]\nFor example, including a \"MonthlySalary\" column when predicting \"YearlySalary\"; or \"MinutesLate\" when predicting \"IsLate\".\n\nTraining example leakage[edit]\nRow-wise leakage is caused by improper sharing of information between rows of data. Types of row-wise leakage include:\n\nPremature featurization; leaking from premature featurization before Cross-validation/Train/Test split (must fit MinMax/ngrams/etc on only the train split, then transform the test set)\nDuplicate rows between train/validation/test (e.g. oversampling a dataset to pad its size before splitting; e.g. different rotations/augmentations of a single image; bootstrap sampling before splitting; or duplicating rows to up sample the minority class)\nNon-i.i.d. data\nTime leakage (e.g. splitting a time-series dataset randomly instead of newer data in test set using a TrainTest split or rolling-origin cross validation)\nGroup leakage\u2014not including a grouping split column (e.g. Andrew Ng's group had 100k x-rays of 30k patients, meaning ~3 images per patient. The paper used random splitting instead of ensuring that all images of a patient were in the same split. Hence the model partially memorized the patients instead of learning to recognize pneumonia in chest x-rays.[3][4])\nA 2023 review found data leakage to be \"a widespread failure mode in machine-learning (ML)-based science\", having affected at least 294 academic publications across 17 disciplines, and causing a potential reproducibility crisis.[5]\n\nDetection[edit]\nData leakage in machine learning can be detected through various methods, focusing on performance analysis, feature examination, data auditing, and model behavior analysis. Performance-wise, unusually high accuracy or significant discrepancies between training and test results often indicate leakage.[6] Inconsistent cross-validation outcomes may also signal issues.\nFeature examination involves scrutinizing feature importance rankings and ensuring temporal integrity in time series data. A thorough audit of the data pipeline is crucial, reviewing pre-processing steps, feature engineering, and data splitting processes.[7] Detecting duplicate entries across dataset splits is also important.\nAnalyzing model behavior can reveal leakage. Models relying heavily on counter-intuitive features or showing unexpected prediction patterns warrant investigation. Performance degradation over time when tested on new data may suggest earlier inflated metrics due to leakage.\nAdvanced techniques include backward feature elimination, where suspicious features are temporarily removed to observe performance changes. Using a separate hold-out dataset for final validation before deployment is advisable.[7]\n\nSee also[edit]\nAutoML\nConcept drift (where the structure of the system being studied evolves over time, invalidating the model)\nOverfitting\nResampling (statistics)\nSupervised learning\nTraining, validation, and test sets\nReferences[edit]\n\n\n^ a b c Shachar Kaufman; Saharon Rosset; Claudia Perlich (January 2011). \"Leakage in data mining: Formulation, detection, and avoidance\". Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining. Vol.\u00a06. pp.\u00a0556\u2013563. doi:10.1145/2020408.2020496. ISBN\u00a09781450308137. S2CID\u00a09168804. Retrieved 13 January 2020.\n\n^ Soumen Chakrabarti (2008). \"9\". Data Mining: Know it All. Morgan Kaufmann Publishers. p.\u00a0383. ISBN\u00a0978-0-12-374629-0. Anachronistic variables are a pernicious mining problem. However, they aren't any problem at all at deployment time\u2014unless someone expects the model to work! Anachronistic variables are out of place in time. Specifically, at data modeling time, they carry information back from the future to the past.\n\n^ Guts, Yuriy (30 October 2018). Yuriy Guts. TARGET LEAKAGE IN MACHINE LEARNING (Talk). AI Ukraine Conference. Ukraine \u2013 via YouTube.\nYuriy Guts. \"Target Leakage in ML\" (PDF). AI Ukraine Online Conference.\n\n^ Nick, Roberts (16 November 2017). \"Replying to @AndrewYNg @pranavrajpurkar and 2 others\". Brooklyn, NY, USA: Twitter. Archived from the original on 10 June 2018. Retrieved 13 January 2020. Replying to  @AndrewYNg   @pranavrajpurkar  and 2 others ... Were you concerned that the network could memorize patient anatomy since patients cross train and validation?  \"ChestX-ray14 dataset contains 112,120 frontal-view X-ray images of 30,805 unique patients. We randomly split the entire dataset into 80% training, and 20% validation.\"\n\n^ Kapoor, Sayash; Narayanan, Arvind (August 2023). \"Leakage and the reproducibility crisis in machine-learning-based science\". Patterns. 4 (9): 100804. doi:10.1016/j.patter.2023.100804. ISSN\u00a02666-3899. PMC\u00a010499856. PMID\u00a037720327.\n\n^ Batutin, Andrew (2024-06-20). \"Data Leakage in Machine Learning Models\". Shelf. Retrieved 2024-10-18.\n\n^ a b \"What is Data Leakage in Machine Learning? | IBM\". www.ibm.com. 2024-09-30. Retrieved 2024-10-18.\n\n\n\n\nThis artificial intelligence-related article is a stub. You can help Wikipedia by expanding it.vte\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Leakage_(machine_learning)&oldid=1251897015\""}, {"url": "https://en.wikipedia.org/wiki/Systems_design", "content": "This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources:\u00a0\"Systems design\"\u00a0\u2013\u00a0news\u00a0\u00b7 newspapers\u00a0\u00b7 books\u00a0\u00b7 scholar\u00a0\u00b7 JSTOR (April 2013) (Learn how and when to remove this message)Organizing components structures and behaviors for any simple to complex system\nThe basic study of system design is the understanding of component parts and their subsequent interaction with one another.[1]\nSystems design has appeared in a variety of fields, including sustainability,[2] computer/software architecture,[3] and sociology.[4]\n\n\nProduct Development[edit]\nIf the broader topic of product development \"blends the perspective of marketing, design, and manufacturing into a single approach to product development,\"[5] then design is the act of taking the marketing information and creating the design of the product to be manufactured. \nThus in product development, systems design involves the process of defining and developing systems, such as interfaces and data, for an electronic control system to satisfy specified requirements. Systems design could be seen as the application of systems theory to product development. There is some overlap with the disciplines of systems analysis, systems architecture and systems engineering.[6][7]\n\nPhysical design[edit]\nThe physical design relates to the actual input and output processes of the system. This is explained in terms of how data is input into a system, how it is verified/authenticated, how it is processed, and how it is displayed.\nIn physical design, the following requirements about the system are decided.\n\nInput requirement,\nOutput requirements,\nStorage requirements,\nProcessing requirements,\nSystem control and backup or recovery.[8]\nPut another way, the physical portion of system design can generally be broken down into three sub-tasks:\n\nUser Interface Design\nData Design\nProcess Design\nWeb System design[edit]\nOnline websites, such as Google, Twitter, Facebook, Amazon and Netflix are used by millions of users worldwide. A scalable, highly available system must be designed to accommodate an increasing number of users. Here are the things to consider in designing the system:\n\nFunctional and non functional requirements\nCapacity estimation\nDatabase to use, Relational or NoSQL\nVertical scaling, Horizontal scaling, Shard\nLoad Balancing\nPrimary-secondary Replication\nCache and CDN\nStateless and Stateful servers\nDatacenter georouting\nMessage Queue, Publish-Subscribe Architecture\nPerformance Metrics Monitoring and Logging\nBuild, test, configure deploy automation\nFinding single point of failure\nAPI Rate Limiting\nService Level Agreement\nSee also[edit]\n\nArcadia (engineering)\nArchitectural pattern (computer science)\nConfiguration design\nElectronic design automation (EDA)\nElectronic system-level (ESL)\nEmbedded system\nGraphical system design\nHypersystems\nModular design\nMorphological analysis (problem-solving)\nSystems analysis and design\nSCSD (School Construction Systems Development) project\nSystem information modelling\nSystem development life cycle (SDLC)\nSystem engineering\nSystem thinking\nTRIZ\n\nReferences[edit]\n\n\n^ Papanek, Victor J. (1984) [1972]. Design for the Real World: Human Ecology and Social Change (2nd\u00a0ed.). Chicago: Academy Chicago. p.\u00a0276. ISBN\u00a00897331532. OCLC\u00a012343986.\n\n^ Blizzard, Jacqualyn; Klotz, Leidy (2012). \"A framework for sustainable whole systems design\". R Design Studies. 33 (5): 456\u2013479. doi:10.1016/j.destud.2012.03.001.\n\n^ Lukosh, Heidi; Bekebrede, Geertje; Kurapati, Shalini; Lukosch, Stephan (2018). \"A Scientific Foundation of Simulation Games for the Analysis and Design of Complex Systems\". Simulation & Gaming. 49 (3): 279\u2013314. doi:10.1177/1046878118768858. PMC\u00a06187265. PMID\u00a030369775.\n\n^ Werner, Ulrich (September 1987). \"Critical heuristics of social systems design\". European Journal of Operational Research. 31 (3): 276-283. doi:10.1016/0377-2217(87)90036-1.\n\n^ Ulrich, Karl T.; Eppinger, Steven D. (2000). Product Design and Development (Second\u00a0ed.). Boston: Irwin McGraw-Hill.\n\n^ \u00a0This article incorporates public domain material from Federal Standard 1037C. General Services Administration. Archived from the original on 2022-01-22.\n\n^ \u00a0This article incorporates public domain material from Dictionary of Military and Associated Terms. United States Department of Defense.\n\n^ Arden, Trevor (1991). Information technology applications. London: Pitman. ISBN\u00a0978-0-273-03470-4.\n\n\nFurther reading[edit]\nBentley, Lonnie D.; Dittman, Kevin C.; Whitten, Jeffrey L. (2004) [1986]. System analysis and design methods.\nChurchman, C. West (1971). The Design of Inquiring Systems: Basic Concepts of Systems and Organization. New York: Basic Books. ISBN\u00a00-465-01608-1.\nGosling, William (1962). The design of engineering systems. New York: Wiley.\nHawryszkiewycz, Igor T. (1994). Introduction to system analysis and design. Prentice Hall PTR.\nLevin, Mark S. (2015). Modular system design and evaluation. Springer.\nMaier, Mark W.; Rechtin, Eberhardt (2000). The Art of System Architecting (Second\u00a0ed.). Boca Raton: CRC Press.\nJ. H. Saltzer; D. P. Reed; D. D. Clark (1 November 1984). \"End-to-end arguments in system design\" (PDF). ACM Transactions on Computer Systems. 2 (4): 277\u2013288. doi:10.1145/357401.357402. ISSN\u00a00734-2071. S2CID\u00a0215746877. Wikidata\u00a0Q56503280.\nWhitten, Jeffrey L.; Bentley, Lonnie D.; Dittman, Kevin C. (2004). Fundamentals of system analysis and design methods.\nExternal links[edit]\n\n\n\nLook up systems design in Wiktionary, the free dictionary.\n\nInteractive System Design. Course by Chris Johnson, 1993\n[1] Course by Prof. Birgit Weller, 2020\nvteDesign\nOutline\nDesigner\nDisciplinesCommunicationdesign\nAdvertising\nBook design\nBrand design\nExhibit design\nFilm title design\nGraphic design\nMotion\nPostage stamp design\nPrint design\nIllustration\nInformation design\nInstructional design\nNews design\nPhotography\nRetail design\nSignage\u00a0/ Traffic sign design\nTypography\u00a0/ Type design\nVideo design\nVisual merchandising\nEnvironmentaldesign\nArchitecture\nArchitectural lighting design\nBuilding design\nPassive solar\nEcological design\nEnvironmental impact design\nGarden design\nComputer-aided\nHealthy community design\nHotel design\nInterior architecture\nInterior design\nEID\nKeyline design\nLandscape architecture\nSustainable\nLandscape design\nSpatial design\nUrban design\nIndustrialdesign\nAutomotive design\nAutomotive suspension design\nCMF design\nCorrugated box design\nElectric guitar design\nFurniture design\nSustainable\nHardware interface design\nMotorcycle design\nPackaging and labeling\nPhotographic lens design\nProduct design\nProduction design\nSensory design\nService design\nInteractiondesign\nExperience design\nEED\nGame design\nLevel design\nVideo game design\nHardware interface design\nIcon design\nImmersive design\nInformation design\nSonic interaction design\nUser experience design\nUser interface design\nWeb design\nOtherapplied arts\nPublic art design\nCeramic\u00a0/ glass design\nFashion design\nCostume design\nJewellery design\nFloral design\nGame art design\nProperty design\nScenic design\nSound design\nStage/set lighting design\nTextile design\nOtherdesign& engineering\nAlgorithm design\nBehavioural design\nBoiler design\nDatabase design\nDrug design\nElectrical system design\nExperimental design\nFilter design\nGeometric design\nWork design\nIntegrated circuit design\nCircuit design\nPhysical design\nPower network design\nMechanism design\nNuclear weapon design\nNucleic acid design\nOrganization design\nProcess design\nProcessor design\nProtein design\nResearch design\nSocial design\nSoftware design\nSpacecraft design\nStrategic design\nSystems design\nApproaches\nActivity-centered\nAdaptive web\nAffective\nBrainstorming\nBy committee\nBy contract\nC-K theory\nClosure\nCo-design\nConcept-oriented\nConfiguration\nContextual\nContinuous\nCradle-to-cradle\nCreative problem-solving\nCreativity techniques\nCritical\nDesign fiction\nDefensive\nDesign\u2013bid\u2013build\nDesign\u2013build\narchitect-led\nDiffuse\nDomain-driven\nEcological design\nEnergy neutral\nEngineering design process\nProbabilistic design\nError-tolerant\nFault-tolerant\nFramework-oriented\nFor assembly\nFor behaviour change\nFor manufacturability\nFor Six Sigma\nFor testing\nFor X\nFunctional\nGenerative\nGeodesign\nHCD\nHigh-level\nInclusive\nIntegrated\nIntegrated topside\nIntelligence-based\nIterative\nKISS principle\nLow-level\nMetadesign\nMind mapping\nModular\nNew Wave\nObject-oriented\nOpen\nParametric\nParticipatory\nPlatform-based\nPolicy-based\nProcess-centered\nPublic interest\nRational\nRegenerative\nReliability engineering\nResearch-based\nResponsibility-driven\nRWD\nSafe-life\nSustainable\nSystemic\nSOD\nTableless web\nTheory of constraints\nTop-down and bottom-up\nTransformation\nTransgenerational\nTRIZ\nUniversal\nDesign for All\nUsage-centered\nUse-centered\nUser-centered\nEmpathic\nUser innovation\nValue-driven\nValue sensitive\nPrivacy by\nDesign choice\ncomputing\ncontrols\nculture\nflow\nleadership\nmanagement\nmarker\nmethods\npattern\nresearch\nscience\nsprint\nstrategy\ntheory\nthinking\nToolsIntellectual propertyOrganizationsAwardsTools\nAAD\nArchitectural model\nBlueprint\nComprehensive layout\nCAD\nCAID\nVirtual home design software\nCAutoD\nDesign quality indicator\nElectronic design automation\nFlowchart\nMockup\nDesign specification\nPrototype\nSketch\nStoryboard\nTechnical drawing\nHTML editor\nWebsite wireframe\nIntellectualproperty\nCommunity design\nDesign around\nDesign infringement\nDesign patent\nFashion design copyright\nGeschmacksmuster\nIndustrial design rights\nEuropean Union\nOrganizations\nAmerican Institute of Graphic Arts\nChartered Society of Designers\nDesign and Industries Association\nDesign Council\nInternational Forum Design\nDesign Research Society\nAwards\nEuropean Design Award\nGerman Design Award\nGood Design Award (Museum of Modern Art)\nGood Design Award (Chicago Athenaeum)\nGraphex\nIF Product Design Award\nJames Dyson Award\nPrince Philip Designers Prize\nRelated topics\nAgile\nConcept art\nConceptual design\nCreative industries\nCultural icon\n.design\nEnterprise architecture\nForm factor\nFutures studies\nIndie design\nInnovation management\nIntelligent design\nLean startup\nNew product development\nOODA loop\nPhilosophy of design\nProcess simulation\nSlow design\nSTEAM fields\nUnintelligent design\nVisualization\nWicked problem\nDesign brief\nchange\nclassic\ncompetition\narchitectural\nstudent\ndirector\neducation\nelements\nengineer\nfirm\nhistory\nknowledge\nlanguage\nlife\nload\nmuseum\nparadigm\nprinciples\nrationale\nreview\nspecification\nstudies\nstudio\ntechnology\n\n Commons \n Wikibooks \n Wikinews \n Wikiquote \n Wikisource \n Wiktionary \n\nvteSystems engineeringSubfields\nAerospace engineering\nBiological systems engineering\nCognitive systems engineering\nConfiguration management\nEarth systems engineering and management\nElectrical engineering\nEnterprise systems engineering\nHealth systems engineering\nPerformance engineering\nReliability engineering\nSafety engineering\nSociocultural Systems Engineering\nProcesses\nRequirements engineering\nFunctional specification\nSystem integration\nVerification and validation\nDesign review\nSystem of systems engineering\nConcepts\nBusiness process\nFault tolerance\nSystem\nSystem lifecycle\nV-Model\nSystems development life cycle\nTools\nDecision-making\nFunction modelling\nIDEF\nOptimization\nQuality function deployment\nSystem dynamics\nSystems Modeling Language\nSystems analysis\nSystems modeling\nWork breakdown structure\nPeople\nJames S. Albus\nRuzena Bajcsy\nBenjamin S. Blanchard\nWernher von Braun\nKathleen Carley\nHarold Chestnut\nWolt Fabrycky\nBarbara Grosz\nArthur David Hall III\nDerek Hitchins\nRobert E. Machol\nRadhika Nagpal\nSimon Ramo\nJoseph Francis Shea\nKatia Sycara\nManuela M. Veloso\nJohn N. Warfield\nRelated fields\nControl engineering\nComputer engineering\nIndustrial engineering\nOperations research\nProject management\nQuality management\nRisk management\nSoftware engineering\n\nCategory\n\nAuthority control databases: National United StatesIsrael\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Systems_design&oldid=1236957349\""}, {"url": "https://en.wikipedia.org/wiki/Neural_architecture_search", "content": "Machine learning-powered structure design\n\nPart of a series onMachine learningand data mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\n\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\n\nSupervised learning(classification\u00a0\u2022 regression) \nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\n\nClustering\nBIRCH\nCURE\nHierarchical\nk-means\nFuzzy\nExpectation\u2013maximization (EM)\nDBSCAN\nOPTICS\nMean shift\n\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\n\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\n\nAnomaly detection\nRANSAC\nk-NN\nLocal outlier factor\nIsolation forest\n\nArtificial neural network\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural radiance field\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM (ECRAM)\n\nReinforcement learning\nQ-learning\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\n\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nRLHF\n\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\n\nMathematical foundations\nKernel machines\nBias\u2013variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\n\nJournals and conferences\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\n\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nvte\nNeural architecture search (NAS)[1][2] is a technique for automating the design of artificial neural networks (ANN), a widely used model in the field of machine learning. NAS has been used to design networks that are on par with or outperform hand-designed architectures.[3][4] Methods for NAS can be categorized according to the search space, search strategy and performance estimation strategy used:[1]\n\nThe search space defines the type(s) of ANN that can be designed and optimized.\nThe search strategy defines the approach used to explore the search space.\nThe performance estimation strategy evaluates the performance of a possible ANN from its design (without constructing and training it).\nNAS is closely related to hyperparameter optimization[5] and meta-learning[6] and is a subfield of automated machine learning (AutoML).[7]\n\n\nReinforcement learning[edit]\nReinforcement learning (RL) can underpin a NAS search strategy. Barret Zoph and Quoc Viet Le[3] applied NAS with RL targeting the CIFAR-10 dataset and achieved a network architecture that rivals the best manually-designed architecture for accuracy, with an error rate of 3.65, 0.09 percent better and 1.05x faster than a related hand-designed model. On the Penn Treebank dataset, that model composed a recurrent cell that outperforms LSTM, reaching a test set perplexity of 62.4, or 3.6 perplexity better than the prior leading system. On the PTB character language modeling task it achieved bits per character of 1.214.[3]\nLearning a model architecture directly on a large dataset can be a lengthy process. NASNet[4][8] addressed this issue by transferring a building block designed for a small dataset to a larger dataset. The design was constrained to use two types of convolutional cells to return feature maps that serve two main functions when convoluting an input feature map: normal cells that return maps of the same extent (height and width) and reduction cells in which the returned feature map height and width is reduced by a factor of two. For the reduction cell, the initial operation applied to the cell's inputs uses a stride of two (to reduce the height and width).[4] The learned aspect of the design included elements such as which lower layer(s) each higher layer took as input, the transformations applied at that layer and to merge multiple outputs at each layer. In the studied example, the best convolutional layer (or \"cell\") was designed for the CIFAR-10 dataset and then applied to the ImageNet dataset by stacking copies of this cell, each with its own parameters. The approach yielded accuracy of 82.7% top-1 and 96.2% top-5. This exceeded the best human-invented architectures at a cost of 9 billion fewer FLOPS\u2014a reduction of 28%. The system continued to exceed the manually-designed alternative at varying computation levels. The image features learned from image classification can be transferred to other computer vision problems. E.g., for object detection, the learned cells integrated with the Faster-RCNN framework improved performance by 4.0% on the COCO dataset.[4]\nIn the so-called Efficient Neural Architecture Search (ENAS), a controller discovers architectures by learning to search for an optimal subgraph within a large graph. The controller is trained with policy gradient to select a subgraph that maximizes the validation set's expected reward. The model corresponding to the subgraph is trained to minimize a canonical cross entropy loss. Multiple child models share parameters, ENAS requires fewer GPU-hours than other approaches and 1000-fold less than \"standard\" NAS. On CIFAR-10, the ENAS design achieved a test error of 2.89%, comparable to NASNet. On Penn Treebank, the ENAS design reached test perplexity of 55.8.[9]\n\nEvolution[edit]\nAn alternative approach to NAS is based on evolutionary algorithms, which has been employed by several groups.[10][11][12][13][14][15][16] An Evolutionary Algorithm for Neural Architecture Search generally performs the following procedure.[17] First a pool consisting of different candidate architectures along with their validation scores (fitness) is initialised. At each step the architectures in the candidate pool are mutated (e.g.: 3x3 convolution instead of a 5x5 convolution). Next the new architectures are trained from scratch for a few epochs and their validation scores are obtained. This is followed by replacing the lowest scoring architectures in the candidate pool with the better, newer architectures. This procedure is repeated multiple times and thus the candidate pool is refined over time. Mutations in the context of evolving ANNs are operations such as adding or removing a layer, which include changing the type of a layer (e.g., from convolution to pooling), changing the hyperparameters of a layer, or changing the training hyperparameters. On CIFAR-10 and ImageNet, evolution and RL performed comparably, while both slightly outperformed random search.[13][12]\n\nBayesian optimization[edit]\nBayesian Optimization (BO), which has proven to be an efficient method for hyperparameter optimization, can also be applied to NAS. In this context, the objective function maps an architecture to its validation error after being trained for a number of epochs. At each iteration, BO uses a surrogate to model this objective function based on previously obtained architectures and their validation errors. One then chooses the next architecture to evaluate by maximizing an acquisition function, such as expected improvement, which provides a balance between exploration and exploitation. Acquisition function maximization and objective function evaluation are often computationally expensive for NAS, and make the application of BO challenging in this context. Recently, BANANAS[18] has achieved promising results in this direction by introducing a high-performing instantiation of BO coupled to a neural predictor.\n\nHill-climbing[edit]\nAnother group used a hill climbing procedure that applies network morphisms, followed by short cosine-annealing optimization runs. The approach yielded competitive results, requiring resources on the same order of magnitude as training a single network. E.g., on CIFAR-10, the method designed and trained a network with an error rate below 5% in 12 hours on a single GPU.[19]\n\nMulti-objective search[edit]\nWhile most approaches solely focus on finding architecture with maximal predictive performance, for most practical applications other objectives are relevant, such as memory consumption, model size or inference time (i.e., the time required to obtain a prediction). Because of that, researchers created a multi-objective search.[16][20]\nLEMONADE[16] is an evolutionary algorithm that adopted Lamarckism to efficiently optimize multiple objectives. In every generation, child networks are generated to improve the Pareto frontier with respect to the current population of ANNs.\nNeural Architect[20] is claimed to be a resource-aware multi-objective RL-based NAS with network embedding and performance prediction. Network embedding encodes an existing network to a trainable embedding vector. Based on the embedding, a controller network generates transformations of the target network. A multi-objective reward function considers network accuracy, computational resource and training time. The reward is predicted by multiple performance simulation networks that are pre-trained or co-trained with the controller network. The controller network is trained via policy gradient. Following a modification, the resulting candidate network is evaluated by both an accuracy network and a training time network. The results are combined by a reward engine that passes its output back to the controller network.\n\nOne-shot models[edit]\nRL or evolution-based NAS require thousands of GPU-days of searching/training to achieve state-of-the-art computer vision results as described in the NASNet, mNASNet and MobileNetV3 papers.[4][21][22]\nTo reduce computational cost, many recent NAS methods rely on the weight-sharing idea.[23][24] In this approach, a single overparameterized supernetwork (also known as the one-shot model) is defined. A supernetwork is a very large Directed Acyclic Graph (DAG) whose subgraphs are different candidate neural networks. Thus, in a supernetwork, the weights are shared among a large number of different sub-architectures that have edges in common, each of which is considered as a path within the supernet. The essential idea is to train one supernetwork that spans many options for the final design rather than generating and training thousands of networks independently. In addition to the learned parameters, a set of architecture parameters are learnt to depict preference for one module over another. Such methods reduce the required computational resources to only a few GPU days.\nMore recent works further combine this weight-sharing paradigm, with a continuous relaxation of the search space,[25][26][27][28] which enables the use of gradient-based optimization methods. These approaches are generally referred to as differentiable NAS and have proven very efficient in exploring the search space of neural architectures. One of the most popular algorithms amongst the gradient-based methods for NAS is DARTS.[27] However, DARTS faces problems such as performance collapse due to an inevitable aggregation of skip connections and poor generalization which were tackled by many future algorithms.[29][30][31][32] Methods like [30][31] aim at robustifying DARTS and making the validation accuracy landscape smoother by introducing a Hessian norm based regularisation and random smoothing/adversarial attack respectively. The cause of performance degradation is later analyzed from the architecture selection aspect.[33]\nDifferentiable NAS has shown to produce competitive results using a fraction of the search-time required by RL-based search methods. For example, FBNet (which is short for Facebook Berkeley Network) demonstrated that supernetwork-based search produces networks that outperform the speed-accuracy tradeoff curve of mNASNet and MobileNetV2 on the ImageNet image-classification dataset. FBNet accomplishes this using over 400x less search time than was used for mNASNet.[34][35][36] Further, SqueezeNAS demonstrated that supernetwork-based NAS produces neural networks that outperform the speed-accuracy tradeoff curve of MobileNetV3 on the Cityscapes semantic segmentation dataset, and SqueezeNAS uses over 100x less search time than was used in the MobileNetV3 authors' RL-based search.[37][38]\n\nNeural architecture search benchmarks[edit]\nNeural architecture search often requires large computational resources, due to its expensive training and evaluation phases. This further leads to a large carbon footprint required for the evaluation of these methods.  To overcome this limitation, NAS benchmarks[39][40][41][42] have been introduced, from which one can either query or predict the final performance of neural architectures in seconds. A NAS benchmark is defined as a dataset with a fixed train-test split, a search space, and a fixed training pipeline (hyperparameters). There are primarily two types of NAS benchmarks: a surrogate NAS benchmark and a tabular NAS benchmark. A surrogate benchmark uses a  surrogate model (e.g.: a neural network) to predict the performance of an architecture from the search space. On the other hand, a tabular benchmark queries the actual performance of an architecture trained up to convergence. Both of these benchmarks are queryable and can be used to efficiently simulate many NAS algorithms using only a CPU to query the benchmark instead of training an architecture from scratch.\n\nSee also[edit]\nNeural Network Intelligence\nAutomated Machine Learning\nHyperparameter Optimization\nFurther reading[edit]\nSurvey articles.\n\nWistuba, Martin; Rawat, Ambrish; Pedapati, Tejaswini (2019-05-04). \"A Survey on Neural Architecture Search\". arXiv:1905.01392 [cs.LG].\nElsken, Thomas; Metzen, Jan Hendrik; Hutter, Frank (August 8, 2019). \"Neural Architecture Search: A Survey\". Journal of Machine Learning Research. 20 (55): 1\u201321. arXiv:1808.05377.\nLiu, Yuqiao; Sun, Yanan; Xue, Bing; Zhang, Mengjie; Yen, Gary G; Tan, Kay Chen (2021). \"A Survey on Evolutionary Neural Architecture Search\". IEEE Transactions on Neural Networks and Learning Systems. 34 (2): 1\u201321. arXiv:2008.10937. doi:10.1109/TNNLS.2021.3100554. PMID\u00a034357870. S2CID\u00a0221293236.\nWhite, Colin; Safari, Mahmoud; Sukthanker, Rhea; Ru, Binxin; Elsken, Thomas; Zela, Arber; Dey, Debadeepta; Hutter, Frank (2023-01-25). \"Neural Architecture Search: Insights from 1000 Papers\". arXiv:2301.08727 [cs.LG].\nReferences[edit]\n\n\n^ a b Elsken, Thomas; Metzen, Jan Hendrik; Hutter, Frank (August 8, 2019). \"Neural Architecture Search: A Survey\". Journal of Machine Learning Research. 20 (55): 1\u201321. arXiv:1808.05377.\n\n^ Wistuba, Martin; Rawat, Ambrish; Pedapati, Tejaswini (2019-05-04). \"A Survey on Neural Architecture Search\". arXiv:1905.01392 [cs.LG].\n\n^ a b c Zoph, Barret; Le, Quoc V. (2016-11-04). \"Neural Architecture Search with Reinforcement Learning\". arXiv:1611.01578 [cs.LG].\n\n^ a b c d e Zoph, Barret; Vasudevan, Vijay; Shlens, Jonathon; Le, Quoc V. (2017-07-21). \"Learning Transferable Architectures for Scalable Image Recognition\". arXiv:1707.07012 [cs.CV].\n\n^ Matthias Feurer and Frank Hutter. Hyperparameter optimization. In: AutoML: Methods, Systems, Challenges, pages 3\u201338.\n\n^ Vanschoren, Joaquin (2019). \"Meta-Learning\". Automated Machine Learning. The Springer Series on Challenges in Machine Learning. pp.\u00a035\u201361. doi:10.1007/978-3-030-05318-5_2. ISBN\u00a0978-3-030-05317-8. S2CID\u00a0239362577.\n\n^ Salehin, Imrus; Islam, Md. Shamiul; Saha, Pritom; Noman, S. M.; Tuni, Azra; Hasan, Md. Mehedi; Baten, Md. Abu (2024-01-01). \"AutoML: A systematic review on automated machine learning with neural architecture search\". Journal of Information and Intelligence. 2 (1): 52\u201381. doi:10.1016/j.jiixd.2023.10.002. ISSN\u00a02949-7159.\n\n^ Zoph, Barret; Vasudevan, Vijay; Shlens, Jonathon; Le, Quoc V. (November 2, 2017). \"AutoML for large scale image classification and object detection\". Research Blog. Retrieved 2018-02-20.\n\n^ Pham, Hieu; Guan, Melody Y.; Zoph, Barret; Le, Quoc V.; Dean, Jeff (2018-02-09). \"Efficient Neural Architecture Search via Parameter Sharing\". arXiv:1802.03268 [cs.LG].\n\n^ Real, Esteban; Moore, Sherry; Selle, Andrew; Saxena, Saurabh; Suematsu, Yutaka Leon; Tan, Jie; Le, Quoc; Kurakin, Alex (2017-03-03). \"Large-Scale Evolution of Image Classifiers\". arXiv:1703.01041 [cs.NE].\n\n^ Suganuma, Masanori; Shirakawa, Shinichi; Nagao, Tomoharu (2017-04-03). \"A Genetic Programming Approach to Designing Convolutional Neural Network Architectures\". arXiv:1704.00764v2 [cs.NE].\n\n^ a b Liu, Hanxiao; Simonyan, Karen; Vinyals, Oriol; Fernando, Chrisantha; Kavukcuoglu, Koray (2017-11-01). \"Hierarchical Representations for Efficient Architecture Search\". arXiv:1711.00436v2 [cs.LG].\n\n^ a b Real, Esteban; Aggarwal, Alok; Huang, Yanping; Le, Quoc V. (2018-02-05). \"Regularized Evolution for Image Classifier Architecture Search\". arXiv:1802.01548 [cs.NE].\n\n^ Miikkulainen, Risto; Liang, Jason; Meyerson, Elliot; Rawal, Aditya; Fink, Dan; Francon, Olivier; Raju, Bala; Shahrzad, Hormoz; Navruzyan, Arshak; Duffy, Nigel; Hodjat, Babak (2017-03-04). \"Evolving Deep Neural Networks\". arXiv:1703.00548 [cs.NE].\n\n^ Xie, Lingxi; Yuille, Alan (2017). \"Genetic CNN\". 2017 IEEE International Conference on Computer Vision (ICCV). pp.\u00a01388\u20131397. arXiv:1703.01513. doi:10.1109/ICCV.2017.154. ISBN\u00a0978-1-5386-1032-9. S2CID\u00a0206770867.\n\n^ a b c Elsken, Thomas; Metzen, Jan Hendrik; Hutter, Frank (2018-04-24). \"Efficient Multi-objective Neural Architecture Search via Lamarckian Evolution\". arXiv:1804.09081 [stat.ML].\n\n^ Liu, Yuqiao; Sun, Yanan; Xue, Bing; Zhang, Mengjie; Yen, Gary G; Tan, Kay Chen (2021). \"A Survey on Evolutionary Neural Architecture Search\". IEEE Transactions on Neural Networks and Learning Systems. 34 (2): 1\u201321. arXiv:2008.10937. doi:10.1109/TNNLS.2021.3100554. PMID\u00a034357870. S2CID\u00a0221293236.\n\n^ White, Colin; Neiswanger, Willie; Savani, Yash (2020-11-02). \"BANANAS: Bayesian Optimization with Neural Architectures for Neural Architecture Search\". arXiv:1910.11858 [cs.LG].\n\n^ Thomas, Elsken; Jan Hendrik, Metzen; Frank, Hutter (2017-11-13). \"Simple And Efficient Architecture Search for Convolutional Neural Networks\". arXiv:1711.04528 [stat.ML].\n\n^ a b Zhou, Yanqi; Diamos, Gregory. \"Neural Architect: A Multi-objective Neural Architecture Search with Performance Prediction\" (PDF). Baidu. Archived from the original (PDF) on 2019-09-27. Retrieved 2019-09-27.\n\n^ Tan, Mingxing; Chen, Bo; Pang, Ruoming; Vasudevan, Vijay; Sandler, Mark; Howard, Andrew; Le, Quoc V. (2018). \"MnasNet: Platform-Aware Neural Architecture Search for Mobile\". arXiv:1807.11626 [cs.CV].\n\n^ Howard, Andrew; Sandler, Mark; Chu, Grace; Chen, Liang-Chieh; Chen, Bo; Tan, Mingxing; Wang, Weijun; Zhu, Yukun; Pang, Ruoming; Vasudevan, Vijay; Le, Quoc V.; Adam, Hartwig (2019-05-06). \"Searching for MobileNetV3\". arXiv:1905.02244 [cs.CV].\n\n^ Pham, Hieu; Guan, Melody Y.; Zoph, Barret; Le, Quoc V.; Dean, Jeff (2018). \"Efficient Neural Architecture Search via Parameter Sharing\". arXiv:1802.03268 [cs.LG].\n\n^ Li, Liam; Talwalkar, Ameet (2019). \"Random Search and Reproducibility for Neural Architecture Search\". arXiv:1902.07638 [cs.LG].\n\n^ Cai, Han; Zhu, Ligeng; Han, Song (2018). \"ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware\". arXiv:1812.00332 [cs.LG].\n\n^ Dong, Xuanyi; Yang, Yi (2019). \"Searching for a Robust Neural Architecture in Four GPU Hours\". arXiv:1910.04465 [cs.CV].\n\n^ a b Liu, Hanxiao; Simonyan, Karen; Yang, Yiming (2018). \"DARTS: Differentiable Architecture Search\". arXiv:1806.09055 [cs.LG].\n\n^ Xie, Sirui; Zheng, Hehui; Liu, Chunxiao; Lin, Liang (2018). \"SNAS: Stochastic Neural Architecture Search\". arXiv:1812.09926 [cs.LG].\n\n^ Chu, Xiangxiang; Zhou, Tianbao; Zhang, Bo; Li, Jixiang (2019). \"Fair DARTS: Eliminating Unfair Advantages in Differentiable Architecture Search\". arXiv:1911.12126 [cs.LG].\n\n^ a b Zela, Arber; Elsken, Thomas; Saikia, Tonmoy; Marrakchi, Yassine; Brox, Thomas; Hutter, Frank (2019). \"Understanding and Robustifying Differentiable Architecture Search\". arXiv:1909.09656 [cs.LG].\n\n^ a b Chen, Xiangning; Hsieh, Cho-Jui (2020). \"Stabilizing Differentiable Architecture Search via Perturbation-based Regularization\". arXiv:2002.05283 [cs.LG].\n\n^ Xu, Yuhui; Xie, Lingxi; Zhang, Xiaopeng; Chen, Xin; Qi, Guo-Jun; Tian, Qi; Xiong, Hongkai (2019). \"PC-DARTS: Partial Channel Connections for Memory-Efficient Architecture Search\". arXiv:1907.05737 [cs.CV].\n\n^ Wang, Ruochen; Cheng, Minhao; Chen, Xiangning; Tang, Xiaocheng; Hsieh, Cho-Jui (2021). \"Rethinking Architecture Selection in Differentiable NAS\". arXiv:2108.04392 [cs.LG].\n\n^ Wu, Bichen; Dai, Xiaoliang; Zhang, Peizhao; Wang, Yanghan; Sun, Fei; Wu, Yiming; Tian, Yuandong; Vajda, Peter; Jia, Yangqing; Keutzer, Kurt (24 May 2019). \"FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search\". arXiv:1812.03443 [cs.CV].\n\n^ Sandler, Mark; Howard, Andrew; Zhu, Menglong; Zhmoginov, Andrey; Chen, Liang-Chieh (2018). \"MobileNetV2: Inverted Residuals and Linear Bottlenecks\". arXiv:1801.04381 [cs.CV].\n\n^ Keutzer, Kurt (2019-05-22). \"Co-Design of DNNs and NN Accelerators\" (PDF). IEEE. Retrieved 2019-09-26.\n\n^ Shaw, Albert; Hunter, Daniel; Iandola, Forrest; Sidhu, Sammy (2019). \"SqueezeNAS: Fast neural architecture search for faster semantic segmentation\". arXiv:1908.01748 [cs.CV].\n\n^ Yoshida, Junko (2019-08-25). \"Does Your AI Chip Have Its Own DNN?\". EE Times. Retrieved 2019-09-26.\n\n^ Ying, Chris; Klein, Aaron; Real, Esteban; Christiansen, Eric; Murphy, Kevin; Hutter, Frank (2019). \"NAS-Bench-101: Towards Reproducible Neural Architecture Search\". arXiv:1902.09635 [cs.LG].\n\n^ Zela, Arber; Siems, Julien; Hutter, Frank (2020). \"NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search\". arXiv:2001.10422 [cs.LG].\n\n^ Dong, Xuanyi; Yang, Yi (2020). \"NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search\". arXiv:2001.00326 [cs.CV].\n\n^ Zela, Arber; Siems, Julien; Zimmer, Lucas; Lukasik, Jovita; Keuper, Margret; Hutter, Frank (2020). \"Surrogate NAS Benchmarks: Going Beyond the Limited Search Spaces of Tabular NAS Benchmarks\". arXiv:2008.09777 [cs.LG].\n\n\nvteDifferentiable computingGeneral\nDifferentiable programming\nInformation geometry\nStatistical manifold\nAutomatic differentiation\nNeuromorphic engineering\nPattern recognition\nTensor calculus\nComputational learning theory\nInductive bias\nHardware\nIPU\nTPU\nVPU\nMemristor\nSpiNNaker\nSoftware libraries\nTensorFlow\nPyTorch\nKeras\nscikit-learn\nTheano\nJAX\nFlux.jl\nMindSpore\n\n Portals\nComputer programming\nTechnology\n\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Neural_architecture_search&oldid=1250234727\""}, {"url": "https://en.wikipedia.org/wiki/Neuroevolution", "content": "Form of artificial intelligence\nNot to be confused with Evolution of nervous systems, Neural development, or Neural Darwinism.\nNeuroevolution, or neuro-evolution, is a form of  artificial intelligence that uses evolutionary algorithms to generate artificial neural networks (ANN), parameters, and rules.[1] It is most commonly applied in artificial life, general game playing[2] and evolutionary robotics. The main benefit is that neuroevolution can be applied more widely than supervised learning algorithms, which require a syllabus of correct input-output pairs. In contrast, neuroevolution requires only a measure of a network's performance at a task. For example, the outcome of a game (i.e., whether one player won or lost) can be easily measured without providing labeled examples of desired strategies. Neuroevolution is commonly used as part of the reinforcement learning paradigm, and it can be contrasted with conventional deep learning techniques that use backpropagation (gradient descent on a neural network) with a fixed topology.\n\n\nFeatures[edit]\nMany neuroevolution algorithms have been defined. One common distinction is between algorithms that evolve only the strength of the connection weights for a fixed network topology (sometimes called conventional neuroevolution), and algorithms that evolve both the topology of the network and its weights (called TWEANNs, for Topology and Weight Evolving Artificial Neural Network algorithms).\nA separate distinction can be made between methods that evolve the structure of ANNs in parallel to its parameters (those applying standard evolutionary algorithms) and those that develop them separately (through memetic algorithms).[3]\n\nComparison with gradient descent[edit]\nFurther information: Gradient descent\nMost neural networks use gradient descent rather than neuroevolution. However, around 2017 researchers at Uber stated they had found that simple structural neuroevolution algorithms were competitive with sophisticated modern industry-standard gradient-descent deep learning algorithms, in part because neuroevolution was found to be less likely to get stuck in local minima. In Science,\njournalist Matthew Hutson speculated that part of the reason neuroevolution is succeeding where it had failed before is due to the increased computational power available in the 2010s.[4]\nIt can be shown that there is a correspondence between neuroevolution and gradient descent.[5]\n\nDirect and indirect encoding[edit]\nEvolutionary algorithms operate on a population of genotypes (also referred to as genomes). In neuroevolution, a genotype is mapped to a neural network phenotype that is evaluated on some task to derive its fitness.\nIn direct encoding schemes the genotype directly maps to the phenotype. That is, every neuron and connection in the neural network is specified directly and explicitly in the genotype. In contrast, in indirect encoding schemes the genotype specifies indirectly how that network should be generated.[6]\nIndirect encodings are often used to achieve several aims:[6][7][8][9][10]\n\nmodularity and other regularities;\ncompression of phenotype to a smaller genotype, providing a smaller search space;\nmapping the search space (genome) to the problem domain.\nTaxonomy of embryogenic systems for indirect encoding[edit]\nTraditionally indirect encodings that employ artificial embryogeny (also known as artificial development) have been categorised along the lines of a grammatical approach versus a cell chemistry approach.[11] The former evolves sets of rules in the form of grammatical rewrite systems. The latter attempts to mimic how physical structures emerge in biology through gene expression. Indirect encoding systems often use aspects of both approaches.\nStanley and Miikkulainen[11] propose a taxonomy for embryogenic systems that is intended to reflect their underlying properties. The taxonomy identifies five continuous dimensions, along which any embryogenic system can be placed:\n\nCell (neuron) fate: the final characteristics and role of the cell in the mature phenotype. This dimension counts the number of methods used for determining the fate of a cell.\nTargeting: the method by which connections are directed from source cells to target cells. This ranges from specific targeting (source and target are explicitly identified) to relative targeting (e.g., based on locations of cells relative to each other).\nHeterochrony: the timing and ordering of events during embryogeny. Counts the number of mechanisms for changing the timing of events.\nCanalization: how tolerant the genome is to mutations (brittleness). Ranges from requiring precise genotypic instructions to a high tolerance of imprecise mutation.\nComplexification: the ability of the system (including evolutionary algorithm and genotype to phenotype mapping) to allow complexification of the genome (and hence phenotype) over time. Ranges from allowing only fixed-size genomes to allowing highly variable length genomes.\nExamples[edit]\nExamples of neuroevolution methods (those with direct encodings are necessarily non-embryogenic):\n\n\n\nMethod\n\nEncoding\n\nEvolutionary algorithm\n\nAspects evolved\n\n\nNeuro-genetic evolution by E. Ronald, 1994[12]\n\nDirect\n\nGenetic algorithm\n\nNetwork Weights\n\n\nCellular Encoding (CE) by F. Gruau, 1994[8]\n\nIndirect, embryogenic (grammar tree using S-expressions)\n\nGenetic programming\n\nStructure and parameters (simultaneous, complexification)\n\n\nGNARL by Angeline et al., 1994[13]\n\nDirect\n\nEvolutionary programming\n\nStructure and parameters (simultaneous, complexification)\n\n\nEPNet by Yao and Liu, 1997[14]\n\nDirect\n\nEvolutionary programming (combined with backpropagation and simulated annealing)\n\nStructure and parameters (mixed, complexification and simplification)\n\n\nNeuroEvolution of Augmenting Topologies (NEAT) by Stanley and Miikkulainen, 2002[15][16]\n\nDirect\n\nGenetic algorithm. Tracks genes with historical markings to allow crossover between different topologies, protects innovation via speciation.\n\nStructure and parameters\n\n\nHypercube-based NeuroEvolution of Augmenting Topologies (HyperNEAT) by Stanley, D'Ambrosio, Gauci, 2008[7]\n\nIndirect, non-embryogenic (spatial patterns generated by a Compositional pattern-producing network (CPPN) within a hypercube are interpreted as connectivity patterns in a lower-dimensional space)\n\nGenetic algorithm. The NEAT algorithm (above) is used to evolve the CPPN.\n\nParameters, structure fixed (functionally fully connected)\n\n\nEvolvable Substrate Hypercube-based NeuroEvolution of Augmenting Topologies (ES-HyperNEAT) by Risi, Stanley 2012[10]\n\nIndirect, non-embryogenic (spatial patterns generated by a Compositional pattern-producing network (CPPN) within a hypercube are interpreted as connectivity patterns in a lower-dimensional space)\n\nGenetic algorithm. The NEAT algorithm (above) is used to evolve the CPPN.\n\nParameters and network structure\n\n\nEvolutionary Acquisition of Neural Topologies (EANT/EANT2) by Kassahun and Sommer, 2005[17] / Siebel and Sommer, 2007[18]\n\nDirect and indirect, potentially embryogenic (Common Genetic Encoding[6])\n\nEvolutionary programming/Evolution strategies\n\nStructure and parameters (separately, complexification)\n\n\nInteractively Constrained Neuro-Evolution (ICONE) by Rempis, 2012[19]\n\nDirect, includes constraint masks to restrict the search to specific topology / parameter manifolds.\n\nEvolutionary algorithm. Uses constraint masks to drastically reduce the search space through exploiting domain knowledge.\n\nStructure and parameters (separately, complexification, interactive)\n\n\nDeus Ex Neural Network (DXNN) by Gene Sher, 2012[20]\n\nDirect/Indirect, includes constraints, local tuning, and allows for evolution to integrate new sensors and actuators.\n\nMemetic algorithm. Evolves network structure and parameters on different time-scales.\n\nStructure and parameters (separately, complexification, interactive)\n\n\nSpectrum-diverse Unified Neuroevolution Architecture (SUNA) by Danilo Vasconcellos Vargas, Junichi Murata[21] (Download code)\n\nDirect, introduces the Unified Neural Representation (representation integrating most of the neural network features from the literature).\n\nGenetic Algorithm with a diversity preserving mechanism called Spectrum-diversity that scales well with chromosome size, is problem independent and focus more on obtaining diversity of high level behaviours/approaches. To achieve this diversity the concept of chromosome Spectrum is introduced and used together with a Novelty Map Population.\n\nStructure and parameters (mixed, complexification and simplification)\n\n\nModular Agent-Based Evolver (MABE) by Clifford Bohm, Arend Hintze, and others.[22] (Download code)\n\nDirect or indirect encoding of Markov networks, Neural Networks, genetic programming, and other arbitrarily customizable controllers.\n\nProvides evolutionary algorithms, genetic programming algorithms, and allows customized algorithms, along with specification of arbitrary constraints.\n\nEvolvable aspects include the neural model and allows for the evolution of morphology and sexual selection among others.\n\n\nCovariance Matrix Adaptation with Hypervolume Sorted Adaptive Grid Algorithm (CMA-HAGA) by Shahin Rostami, and others.[23][24]\n\nDirect, includes an atavism feature which enables traits to disappear and re-appear at different generations.\n\nMulti-Objective Evolution Strategy with Preference Articulation (Computational Steering)\n\nStructure, weights, and biases.\n\n\nGACNN evolutionary pressure-driven by Di Biasi et al,  [25]\n\nDirect\n\nGenetic algorithm, Single-Objective Evolution Strategy, specialized for Convolutional Neural Network\n\nStructure\n\n\nFast-DENSER by Assun\u00e7\u00e3o et al[26] and others[27][28]\n\nIndirect\n\nGrammatical evolution (Dynamic Structured Grammar Evolution)[29]\n\nStructure and optimiser used for training\n\nSee also[edit]\nAutomated machine learning (AutoML)\nEvolutionary computation\nNeuroEvolution of Augmenting Topologies (NEAT)\nHyperNEAT (A Generative version of NEAT)\nEvolutionary Acquisition of Neural Topologies (EANT/EANT2)\nReferences[edit]\n\n\n^ Stanley, Kenneth O. (2017-07-13). \"Neuroevolution: A different kind of deep learning\". O'Reilly Media. Retrieved 2017-09-04.\n\n^ Risi, Sebastian; Togelius, Julian (2017). \"Neuroevolution in Games: State of the Art and Open Challenges\". IEEE Transactions on Computational Intelligence and AI in Games. 9: 25\u201341. arXiv:1410.7326. doi:10.1109/TCIAIG.2015.2494596. S2CID\u00a011245845.\n\n^ Togelius, Julian; Schaul, Tom; Schmidhuber, J\u00fcrgen; Gomez, Faustino (2008). \"Countering Poisonous Inputs with Memetic Neuroevolution\". Parallel Problem Solving from Nature \u2013 PPSN X. Lecture Notes in Computer Science. Vol.\u00a05199. pp.\u00a0610\u2013619. doi:10.1007/978-3-540-87700-4_61. ISBN\u00a0978-3-540-87699-1.\n\n^ Hutson, Matthew (11 January 2018). \"Artificial intelligence can 'evolve' to solve problems\". Science. doi:10.1126/science.aas9715.\n\n^ Whitelam, Stephen; Selin, Viktor; Park, Sang-Won; Tamblyn, Isaac (2 November 2021). \"Correspondence between neuroevolution and gradient descent\". Nature Communications. 12 (1): 6317. arXiv:2008.06643. Bibcode:2021NatCo..12.6317W. doi:10.1038/s41467-021-26568-2. PMC\u00a08563972. PMID\u00a034728632.\n\n^ a b c Kassahun, Yohannes; Sommer, Gerald; Edgington, Mark; Metzen, Jan Hendrik; Kirchner, Frank (2007), \"Common genetic encoding for both direct and indirect encodings of networks\", Genetic and Evolutionary Computation Conference, ACM Press, pp.\u00a01029\u20131036, CiteSeerX\u00a010.1.1.159.705\n\n^ a b Gauci, Stanley (2007), \"Generating Large-Scale Neural Networks Through Discovering Geometric Regularities\" (PDF), Genetic and Evolutionary Computation Conference, New York, NY: ACM\n\n^ a b Gruau, Fr\u00e9d\u00e9ric; I, L'universite Claude Bernard-lyon; Doctorat, Of A. Diplome De; Demongeot, M. Jacques; Cosnard, Examinators M. Michel; Mazoyer, M. Jacques; Peretto, M. Pierre; Whitley, M. Darell (1994). Neural Network Synthesis Using Cellular Encoding And The Genetic Algorithm. CiteSeerX\u00a010.1.1.29.5939.\n\n^ Clune, J.; Stanley, Kenneth O.; Pennock, R. T.; Ofria, C. (June 2011). \"On the Performance of Indirect Encoding Across the Continuum of Regularity\". IEEE Transactions on Evolutionary Computation. 15 (3): 346\u2013367. CiteSeerX\u00a010.1.1.375.6731. doi:10.1109/TEVC.2010.2104157. ISSN\u00a01089-778X. S2CID\u00a03008628.\n\n^ a b Risi, Sebastian; Stanley, Kenneth O. (October 2012). \"An Enhanced Hypercube-Based Encoding for Evolving the Placement, Density, and Connectivity of Neurons\". Artificial Life. 18 (4): 331\u2013363. doi:10.1162/ARTL_a_00071. PMID\u00a022938563. S2CID\u00a03256786.\n\n^ a b Stanley, Kenneth O.; Miikkulainen, Risto (April 2003). \"A Taxonomy for Artificial Embryogeny\". Artificial Life. 9 (2): 93\u2013130. doi:10.1162/106454603322221487. PMID\u00a012906725. S2CID\u00a02124332.\n\n^ Ronald, Edmund; Schoenauer, March (1994), \"Genetic Lander: An experiment in accurate neuro-genetic control\", PPSN III 1994 Parallel Programming Solving from Nature, pp.\u00a0452\u2013461, CiteSeerX\u00a010.1.1.56.3139\n\n^ Angeline, P.J.; Saunders, G.M.; Pollack, J.B. (January 1994). \"An evolutionary algorithm that constructs recurrent neural networks\". IEEE Transactions on Neural Networks. 5 (1): 54\u201365. CiteSeerX\u00a010.1.1.64.1853. doi:10.1109/72.265960. PMID\u00a018267779. S2CID\u00a044767.\n\n^ Yao, X.; Liu, Y. (May 1997). \"A new evolutionary system for evolving artificial neural networks\". IEEE Transactions on Neural Networks. 8 (3): 694\u2013713. doi:10.1109/72.572107. PMID\u00a018255671.\n\n^ Stanley, Kenneth O.; Bryant, Bobby D.; Miikkulainen, Risto (December 2005). \"Real-Time Neuroevolution in the NERO Video Game\" (PDF).\n\n^ Stanley, Kenneth O.; Miikkulainen, Risto (June 2002). \"Evolving Neural Networks through Augmenting Topologies\". Evolutionary Computation. 10 (2): 99\u2013127. CiteSeerX\u00a010.1.1.638.3910. doi:10.1162/106365602320169811. PMID\u00a012180173. S2CID\u00a0498161.\n\n^ Kassahun, Yohannes; Sommer, Gerald (April 2005), \"Efficient reinforcement learning through evolutionary acquisition of neural topologies\" (PDF), 13th European Symposium on Artificial Neural Networks, Bruges, Belgium, pp.\u00a0259\u2013266{{citation}}:  CS1 maint: location missing publisher (link)\n\n^ Siebel, Nils T.; Sommer, Gerald (17 October 2007). \"Evolutionary reinforcement learning of artificial neural networks\". International Journal of Hybrid Intelligent Systems. 4 (3): 171\u2013183. doi:10.3233/his-2007-4304.\n\n^ Rempis, Christian Wilhelm (2012). Evolving Complex Neuro-Controllers with Interactively Constrained Neuro-Evolution (Thesis).\n\n^ Sher, Gene I. (2013). Handbook of Neuroevolution Through Erlang. doi:10.1007/978-1-4614-4463-3. ISBN\u00a0978-1-4614-4462-6. S2CID\u00a021777855.\n\n^ Vargas, Danilo Vasconcellos; Murata, Junichi (2019). \"Spectrum-Diverse Neuroevolution With Unified Neural Models\". IEEE Transactions on Neural Networks and Learning Systems. 28 (8): 1759\u20131773. arXiv:1902.06703. Bibcode:2019arXiv190206703V. doi:10.1109/TNNLS.2016.2551748. PMID\u00a028113564. S2CID\u00a0206757620.\n\n^ Edlund, Jeffrey; Chaumont, Nicolas; Hintze, Arend; Koch, Christof; Tononi, Giulio; Adami, Christoph (2011). \"Integrated Information Increases with Fitness in the Evolution of Animats\". PLOS Computational Biology. 7 (10): e1002236. arXiv:1103.1791. Bibcode:2011PLSCB...7E2236E. doi:10.1371/journal.pcbi.1002236. PMC\u00a03197648. PMID\u00a022028639.\n\n^ Rostami, Shahin; Neri, Ferrante (June 2017). \"A fast hypervolume driven selection mechanism for many-objective optimisation problems\". Swarm and Evolutionary Computation. 34: 50\u201367. doi:10.1016/j.swevo.2016.12.002. hdl:2086/13102.\n\n^ Shenfield, Alex; Rostami, Shahin (2017). \"Multi-objective evolution of artificial neural networks in multi-class medical diagnosis problems with class imbalance\" (PDF). 2017 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB). pp.\u00a01\u20138. doi:10.1109/CIBCB.2017.8058553. ISBN\u00a0978-1-4673-8988-4. S2CID\u00a022674515.\n\n^ Di Biasi, Luigi; De Marco, Fabiola; Auriemma Citarella, Alessia; Barra, Paola; Piotto Piotto, Stefano; Tortora, Genoveffa (2023). \"Hybrid Approach for the Design of CNNS Using Genetic Algorithms for Melanoma Classification\". In Rousseau, Jean-Jacques; Kapralos, Bill (eds.). Pattern Recognition, Computer Vision, and Image Processing. ICPR 2022 International Workshops and Challenges. Lecture Notes in Computer Science. Vol.\u00a013643. Cham: Springer Nature Switzerland. pp.\u00a0514\u2013528. doi:10.1007/978-3-031-37660-3_36. ISBN\u00a0978-3-031-37660-3.\n\n^ Assun\u00e7\u00e3o, Filipe; Louren\u00e7o, Nuno; Ribeiro, Bernardete; Machado, Penousal (June 2021). \"Fast-DENSER: Fast Deep Evolutionary Network Structured Representation\". SoftwareX. 14: 100694. Bibcode:2021SoftX..1400694A. doi:10.1016/j.softx.2021.100694. hdl:10316/100856.\n\n^ Vinhas, Adriano; Correia, Jo\u00e3o; Machado, Penousal (2024-06-20), Towards evolution of Deep Neural Networks through contrastive Self-Supervised learning, arXiv:2406.14525, retrieved 2024-06-21\n\n^ Cort\u00eas, Gabriel; Louren\u00e7o, Nuno; Machado, Penousal (2024), Smith, Stephen; Correia, Jo\u00e3o; Cintrano, Christian (eds.), \"Towards Physical Plausibility in Neuroevolution Systems\", Applications of Evolutionary Computation, vol.\u00a014635, Cham: Springer Nature Switzerland, pp.\u00a076\u201390, doi:10.1007/978-3-031-56855-8_5, ISBN\u00a0978-3-031-56854-1, retrieved 2024-06-21\n\n^ Louren\u00e7o, Nuno; Assun\u00e7\u00e3o, Filipe; Pereira, Francisco B.; Costa, Ernesto; Machado, Penousal (2018), Ryan, Conor; O'Neill, Michael; Collins, JJ (eds.), \"Structured Grammatical Evolution: A Dynamic Approach\", Handbook of Grammatical Evolution, Cham: Springer International Publishing, pp.\u00a0137\u2013161, doi:10.1007/978-3-319-78717-6_6, ISBN\u00a0978-3-319-78717-6, retrieved 2024-06-21\n\n\nExternal links[edit]\n\"Evolution 101: Neuroevolution | BEACON\". beacon-center.org. Retrieved 2018-01-14.\n\"NNRG Areas - Neuroevolution\". nn.cs.utexas.edu. University of Texas. Retrieved 2018-01-14. (has downloadable papers on NEAT and applications)\n\"SharpNEAT Neuroevolution Framework\". sharpneat.sourceforge.net. Retrieved 2018-01-14. mature open source neuroevolution project implemented in C#/.Net.\nANNEvolve is an Open Source AI Research Project (Downloadable source code in C and Python with a tutorial & miscellaneous writings and illustrations\n\"Nils T Siebel \u2013 EANT2 \u2013 Evolutionary Reinforcement Learning of Neural Networks\". siebel-research.de. Retrieved 2018-01-14. Web page on evolutionary learning with EANT/EANT2] (information and articles on EANT/EANT2 with applications to robot learning)\nNERD Toolkit. The Neurodynamics and Evolutionary Robotics Development Toolkit. A free, open source software collection for various experiments on neurocontrol and neuroevolution. Includes a scriptable simulator, several neuro-evolution algorithms (e.g. ICONE), cluster support, visual network design and analysis tools.\n\"CorticalComputer (Gene)\". GitHub. Retrieved 2018-01-14. Source code for the DXNN Neuroevolutionary system.\n\"ES-HyperNEAT Users Page\". eplex.cs.ucf.edu. Retrieved 2018-01-14.\nvteEvolutionary computationMain Topics\nEvolutionary algorithm\nEvolutionary data mining\nEvolutionary multimodal optimization\nHuman-based evolutionary computation\nInteractive evolutionary computation\nAlgorithms\nCellular evolutionary algorithm\nCovariance Matrix Adaptation Evolution Strategy (CMA-ES)\nCultural algorithm\nDifferential evolution\nEvolutionary programming\nGenetic algorithm\nGenetic programming\nGene expression programming\nEvolution strategy\nNatural evolution strategy\nNeuroevolution\nLearning classifier system\nRelated techniques\nSwarm intelligence\nAnt colony optimization\nBees algorithm\nCuckoo search\nParticle swarm optimization\nBacterial Colony Optimization\nMetaheuristic methods\nFirefly algorithm\nHarmony search\nGaussian adaptation\nMemetic algorithm\nRelated topics\nArtificial development\nArtificial intelligence\nArtificial life\nDigital organism\nEvolutionary robotics\nFitness function\nFitness landscape\nFitness approximation\nGenetic operators\nInteractive evolutionary computation\nNo free lunch in search and optimization\nMachine learning\nMating pool\nProgram synthesis\nJournals\nEvolutionary Computation (journal)\n\nvteNeuroscience\nOutline\nHistory\nBasicscience\nBehavioral epigenetics\nBehavioral genetics\nBrain mapping\nBrain-reading\nCellular neuroscience\nComputational neuroscience\nConnectomics\nImaging genetics\nIntegrative neuroscience\nMolecular neuroscience\nNeural decoding\nNeural engineering\nNeuroanatomy\nNeurobiology\nNeurochemistry\nNeuroendocrinology\nNeurogenetics\nNeuroinformatics\nNeurometrics\nNeuromorphology\nNeurophysics\nNeurophysiology\nSystems neuroscience\nClinicalneuroscience\nBehavioral neurology\nClinical neurophysiology\nEpileptology\nNeurocardiology\nNeuroepidemiology\nNeurogastroenterology\nNeuroimmunology\nNeurointensive care\nNeurology\nNeuro-oncology\nNeuro-ophthalmology\nNeuropathology\nNeuropharmacology\nNeuroprosthetics\nNeuropsychiatry\nNeuroradiology\nNeurorehabilitation\nNeurosurgery\nNeurotology\nNeurovirology\nNutritional neuroscience\nPsychiatry\nCognitiveneuroscience\nAffective neuroscience\nBehavioral neuroscience\nChronobiology\nMolecular cellular cognition\nMotor control\nNeurolinguistics\nNeuropsychology\nSensory neuroscience\nSocial cognitive neuroscience\nInterdisciplinaryfields\nConsumer neuroscience\nCultural neuroscience\nEducational neuroscience\nEvolutionary neuroscience\nGlobal neurosurgery\nNeuroanthropology\nNeural engineering\nNeurobiotics\nNeurocriminology\nNeuroeconomics\nNeuroepistemology\nNeuroesthetics\nNeuroethics\nNeuroethology\nNeurohistory\nNeurolaw\nNeuromarketing\nNeuromorphic engineering\nNeurophenomenology\nNeurophilosophy\nNeuropolitics\nNeurorobotics\nNeurotheology\nPaleoneurobiology\nSocial neuroscience\nConcepts\nBrain\u2013computer interface\nDevelopment of the nervous system\nNeural network (artificial)\nNeural network (biological)\nDetection theory\nIntraoperative neurophysiological monitoring\nNeurochip\nNeurodegenerative disease\nNeurodevelopmental disorder\nNeurodiversity\nNeurogenesis\nNeuroimaging\nNeuroimmune system\nNeuromanagement\nNeuromodulation\nNeuroplasticity\nNeurotechnology\nNeurotoxin\nSelf-awareness\n\n Category\n Commons\n\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Neuroevolution&oldid=1236034036\""}, {"url": "https://en.wikipedia.org/wiki/Self-tuning", "content": "This article includes a list of general references, but it lacks sufficient corresponding inline citations. Please help to improve this article by introducing more precise citations. (August 2010) (Learn how and when to remove this message)\nIn control theory a self-tuning system is capable of optimizing its own internal running parameters in order to maximize or minimize the fulfilment of an objective function; typically the maximization of efficiency or error minimization.\nSelf-tuning and auto-tuning often refer to the same concept.  Many software research groups consider auto-tuning the proper nomenclature.\nSelf-tuning systems typically exhibit non-linear adaptive control.  Self-tuning systems have been a hallmark of the aerospace industry for decades, as this sort of feedback is necessary to generate optimal multi-variable control for non-linear processes.  In the telecommunications industry, adaptive communications are often used to dynamically modify operational system parameters to maximize efficiency and robustness.\n\n\nExamples[edit]\nExamples of self-tuning systems in computing include:\n\nTCP  (Transmission Control Protocol)\nMicrosoft SQL Server  (Newer implementations only)\nFFTW (Fastest Fourier Transform in the West)\nATLAS (Automatically Tuned Linear Algebra Software)\nlibtune (Tunables library for Linux)\nPhiPAC (Self Tuning Linear Algebra Software for RISC)\nMILEPOST GCC (Machine learning based self-tuning compiler)\nPerformance benefits can be substantial.  Professor Jack Dongarra, an American computer scientist, claims self-tuning boosts performance, often on the order of 300%.[1]\nDigital self-tuning controllers are an example of self-tuning systems at the hardware level.\n\nArchitecture[edit]\nSelf-tuning systems are typically composed of four components: expectations, measurement, analysis, and actions. The expectations describe how the system should behave given exogenous conditions.\nMeasurements gather data about the conditions and behaviour.  Analysis helps determine whether the expectations are being met- and which subsequent actions should be performed. Common actions are gathering more data and performing dynamic reconfiguration of the system.\nSelf-tuning (self-adapting) systems of automatic control are systems whereby adaptation to randomly changing conditions is performed by means of automatically changing parameters or via automatically determining their optimum configuration.[2] In any non-self-tuning automatic control system there are parameters which have an influence on system stability and control quality and which can be tuned. If these parameters remain constant whilst operating conditions (such as input signals or different characteristics of controlled objects) are substantially varying, control can degrade or even become unstable. Manual tuning is often cumbersome and sometimes impossible. In such cases, not only is using self-tuning systems technically and economically worthwhile, but it could be the only means of robust control. Self-tuning systems can be with or without parameter determination.\nIn systems with parameter determination the required level of control quality is achieved by automatically searching for an optimum (in some sense) set of parameter values. Control quality is described by a generalised characteristic which is usually a complex and not completely known or stable function of the primary parameters. This characteristic is either measured directly or computed based on the primary parameter values. The parameters are then tentatively varied. An analysis of the control quality characteristic oscillations caused by the varying of the parameters makes it possible to figure out if the parameters have optimum values, i.e.. if those values deliver extreme (minimum or maximum) values of the control quality characteristic. If the characteristic values deviate from an extremum, the parameters need to be varied until optimum values are found. Self-tuning systems with parameter determination can reliably operate in environments characterised by wide variations of exogenous conditions.\nIn practice systems with parameter determination require considerable time to find an optimum tuning, i.e. time necessary for self-tuning in such systems is bounded from below. Self-tuning systems without parameter determination do not have this disadvantage. In such systems, some characteristic of control quality is used (e.g., the first time derivative of a controlled parameter). Automatic tuning makes sure that this characteristic is kept within given bounds. Different self-tuning systems without parameter determination exist that are based on controlling transitional processes, frequency characteristics, etc. All of those are examples of closed-circuit self-tuning systems, whereby parameters are automatically corrected every time the quality characteristic value falls outside the allowable bounds. In contrast, open-circuit self-tuning systems are systems with para-metrical compensation, whereby input signal itself is controlled and system parameters are changed according to a specified procedure. This type of self-tuning can be close to instantaneous. However, in order to realise such self-tuning one needs to control the environment in which the system operates and a good enough understanding of how the environment influences the controlled system is required.\nIn practice self-tuning is done through the use of specialised hardware or adaptive software algorithms. Giving software the ability to self-tune (adapt):\n\nFacilitates controlling critical processes of systems;\nApproaches optimum operation regimes;\nFacilitates design unification of control systems;\nShortens the lead times of system testing and tuning;\nLowers the criticality of technological requirements on control systems by making the systems more robust;\nSaves personnel time for system tuning.\nMetaheuristics[edit]\nThis section is an excerpt from List of metaphor-based metaheuristics \u00a7 Self-tuning metaheuristics.[edit]\nSelf-tuning metaheuristics have emerged as a significant advancement in the field of optimization algorithms in recent years, since fine tuning can be a very long and difficult process.[3] These algorithms differentiate themselves by their ability to autonomously adjust their parameters in response to the problem at hand, enhancing efficiency and solution quality. This self-tuning capability is particularly important in complex optimization scenarios where traditional methods may struggle due to rigid parameter settings. In this attempt, a PSO variant has already been introduced that adopts fuzzy logic to automatically calculate the parameters of each particle[4] as well as the Flying fox optimization which is a fuzzy self tuning optimizer.[5]\n\nThe advent of self-tuning variants in metaheuristics, marks a pivotal shift towards more autonomous optimization tools. These self-tuning algorithms significantly reduce the need for expert intervention in parameter tuning, a process  requiring extensive domain knowledge. By leveraging fuzzy logic and other adaptive mechanisms, these algorithms can intelligently adjust their parameters in response to the problem's characteristics and search space dynamics. This autonomy not only simplifies the optimization process but also broadens the applicability of these algorithms, making them more accessible and effective for a wider range of users and complex problems. The ability of these self-tuning metaheuristics to perform effectively without perfect tuning by the user represents a considerable advancement in making optimization more user-friendly and efficient.\nLiterature[edit]\n\n\n^ http://appliedmathematician.org/pdf/news/781.pdf Faster than a Speeding Algorithm\n\n^ http://bse.sci-lib.com/article099233.html Big Soviet Encyclopedia, Self-Tuning Systems (in Russian)\n\n^ Huang, Changwu; Li, Yuanxiang; Yao, Xin (2019). \"A Survey of Automatic Parameter Tuning Methods for Metaheuristics\". IEEE Transactions on Evolutionary Computation. 24 (2): 201\u2013216. doi:10.1109/TEVC.2019.2921598. ISSN\u00a01089-778X.\n\n^ Nobile, Marco S.; Cazzaniga, Paolo; Besozzi, Daniela; Colombo, Riccardo; Mauri, Giancarlo; Pasi, Gabriella (2018). \"Fuzzy Self-Tuning PSO: A settings-free algorithm for global optimization\". Swarm and Evolutionary Computation. 39: 70\u201385. doi:10.1016/j.swevo.2017.09.001. hdl:10446/106467.\n\n^ Zervoudakis, Konstantinos; Tsafarakis, Stelios (2023). \"A global optimizer inspired from the survival strategies of flying foxes\". Engineering with Computers. 39 (2): 1583\u20131616. doi:10.1007/s00366-021-01554-w. ISSN\u00a00177-0667.\n\n\nExternal links[edit]\nUsing Probabilistic Reasoning to Automate Software Tuning\nFrigo, M. and Johnson, S. G., \"The design and implementation of FFTW3\", Proceedings of the IEEE, 93(2), February 2005, 216 - 231.  doi:10.1109/JPROC.2004.840301.\nOptimizing Matrix Multiply using PHiPAC: a Portable, High-Performance, ANSI C Coding Methodology\nFaster than a Speeding Algorithm\nRethinking Database System Architecture: Towards a Self-tuning RISC-style Database System\nSelf-Tuning Systems Software\nMicrosoft Research Adds Data Mining and Self-tuning Technology to SQL Server 2000\nA Comparison of TCP Automatic Tuning Techniques for Distributed Computing\nTunables library for Linux\nA Review of Relay Auto-tuning Methods for the Tuning of PID-type Controllers\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Self-tuning&oldid=1205470674\""}, {"url": "https://en.wikipedia.org/wiki/Neural_Network_Intelligence", "content": "Microsoft open source library\nNNI (Neural Network Intelligence)Original author(s)Microsoft ResearchDeveloper(s)MicrosoftInitial release2018; 6\u00a0years ago\u00a0(2018)[1]Stable releasev2.10[2]\n   / November\u00a014, 2022; 23 months ago\u00a0(2022-11-14)\nRepositorygithub.com/microsoft/nniWritten inPythonOperating systemWindows, macOS, UbuntuPlatformCross-platformTypeAutoML toolkitLicenseMIT LicenseWebsitenni.readthedocs.io\nNNI (Neural Network Intelligence) is a free and open-source AutoML toolkit developed by Microsoft.[3][4] It is used to automate feature engineering, model compression, neural architecture search, and hyper-parameter tuning.[5][6]\nThe source code is licensed under MIT License and available on GitHub.[7]\n\n\nSee also[edit]\nMachine learning\nML.NET\nReferences[edit]\n\n\n^ \"Tags \u00b7 microsoft/nni \u00b7 GitHub\". GitHub. 10 September 2021.\n\n^ \"Tags \u00b7 microsoft/nni \u00b7 GitHub\". GitHub. 28 June 2022.\n\n^ Raschka, Sebastian; Patterson, Joshua; Nolet, Corey (April 11, 2020). \"Machine Learning in Python: Main Developments and Technology Trends in Data Science, Machine Learning, and Artificial Intelligence\". Information. 11 (4): 193. arXiv:2002.04803. doi:10.3390/info11040193.\n\n^ \"Open Source AutoML Tools: AutoGluon, TransmogrifAI, Auto-sklearn, and NNI\". Bizety. June 16, 2020.\n\n^ Heller, Martin (August 21, 2019). \"Automated machine learning or AutoML explained\". InfoWorld.\n\n^ \"15 Undiscovered & Open Source Machine Learning Frameworks You Need to Know in 2020\". freeCodeCamp.org. June 4, 2020.\n\n^ \"microsoft/nni\". August 11, 2020 \u2013 via GitHub.\n\n\nFurther reading[edit]\nGridin, Ivan (2022). Automated Deep Learning Using Neural Network Intelligence: Develop and Design PyTorch and TensorFlow Models Using Python. Apress. ISBN\u00a0978-1484281482.\nExternal links[edit]\nnni on GitHub\nNeural Network Intelligence - Microsoft Research\nvteMicrosoft free and open-source software (FOSS)Overview\nMicrosoft and open source\nShared Source Initiative\nSoftwareApplications\n3D Movie Maker\nAtom\nConference XP\nFamily.Show\nFile Manager\nOpen Live Writer\nMicrosoft PowerToys\nTerminal\nWindows Calculator\nWindows Console\nWindows Package Manager\nWorldWide Telescope\nXML Notepad\nVideo games\nAllegiance\nProgramminglanguages\nBosque\nC#\nDafny\nF#\nF*\nGW-BASIC\nIronPython\nIronRuby\nLean\nP\nPower Fx\nPowerShell\nProject Verona\nQ#\nSmall Basic Online\nTypeScript\nVisual Basic\nFrameworks,development tools\n.NET\n.NET Framework\n.NET Gadgeteer\n.NET MAUI\n.NET Micro Framework\nAirSim\nASP.NET\nASP.NET AJAX\nASP.NET Core\nASP.NET MVC\nASP.NET Razor\nASP.NET Web Forms\nAvalonia\nBabylon.js\nBitFunnel\nBlazor\nC++/WinRT\nCCF\nChakraCore\nCLR Profiler\nDapr\nDeepSpeed\nDiskSpd\nDryad\nDynamic Language Runtime\neBPF on Windows\nElectron\nEntity Framework\nFluent Design System\nFluid Framework\nInfer.NET\nLightGBM\nManaged Extensibility Framework\nMicrosoft Automatic Graph Layout\nMicrosoft C++ Standard Library\nMicrosoft Cognitive Toolkit\nMicrosoft Design Language\nMicrosoft Detours\nMicrosoft Enterprise Library\nMicrosoft SEAL\nmimalloc\nMixed Reality Toolkit\nML.NET\nmod_mono\nMono\nMonoDevelop\nMSBuild\nMsQuic\nNeural Network Intelligence\nnpm\nNuGet\nOneFuzz\nOpen Management Infrastructure\nOpen Neural Network Exchange\nOpen Service Mesh\nOpen XML SDK\nOrleans\nPlaywright\nProcDump\nProcMon\nPython Tools for Visual Studio\nR Tools for Visual Studio\nRecursiveExtractor\nRoslyn\nSandcastle\nSignalR\nStyleCop\nSVNBridge\nT2 Temporal Prover\nText Template Transformation Toolkit\nTLA+ Toolbox\nU-Prove\nvcpkg\nVirtual File System for Git\nVoldemort\nVoTT\nVowpal Wabbit\nWindows App SDK\nWindows Communication Foundation\nWindows Driver Frameworks\nKMDF\nUMDF\nWindows Forms\nWindows Presentation Foundation\nWindows Template Library\nWindows UI Library\nWinJS\nWinObjC\nWiX\nXDP for Windows\nXSP\nxUnit.net\nZ3 Theorem Prover\nOperating systems\nMS-DOS (v1.25, v2.0 & v4.0)\nBarrelfish\nSONiC\nAzure Linux\nOther\nChronoZoom\nExtensible Storage Engine\nFlexWiki\nFourQ\nGollum\nProject Mu\nReactiveX\nSILK\nTLAPS\nTPM 2.0 Reference Implementation\nWikiBhasha\nLicenses\nMicrosoft Public License\nMicrosoft Reciprocal License\nForges\nCodePlex\nGitHub\nRelated\n.NET Foundation\nF# Software Foundation\nMicrosoft Open Specification Promise\nOpen Letter to Hobbyists\nOpen Source Security Foundation\nOutercurve Foundation\n Category\nvteMicrosoft Research (MSR)MainprojectsLanguages, compilers\nBartok\nBosque\nC\u03c9\nF*\nLean\nP\nProject Verona\nPhoenix\nPolyphonic C#\nSecPAL\nDistributed\u2013grid computing\nBitVault\nConfidential Consortium Framework\nDeepSpeed\nOrleans\nInternet, networking\nAjaxView\nAvalanche\nConference XP\nGazelle\nHoneyMonkey\nPenny Black\nWallop\nWikiBhasha\nOther projects\nAutomatic Graph Layout\nCognitive Toolkit\nDigits\nHoloportation\nIllumiRoom\nImage Composite Editor\nInfer.NET\nLightGBM\nLiveStation\nMyLifeBits\nNeural Network Intelligence\nNodeXL\nOneFuzz\nPhotoDNA\nSEAL\nSLAM\nT2 Temporal Prover\nWorldWide Telescope\nZ3 Theorem Prover\nOperating systems\nBarrelfish\nHomeOS\nMidori\nSingularity\nVerve\nAPIs\nAccelerator\nDryad\nJoins\nmimalloc\nSXM\nLaunched as products\nC#\nComic Chat\nDetours\nF#\nSideshow\nPixelSense (TouchLight)\nSenseCam\nClearType\nGroup Shot\nAllegiance\nTrueSkill\nSongsmith\nXbox\nKinect\nMSR LabsappliedresearchLive LabsCurrent\nPivot\nSeadragon\nDeep Zoom\nDiscontinued\nDeepfish\nListas\nLive Clipboard\nPhotosynth\nVolta\nFUSE Labs\nDocs.com\nKodu\nOther labs\nAcademic Search\nadCenter Labs\nOffice Labs\n Category\nPortal: Free and open-source software\nThis artificial intelligence-related article is a stub. You can help Wikipedia by expanding it.vte\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Neural_Network_Intelligence&oldid=1230619946\""}, {"url": "https://en.wikipedia.org/wiki/ModelOps", "content": "ModelOps (model operations or model operationalization), as defined by Gartner, \"is focused primarily on the governance and lifecycle management of a wide range of operationalized artificial intelligence (AI) and decision models, including machine learning, knowledge graphs, rules, optimization, linguistic and agent-based models\".[1] \"ModelOps lies at the heart of any enterprise AI strategy\".[2] It orchestrates the model lifecycles of all models in production across the entire enterprise, from putting a model into production, then evaluating and updating the resulting application according to a set of governance rules, including both technical and business key performance indicators (KPI's). It grants business domain experts the capability to evaluate AI models in production, independent of data scientists.[3]Illustrates the ModelOps cycle\nA Forbes article promoted ModelOps: \"As enterprises scale up their AI initiatives to become a true Enterprise AI organization, having full operationalized analytics capability puts ModelOps in the center, connecting both DataOps and DevOps.\"[4]\n\n\nHistory[edit]\nIn a 2018 Gartner survey, 37% of respondents reported that they had deployed AI in some form; however, Gartner pointed out that enterprises were still far from implementing AI, citing deployment challenges.[5] Enterprises were accumulating undeployed, unused, and unrefreshed models, and manually deployed, often at a business unit level, increasing the risk exposure of the entire enterprise.[6] Independent analyst firm Forrester also covered this topic in a 2018 report on machine learning and predictive analytics vendors: \u201cData scientists regularly complain that their models are only sometimes or never deployed. A big part of the problem is organizational chaos in understanding how to apply and design models into applications. But another big part of the problem is technology. Models aren\u2019t like software code because they need model management.\u201d[7]\nIn December 2018, Waldemar Hummer and Vinod Muthusamy of IBM Research AI, proposed ModelOps as \"a programming model for reusable, platform-independent, and composable AI workflows\" on IBM Programming Languages Day.[8] In their presentation, they noted the difference between the application development lifecycle, represented by DevOps, and the AI application lifecycle.[9]\nThe goal for developing ModelOps was to address the gap between model deployment and model governance, ensuring that all models were running in production with strong governance, aligned with technical and  business KPI's, while managing the risk. In their presentation, Hummer and Muthusamy described a programmatic solution for AI-aware staged deployment and reusable components that would enable model versions to match business apps, and which would include AI model concepts such as model monitoring, drift detection, and active learning. The solution would also address the tension between model performance and business KPI's, application and model logs, and model proxies and evolving policies.  Various cloud platforms were part of the proposal. In June 2019, Hummer, Muthusamy, Thomas Rausch, Parijat Dube, and Kaoutar El Maghraoui presented a paper at the 2019 IEEE International Conference on Cloud Engineering (IC2E).[10] The paper expanded on their 2018 presentation, proposing ModelOps as a cloud-based framework and platform for end-to-end development and lifecycle management of artificial intelligence (AI) applications. In the abstract, they stated that the framework would show how it is possible to extend the principles of software lifecycle management to enable automation, trust, reliability, traceability, quality control, and reproducibility of AI model pipelines.[11] In March 2020, ModelOp, Inc. published the first comprehensive guide to ModelOps methodology. The objective of this publication was to provide an overview of the capabilities of ModelOps, as well as the technical and organizational requirements for implementing ModelOps practices.[12]\n\nUse cases[edit]\nOne typical use case for ModelOps is in the financial services sector, where hundreds of time-series models are used to focus on strict rules for bias and auditability. In these cases, model fairness and robustness are critical, meaning the models have to be fair and accurate, and they have to run reliably. ModelOps automates the model lifecycle of models in production. Such automation includes designing the model lifecycle, inclusive of technical, business and compliance KPI's and thresholds, to govern and monitor the model as it runs, monitoring the models for bias and other technical and business anomalies, and updating the model as needed without disrupting the applications. ModelOps is the dispatcher that keeps all of the trains running on time and on the right track, ensuring risk control, compliance and business performance.\nAnother use case is the monitoring of a diabetic's blood sugar levels based on a patient's real-time data. The model that can predict hypoglycemia must be constantly refreshed with the current data, business KPI's and anomalies should be continuously monitored  and must be available in a distributed environment, so the information is available on a mobile device as well as reporting to a larger system. The orchestration, governance, retraining, monitoring, and refreshing is done with ModelOps.\n\nThe ModelOps process[edit]\nThe ModelOps process focuses on automating the governance, management and monitoring of models in production across the enterprise, enabling AI and application developers to easily plug in lifecycle capabilities (such as bias-detection, robustness and reliability, drift detection, technical, business and compliance KPI's, regulatory constraints and approval flows) for putting AI models into production as business applications. The process starts with a standard representation of candidate models for production that includes a metamodel (the model specification) with  all of the component and dependent pieces that go into building the model, such as the data, the hardware and software environments, the classifiers, and code plug-ins, and most importantly, the business and compliance/risk KPI's.\n\nModelOps: An evolution of MLOps[edit]\nMLOps (machine learning operations) is a discipline that enables data scientists and IT professionals to collaborate and communicate while automating machine learning algorithms. It extends and expands on the principles of DevOps to support the automation of developing and deploying machine learning models and applications.[13] As a practice, MLOps involves routine machine learning (ML) models. However, the variety and uses of models have changed to include decision optimization models, optimization models, and transformational models that are added to applications. ModelOps is an evolution of MLOps that expands its principles to include  not just the routine deployment of machine learning models but also the continuous retraining, automated updating, and synchronized development and deployment of more complex machine learning models.[14] ModelOps refers to the operationalization of all AI models, including the machine learning models with which MLOps is concerned.[15]\n\nReferences[edit]\n\n\n^ Brethenoux, Erick. \"Gartner Glossary\". Gartner. Retrieved 16 December 2020.\n\n^ Choudhary, Farhan. \"Gartner Glossary\". Gartner. Retrieved 6 August 2020.[dead link\u200d]\n\n^ Barot, Soyeb. \"A Guidance Framework for Operationalizing Machine Learning\". Gartner. Retrieved 6 August 2020.[dead link\u200d]\n\n^ Wu, Jun. \"ModelOps Is The Key To Enterprise AI\". Forbes. Retrieved 5 February 2021.\n\n^ \"Gartner Survey Shows 37 Percent of Organizations Have Implemented AI in Some Form\". Gartner Newsroom. 2018-01-21.\n\n^ Wu, Jun (2020), ModelOps Is the Key To Enterprise AI. (published 31 March 2020)\n\n^ \"Multimodal Predictive Analytics and Machine Learning Solutions, Q3 2018\" (PDF). IBM.\n\n^ \"IBM Programming Languages Day\".\n\n^ Waldemar Hummer and Vinod Muthusamy, A programming model for reusable, platform-independent, and composable AI workflows. IBM Research AI, 10 December 2018.\n\n^ \"IEEE International Conference on Cloud Engineering (IC2E)\".\n\n^ Hummer, Waldemar; Muthusamy, Vinod. ModelOps: Cloud-based Lifecycle Management for Reliable and Trusted AI. IEEE International Conference on Cloud Engineering. Parijat Dube, Kaoutar El Maghraoui. p.\u00a01.\n\n^ \"ModelOps Essentials: Best Practices for Success with Enterprise AI\" (PDF). ModelOp. Retrieved 7 August 2020.\n\n^ Talagala, Nisha (2018-01-30). \"Why MLOps (and not just ML) is your Business' New Competitive Frontier\". AITrends.\n\n^ \"Building ModelOps with intelligent automation for cloud-native apps accelerates growth with digital transformation initiatives\". 451 Research.\n\n^ Barot, Soyeb. \"Model Governance: The Crucial Tool for Business Success\".\n\n\n\n\n\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=ModelOps&oldid=1250505976\""}, {"url": "https://dx.doi.org/10.1093/oxfordhb/9780197653609.013.6", "content": "403 Forbidden\nRequest forbidden by administrative rules.\n\n"}, {"url": "https://dl.acm.org/citation.cfm?id=2487629", "content": "\n \nAuto-WEKA | Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskip to main content\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvanced Search\n\nBrowse\n\nAbout\n\n\n\n\n\n                Sign in\n            \n\n\n\n                        Register\n                    \n\n\n\n\n\n\n\n\nAdvanced SearchJournalsMagazinesProceedingsBooksSIGsConferencesPeopleMore\nSearch ACM Digital LibrarySearchSearch\nAdvanced Search\n\n\n\n10.1145/2487575.2487629acmconferencesArticle/Chapter ViewAbstractPublication PageskddConference Proceedingsconference-collectionskddConferenceProceedingsUpcoming EventsAuthorsAffiliationsAward WinnersMore\n\n\n\nHomeConferencesKDDProceedingsKDD '13Auto-WEKA: combined selection and hyperparameter optimization of classification algorithms\n\n\n\n\n\n\nposter\nShare on\nAuto-WEKA: combined selection and hyperparameter optimization of classification algorithmsAuthors: Chris Thornton, Frank Hutter, Holger H. Hoos, Kevin Leyton-BrownAuthors Info & ClaimsKDD '13: Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data miningPages 847 - 855https://doi.org/10.1145/2487575.2487629Published: 11 August 2013 Publication History\n846citation4,766DownloadsMetricsTotal Citations846Total Downloads4,766Last 12 Months313Last 6 weeks24\n\nGet Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account\nGet AccessContentsKDD '13: Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data miningAuto-WEKA: combined selection and hyperparameter optimization of classification algorithmsPages 847 - 855PREVIOUS CHAPTERMassively parallel expectation maximization using graphics processing unitsPreviousNEXT CHAPTERDirect optimization of ranking measures for learning to rank modelsNextAbstractReferences\n\n\n\nInformation & ContributorsBibliometrics & CitationsGet AccessReferencesMediaTablesShareAbstractMany different machine learning algorithms exist; taking into account each algorithm's hyperparameters, there is a staggeringly large number of possible alternatives overall. We consider the problem of simultaneously selecting a learning algorithm and setting its hyperparameters, going beyond previous work that attacks these issues separately. We show that this problem can be addressed by a fully automated approach, leveraging recent innovations in Bayesian optimization. Specifically, we consider a wide range of feature selection techniques (combining 3 search and 8 evaluator methods) and all classification approaches implemented in WEKA's standard distribution, spanning 2 ensemble methods, 10 meta-methods, 27 base classifiers, and hyperparameter settings for each classifier. On each of 21 popular datasets from the UCI repository, the KDD Cup 09, variants of the MNIST dataset and CIFAR-10, we show classification performance often much better than using standard selection and hyperparameter optimization methods. We hope that our approach will help non-expert users to more effectively identify machine learning algorithms and hyperparameter settings appropriate to their applications, and hence to achieve improved performance.References[1]M. Adankon and M. Cheriet. Model selection for the LS-SVM. application to handwriting recognition. Pattern Recognition, 42(12):3264--3270, 2009.Digital LibraryGoogle Scholar[2]R. Bardenet, M. Brendel, B. K\u00e9gl, and M. Sebag. Collaborative hyperparameter tuning. In Proc. of ICML-13, 2013.Google Scholar[3]Y. Bengio. Gradient-based optimization of hyperparameters. Neural Computation, 12(8):1889--1900, 2000.Digital LibraryGoogle Scholar[4]J. Bergstra, R. Bardenet, Y. Bengio, and B. K\u00e9gl. Algorithms for Hyper-Parameter Optimization. In Proc. of NIPS-11, 2011.Google Scholar[5]J. Bergstra and Y. Bengio. Random search for hyper-parameter optimization. JMLR, 13:281--305, 2012.Digital LibraryGoogle Scholar[6]A. Biem. A model selection criterion for classification: Application to HMM topology optimization. In Proc. of ICDAR-03, pages 104--108. IEEE, 2003.Digital LibraryGoogle Scholar[7]H. Bozdogan. Model selection and Akaike's information criterion (AIC): The general theory and its analytical extensions. Psychometrika, 52(3):345--370, 1987.CrossrefGoogle Scholar[8]P. Brazdil, C. Soares, and J. Da Costa. Ranking learning algorithms: Using IBL and meta-learning on accuracy and time results. Machine Learning, 50(3):251--277, 2003.Digital LibraryGoogle Scholar[9]E. Brochu, V. M. Cora, and N. de Freitas. A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. Technical Report UBC TR-2009-23 and arXiv:1012.2599v1, Department of Computer Science, University of British Columbia, 2009.Google Scholar[10]O. Chapelle, V. Vapnik, and Y. Bengio. Model selection for small sample regression. Machine Learning, 2001.Digital LibraryGoogle Scholar[11]T. Desautels, A. Krause, and J. Burdick. Parallelizing exploration-exploitation tradeoffs with gaussian process bandit optimization. In Proc. of ICML-12, 2012.Google Scholar[12]A. Frank and A. Asuncion. UCI machine learning repository, 2010. URL: http://archive.ics.uci.edu/ml. University of California, Irvine, School of Information and Computer Sciences.Google Scholar[13]X. Guo, J. Yang, C. Wu, C. Wang, and Y. Liang. A novel LS-SVMs hyper-parameter selection based on particle swarm optimization. Neurocomputing, 71(16):3211--3215, 2008.Digital LibraryGoogle Scholar[14]M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, and I. Witten. The WEKA data mining software: an update. ACM SIGKDD Explorations Newsletter, 11(1):10--18, 2009.Digital LibraryGoogle Scholar[15]F. Hutter, H. Hoos, and K. Leyton-Brown. Sequential model-based optimization for general algorithm configuration. In Proc. of LION-5, pages 507--523, 2011.Digital LibraryGoogle Scholar[16]F. Hutter, H. Hoos, K. Leyton-Brown, and T. St\u00fctzle. ParamILS: an automatic algorithm configuration framework. JAIR, 36(1):267--306, 2009.Digital LibraryGoogle Scholar[17]F. Hutter, H. H. Hoos, and K. Leyton-Brown. Parallel algorithm configuration. In Proc. of LION-6, pages 55--70, 2012.Digital LibraryGoogle Scholar[18]D. R. Jones, M. Schonlau, and W. J. Welch. Efficient global optimization of expensive black box functions. Journal of Global Optimization, 13:455--492, 1998.Digital LibraryGoogle Scholar[19]R. Kohavi. A study of cross-validation and bootstrap for accuracy estimation and model selection. In Proc. of IJCAI-95, pages 1137--1145, 1995.Digital LibraryGoogle Scholar[20]A. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images. Master's thesis, Department of Computer Science, University of Toronto, 2009.Google Scholar[21]R. Leite, P. Brazdil, and J. Vanschoren. Selecting classification algorithms with active testing. In Proc. of MLDM-12, pages 117--131, 2012.Digital LibraryGoogle Scholar[22]M. L\u00f3pez-Ib\u00e1\u00f1ez, J. Dubois-Lacoste, T. St\u00fctzle, and M. Birattari. The irace package, iterated race for automatic algorithm configuration. Technical Report TR/IRIDIA/2011-004, IRIDIA, Universit\u00e9 Libre de Bruxelles, Belgium, 2011.Google Scholar[23]O. Maron and A. Moore. Hoeffding races: Accelerating model selection search for classification and function approximation. In Proc. of NIPS-94, pages 59--66, 1994.Google Scholar[24]A. McQuarrie and C. Tsai. Regression and time series model selection. World Scientific, 1998.CrossrefGoogle Scholar[25]B. Pfahringer, H. Bensusan, and C. Giraud-Carrier. Meta-learning by landmarking various learning algorithms. In Proc. of ICML-00, pages 743--750, 2000.Digital LibraryGoogle Scholar[26]T. Schaul, J. Bayer, D. Wierstra, Y. Sun, M. Felder, F. Sehnke, T. R\u00fcckstie\u00df, and J. Schmidhuber. PyBrain. JMLR, 2010.Digital LibraryGoogle Scholar[27]M. Schonlau, W. J. Welch, and D. R. Jones. Global versus local search in constrained optimization of computer models. In N. Flournoy, W. Rosenberger, and W. Wong, editors, New Developments and Applications in Experimental Design, volume 34, pages 11--25. Institute of Mathematical Statistics, Hayward, California, 1998.CrossrefGoogle Scholar[28]J. Snoek, H. Larochelle, and R. Adams. Opportunity cost in Bayesian optimization. In NIPS Workshop on Bayesian Optimization, Sequential Experimental Design, and Bandits, 2011. Published online.Google Scholar[29]J. Snoek, H. Larochelle, and R. P. Adams. Practical bayesian optimization of machine learning algorithms. In Proc. of NIPS-12, 2012.Google Scholar[30]N. Srinivas, A. Krause, S. Kakade, and M. Seeger. Gaussian process optimization in the bandit setting: No regret and experimental design. In Proc. of ICML-10, pages 1015--1022, 2010.Google Scholar[31]V. Strijov and G. Weber. Nonlinear regression model generation using hyperparameter optimization. Computers & Mathematics with Applications, 60(4):981--988, 2010.Digital LibraryGoogle Scholar[32]R. Vilalta and Y. Drissi. A perspective view and survey of meta-learning. Artif. Intell. Rev., 18(2):77--95, Oct. 2002.Digital LibraryGoogle Scholar[33]L. Xu, H. H. Hoos, and K. Leyton-Brown. Hydra: Automatically configuring algorithms for portfolio-based selection. In Proc. of AAAI-10, pages 210--216, 2010.Google Scholar[34]P. Zhao and B. Yu. On model selection consistency of lasso. JMLR, 7:2541--2563, Dec. 2006.Digital LibraryGoogle Scholar\n\n\n\n\nCited ByView allAvc\u0131 E(2024)A No-Code Automated Machine Learning Platform for the Energy SectorGazi University Journal of Science Part A: Engineering and Innovation10.54287/gujsa.147378211:2(289-303)Online publication date: 4-Jun-2024https://doi.org/10.54287/gujsa.1473782Gaber MKang YSchurgers GKeenan T(2024)Using automated machine learning for the upscaling of gross primary productivityBiogeosciences10.5194/bg-21-2447-202421:10(2447-2472)Online publication date: 24-May-2024https://doi.org/10.5194/bg-21-2447-2024Zheng SLiu J(2024)Review of Deep Learning in High-Energy Heavy-Ion CollisionsSymmetry10.3390/sym1611142616:11(1426)Online publication date: 26-Oct-2024https://doi.org/10.3390/sym16111426Show More Cited By\n\n\n\n\n\nIndex Terms\nAuto-WEKA: combined selection and hyperparameter optimization of classification algorithmsComputing methodologiesMachine learningMathematics of computingMathematical analysisMathematical optimizationTheory of computationDesign and analysis of algorithmsMathematical optimization\n\n\n\n\n\n\n\nRecommendations\nAuto-WEKA 2.0: automatic model selection and hyperparameter optimization in WEKA\nWEKA is a widely used, open-source machine learning platform. Due to its intuitive interface, it is particularly popular with novice users. However, such users often find it hard to identify the best approach for their particular dataset among the many ...Read MorePerformance Evaluation of Ensemble Methods For Software Fault Prediction: An ExperimentASWEC ' 15 Vol. II: Proceedings of the ASWEC 2015 24th Australasian Software Engineering Conference  \nIn object-oriented software development, a plethora of studies have been carried out to present the application of machine learning algorithms for fault prediction. Furthermore, it has been empirically validated that an ensemble method can improve ...Read MoreResearch of Text Categorization on WEKAISDEA '13: Proceedings of the 2013 Third International Conference on Intelligent System Design and Engineering Applications  \nThe choice of algorithm is a key text categorization problem. In order to evaluation synthetically, analyzed three popular text categorization algorithm that are naive Bayes (NB), decision tree(DT) and support vector machines(SVM). Carried on simulation ...Read More\n\n\n\n\n\n\n\n\n\n\nComments\nPlease enable JavaScript to view thecomments powered by Disqus.\n\n\n\n\nInformation & ContributorsInformationPublished In\nKDD '13: Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data miningAugust 20131534  pagesISBN:9781450321747DOI:10.1145/2487575Editors: Rayid GhaniUniversity of Chicago,Ted E. SenatorSAIC,Paul BradleyMethodCare, Inc.,Rajesh ParekhGroupon,Jingrui HeStevens Institute of Technology,General Chairs: Robert L. GrossmanUniversity of Chicago and Open Data Group,Ramasamy UthurusamyGeneral Motors Corporation (retired),Program Chairs: Inderjit S. DhillonUniversity of Texas,Yehuda KorenGoogle\nCopyright \u00a9 2013 ACM.Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from [email\u00a0protected].SponsorsSIGMOD: ACM Special Interest Group on Management of DataSIGKDD: ACM Special Interest Group on Knowledge Discovery in DataPublisherAssociation for Computing MachineryNew York, NY, United StatesPublication HistoryPublished: 11 August 2013PermissionsRequest permissions for this article.Request PermissionsCheck for updatesAuthor Tagshyperparameter optimizationmodel selectionwekaQualifiersPosterConferenceKDD' 13Sponsor:SIGMODSIGKDDKDD' 13: The 19th ACM SIGKDD International Conference on Knowledge Discovery and Data MiningAugust 11 - 14, 2013Illinois, Chicago, USA\nAcceptance RatesOverall Acceptance Rate 66 of 1,115 submissions, 6%\nContributors\n\n\n\nOther MetricsView Article MetricsBibliometrics & CitationsBibliometrics\n\n                Article Metrics\n            \n846Total CitationsView Citations4,766Total DownloadsDownloads (Last 12 months)313Downloads (Last 6 weeks)24Reflects downloads up to 16 Nov 2024\nOther MetricsView Author MetricsCitations\nCited ByView allAvc\u0131 E(2024)A No-Code Automated Machine Learning Platform for the Energy SectorGazi University Journal of Science Part A: Engineering and Innovation10.54287/gujsa.147378211:2(289-303)Online publication date: 4-Jun-2024https://doi.org/10.54287/gujsa.1473782Gaber MKang YSchurgers GKeenan T(2024)Using automated machine learning for the upscaling of gross primary productivityBiogeosciences10.5194/bg-21-2447-202421:10(2447-2472)Online publication date: 24-May-2024https://doi.org/10.5194/bg-21-2447-2024Zheng SLiu J(2024)Review of Deep Learning in High-Energy Heavy-Ion CollisionsSymmetry10.3390/sym1611142616:11(1426)Online publication date: 26-Oct-2024https://doi.org/10.3390/sym16111426Liang PQin CZhu A(2024)Using Automated Machine Learning for Spatial Prediction\u2014The Heshan Soil Subgroups Case StudyLand10.3390/land1304055113:4(551)Online publication date: 20-Apr-2024https://doi.org/10.3390/land13040551Grigore ITavares GSilva MCeravolo PBarbon Junior S(2024)Automated Trace Clustering Pipeline Synthesis in Process MiningInformation10.3390/info1504024115:4(241)Online publication date: 20-Apr-2024https://doi.org/10.3390/info15040241Raza APhan TLi HHieu NNghia TChing C(2024)A Comparative Study of Machine Learning Classifiers for Enhancing Knee Osteoarthritis DiagnosisInformation10.3390/info1504018315:4(183)Online publication date: 28-Mar-2024https://doi.org/10.3390/info15040183Kampezidou STikayat Ray ABhat APinon Fischer OMavris D(2024)Fundamental Components and Principles of Supervised Machine Learning Workflows with Numerical and Categorical DataEng10.3390/eng50100215:1(384-416)Online publication date: 29-Feb-2024https://doi.org/10.3390/eng5010021Imamoglu E(2024)Artificial Intelligence and/or Machine Learning Algorithms in Microalgae BioprocessesBioengineering10.3390/bioengineering1111114311:11(1143)Online publication date: 13-Nov-2024https://doi.org/10.3390/bioengineering11111143Bizzarri AFraccaroli MLamma ERiguzzi F(2024)Integration between constrained optimization and deep networks: a surveyFrontiers in Artificial Intelligence10.3389/frai.2024.14147077Online publication date: 19-Jun-2024https://doi.org/10.3389/frai.2024.1414707Gkioka GDominguez MMentzas G(2024)An AutoML-based approach for automatic traffic incident detection in smart citiesIntelligent Decision Technologies10.3233/IDT-24023118:2(1101-1122)Online publication date: 7-Jun-2024https://doi.org/10.3233/IDT-240231Show More Cited By\nView Options\nLogin optionsCheck if you have access through your login credentials or your institution to get full access on this article.Sign inFull AccessGet this Publication\nView options PDFView or Download as a PDF file.PDF eReaderView online with eReader.eReaderMediaFiguresOtherTablesShareShareShare this Publication linkCopy LinkCopied!Copying failed.Share on social mediaXLinkedInRedditFacebookemailAffiliationsChris ThorntonUniversity of British Columbia, Vancouver, BC, CanadaView ProfileFrank HutterUniversity of British Columbia, Vancouver, BC, CanadaView ProfileHolger H. HoosUniversity of British Columbia, Vancouver, BC, CanadaView ProfileKevin Leyton-BrownUniversity of British Columbia, Vancouver, BC, CanadaView ProfileDownload PDF\n\n\n\n\n\nView Table of Contents\nExport CitationsSelect Citation formatBibTeXEndNoteACM RefPlease download or close your previous search result export first before starting a new bulk export.Preview is not available.By clicking download,a status dialog will open to start the export process. The process may takea few minutes but once it finishes a file will be downloadable from your browser. You may continue to browse the DL while the export process is in progress.DownloadDownload citationCopy citation\n\n\n\nFooter\n\n\n\n\n\n\n\n\nCategories\n\nJournals\nMagazines\nBooks\nProceedings\nSIGs\nConferences\nCollections\nPeople\n\n\n\n\nAbout\n\nAbout ACM Digital Library\nACM Digital Library Board\nSubscription Information\nAuthor Guidelines\nUsing ACM Digital Library\nAll Holdings within the ACM Digital Library\nACM Computing Classification System\nAccessibility Statement\n\n\n\n\nJoin\n\nJoin ACM\nJoin SIGs\nSubscribe to Publications\nInstitutions and Libraries\n\n\n\n\nConnect\n\nContact us via email\nACM on Facebook\nACM DL on X\nACM on Linkedin\n\nSend Feedback\nSubmit a Bug Report\n\n\n\n\n\n\n\n\nThe ACM Digital Library is published by the Association for Computing Machinery. Copyright \u00a9 2024 ACM, Inc.\n\nTerms of Usage\nPrivacy Policy\nCode of Ethics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYour Search Results Download Request We are preparing your search results for download ...We will inform you here when the file is ready.Download now!Your Search Results Download RequestYour file of search results citations is now ready.Download now!Your Search Results Download RequestYour search export query has expired. Please try again.\n\n\n\n\n\n\n\n\n"}, {"url": "http://icml2014.automl.org/", "content": "\n\nNot Found\n\n\n\nNot Found\nError 404\n\n\n"}, {"url": "https://doi.org/10.1007%2F978-3-319-31204-0_9", "content": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutomating Biomedical Data Science Through Tree-Based Pipeline Optimization | SpringerLink\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to main content\n\n\n\nAdvertisement\n\n\n\n\n\n\n\n\n\n\n\nLog in\n\n\n\n\n\n\n\nMenu\n\n\n\n\n                            Find a journal\n                        \n\n                            Publish with us\n                        \n\n                            Track your research\n                        \n\n\n\n\n\n\nSearch\n\n\n\n\n\n\nCart\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHome\n\n\n\n\n\nApplications of Evolutionary Computation\n\n\n\n\n\nConference paper\n\n\n\nAutomating Biomedical Data Science Through Tree-Based Pipeline Optimization\n\nConference paper\nFirst Online: 15 March 2016\n\n\n\n pp 123\u2013137\n\n\nCite this conference paper\n\n\n\n\n\n\n\n\n\n\n\nApplications of Evolutionary Computation\n\n(EvoApplications 2016) \n\n\n\n\n\n\n\n\n\n\n\nRandal S. Olson15, Ryan J. Urbanowicz15, Peter C. Andrews15, Nicole A. Lavender16, La Creis Kidd16 & \u2026Jason H. Moore15\u00a0Show authors\n\n\n\n\n\n\n\nPart of the book series:\nLecture Notes in Computer Science ((LNTCS,volume 9597))\n                    \n\n\n\n\n\n\n\n\nIncluded in the following conference series:\n\nEuropean Conference on the Applications of Evolutionary Computation\n\n\n\n\n\n\n\n\n\n6106 Accesses\n\n\n\n\n112 \nCitations\n\n\n\n\n\n11\n                    \nAltmetric\n\n\n\n\n\n\n\n\n\n AbstractOver the past decade, data science and machine learning has grown from a mysterious art form to a staple tool across a variety of fields in academia, business, and government. In this paper, we introduce the concept of tree-based pipeline optimization for automating one of the most tedious parts of machine learning\u2014pipeline design. We implement a Tree-based Pipeline Optimization Tool (TPOT) and demonstrate its effectiveness on a series of simulated and real-world genetic data sets. In particular, we show that TPOT can build machine learning pipelines that achieve competitive classification accuracy and discover novel pipeline operators\u2014such as synthetic feature constructors\u2014that significantly improve classification accuracy on these data sets. We also highlight the current challenges to pipeline optimization, such as the tendency to produce pipelines that overfit the data, and suggest future research paths to overcome these challenges. As such, this work represents an early step toward fully automating machine learning pipeline design.\n\n\n\n\n\n                                \n                                    This is a preview of subscription content, log in via an institution\n\n\n to check access.\n                            \n\n\nAccess this chapter\n\n\nLog in via an institution\n\n\n\n\n\n\n\n\n\nSubscribe and save\n\n\n\n\n\nSpringer+ Basic\n\n\n      \u20ac32.70 /Month\n     \n\n\nGet 10 units per month\nDownload Article/Chapter or eBook\n1 Unit = 1 Article or 1 Chapter\nCancel anytime\n Subscribe now \n\n\n\n\nBuy Now\n\n\n\n\n\n\n\n\n Chapter\n      \n\n\n        EUR\u00a029.95\n       \n\n\n       Price includes VAT (France)\n      \n\n\n        \n\nAvailable as PDF\nRead on any device\nInstant download\nOwn it forever\n\nBuy Chapter \n       \n\n\n\n\n\n\n\n\n\n eBook\n      \n\n       EUR\u00a085.59\n      \n\n       Price includes VAT (France)\n      \n\n\n    \n\nAvailable as EPUB and PDF\nRead on any device\nInstant download\nOwn it forever\n\nBuy eBook \n       \n\n\n\n\n\n\n\n\n\n Softcover Book\n      \n\n       EUR\u00a0105.49\n      \n\n       Price includes VAT (France)\n      \n\n\n    \n\nCompact, lightweight edition\nDispatched in 3 to 5 business days\nFree shipping worldwide - see info\n\nBuy Softcover Book \n       \n\n\n\n\n\n\n\nTax calculation will be finalised at checkout\nPurchases are for personal use only\n\n\n\n\n\n\n\n\nInstitutional subscriptions\n                                        \n\n\n\n\n\n\n\n\nSimilar content being viewed by others\n\n\n\n\n\n\nGenetic Programming as an Innovation Engine for Automated Machine Learning: The Tree-Based Pipeline Optimization Tool (TPOT)\n                                        \n\n\nChapter\n\u00a9 2024\n\n\n\n\n\n\n\n\n\nMachine Learning\u2014Automated Machine Learning (AutoML) for Disease Prediction\n                                        \n\n\nChapter\n\u00a9 2023\n\n\n\n\n\n\n\n\n\nNaive automated machine learning\n                                        \n\n\nArticle\nOpen access\n29 September 2022\n\n\n\n\n\n\n\n ReferencesRJMetrics: The State of Data Science, November 2015. https://rjmetrics.com/resources/reports/the-state-of-data-science/\nHornby, G.S., Lohn, J.D., Linden, D.S.: Computer-automated evolution of an X-band antenna for NASA\u2019s space technology 5 mission. Evol. Comput. 19(1), 1\u201323 (2011)Article\u00a0\n    \n                    Google Scholar\u00a0\n                Forrest, S., Nguyen, T., Weimer, W., Le Goues, C.: A genetic programming approach to automated software repair. In: Proceedings of the 11th Annual Conference on Genetic and Evolutionary Computation, GECCO 2009, pp. 947\u2013954. ACM, New York (2009)\n                        Google Scholar\u00a0\n                Spector, L., Clark, D.M., Lindsay, I., Barr, B., Klein, J.: Genetic programming for finite algebras. In: Proceedings of the 10th Annual Conference on Genetic and Evolutionary Computation, GECCO 2008, pp. 1291\u20131298. ACM, New York (2008)\n                        Google Scholar\u00a0\n                Banzhaf, W., Nordin, P., Keller, R.E., Francone, F.D.: Genetic Programming: An Introduction. Morgan Kaufmann, San Meateo (1998)Book\u00a0\n    MATH\u00a0\n    \n                    Google Scholar\u00a0\n                Hutter, F., L\u00fccke, J., Schmidt-Thieme, L.: Beyond manual tuning of hyperparameters. KI - K\u00fcnstliche Intelligenz 29(4), 329\u2013337 (2015)Article\u00a0\n    \n                    Google Scholar\u00a0\n                Bergstra, J., Bengio, Y.: Random search for hyper-parameter optimization. J. Mach. Learn. Res. 13, 281\u2013305 (2012)MathSciNet\u00a0\n    MATH\u00a0\n    \n                    Google Scholar\u00a0\n                Snoek, J., Larochelle, H., Adams, R.P.: Practical bayesian optimization of machine learning algorithms. In: Pereira, F., Burges, C.J.C., Bottou, L., Weinberger, K.Q. (eds.) Advances in Neural Information Processing Systems, vol. 25, pp. 2951\u20132959. Curran Associates, Inc. (2012)\n                        Google Scholar\u00a0\n                Kanter, J.M., Veeramachaneni, K.: Deep feature synthesis: towards automating data science endeavors. In: Proceedings of the International Conference on Data Science and Advance Analytics. IEEE (2015)\n                        Google Scholar\u00a0\n                Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., et al.: Scikit-learn: machine learning in python. J. Mach. Learn. Res. 12, 2825\u20132830 (2011)MathSciNet\u00a0\n    MATH\u00a0\n    \n                    Google Scholar\u00a0\n                Hastie, T.J., Tibshirani, R.J., Friedman, J.H.: The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Springer, New York (2009)Book\u00a0\n    MATH\u00a0\n    \n                    Google Scholar\u00a0\n                Pan, Q., Hu, T., Malley, J.D., Andrew, A.S., Karagas, M.R., Moore, J.H.: A system-level pathway-phenotype association analysis using synthetic feature random forest. Genet. Epidemiol. 38(3), 209\u2013219 (2014)Article\u00a0\n    \n                    Google Scholar\u00a0\n                Fortin, F.A., Gardner, M.A., Parizeau, M., Gagne, C., de Rainville, F.M.: DEAP: evolutionary algorithms made easy. J. Mach. Learn. Res. 13, 2171\u20132175 (2012)MathSciNet\u00a0\n    MATH\u00a0\n    \n                    Google Scholar\u00a0\n                Urbanowicz, R.J., Kiralis, J., Fisher, J.M., Moore, J.H.: Predicting the difficulty of pure, strict, epistatic models: metrics for simulated model selection. BioData Min. 5(1), 1\u201313 (2012)Article\u00a0\n    \n                    Google Scholar\u00a0\n                Urbanowicz, R.J., Kiralis, J., Sinnott-Armstrong, N.A., Heberling, T., Fisher, J.M., Moore, J.H.: GAMETES: a fast, direct algorithm for generating pure, strict, epistatic models with random architectures. BioData Min. 5(1), 1\u201314 (2012)Article\u00a0\n    \n                    Google Scholar\u00a0\n                Moore, J.H., Hill, D.P., Sulovari, A., Kidd, L.C.: Genetic analysis of prostate cancer using computational evolution, pareto-optimization and post-processing. In: Riolo, R., Vladislavleva, E., Ritchie, M.D., Moore, J.H. (eds.) Genetic Programming Theory and Practice X, pp. 87\u2013101. Springer, New York (2013)Chapter\u00a0\n    \n                    Google Scholar\u00a0\n                Breiman, L., Cutler, A.: Random forests - classification description, November 2015. http://www.stat.berkeley.edu/breiman/RandomForests/cc_home.htm\nGoldberg, D.E.: The Design of Innovation: Lessons from and for Competent Genetic Algorithms. Kluwer Academic Publishers, Norwell (2002)Book\u00a0\n    MATH\u00a0\n    \n                    Google Scholar\u00a0\n                Konak, A., Coit, D.W., Smith, A.E.: Multi-objective optimization using genetic algorithms: a tutorial. Reliab. Eng. Syst. Saf. 91(9), 992\u20131007 (2006)Article\u00a0\n    \n                    Google Scholar\u00a0\n                Deb, K., Pratap, A., Agarwal, S., Meyarivan, T.: A fast and elitist multiobjective genetic algorithm: NSGA-II. IEEE Trans. Evol. Comput. 6(2), 182\u2013197 (2002)Article\u00a0\n    \n                    Google Scholar\u00a0\n                Greene, C.S., Penrod, N.M., Kiralis, J., Moore, J.H.: Spatially Uniform ReliefF (SURF) for computationally-efficient filtering of gene-gene interactions. BioData Min. 2(1), 1 (2009)Article\u00a0\n    \n                    Google Scholar\u00a0\n                Download references AcknowledgmentsWe thank Sebastian Raschka for his valuable input during the development of this project. We also thank the Michigan State University High Performance Computing Center for the use of their computing resources. This work was supported by National Institutes of Health grants LM009012, LM010098, and EY022300. Author informationAuthors and AffiliationsInstitute for Biomedical Informatics, University of Pennsylvania, 3700 Hamilton Walk, Philadelphia, PA, 19104, USARandal S. Olson,\u00a0Ryan J. Urbanowicz,\u00a0Peter C. Andrews\u00a0&\u00a0Jason H. MooreUniversity of Louisville, 505 S. Hancock St., Louisville, KY, 40202, USANicole A. Lavender\u00a0&\u00a0La Creis KiddAuthorsRandal S. OlsonView author publicationsYou can also search for this author in\n                        PubMed\u00a0Google ScholarRyan J. UrbanowiczView author publicationsYou can also search for this author in\n                        PubMed\u00a0Google ScholarPeter C. AndrewsView author publicationsYou can also search for this author in\n                        PubMed\u00a0Google ScholarNicole A. LavenderView author publicationsYou can also search for this author in\n                        PubMed\u00a0Google ScholarLa Creis KiddView author publicationsYou can also search for this author in\n                        PubMed\u00a0Google ScholarJason H. MooreView author publicationsYou can also search for this author in\n                        PubMed\u00a0Google ScholarCorresponding authorCorrespondence to\n                Randal S. Olson . Editor informationEditors and AffiliationsPolitecnico di Torino, Turin, ItalyGiovanni Squillero Aalborg University, Copenhagen, DenmarkPaolo Burelli  Rights and permissionsReprints and permissions Copyright information\u00a9 2016 Springer International Publishing Switzerland About this paperCite this paperOlson, R.S., Urbanowicz, R.J., Andrews, P.C., Lavender, N.A., Kidd, L.C., Moore, J.H. (2016).  Automating Biomedical Data Science Through Tree-Based Pipeline Optimization.\n\n                     In: Squillero, G., Burelli, P. (eds) Applications of Evolutionary Computation. EvoApplications 2016. Lecture Notes in Computer Science(), vol 9597. Springer, Cham. https://doi.org/10.1007/978-3-319-31204-0_9Download citation.RIS.ENW.BIBDOI: https://doi.org/10.1007/978-3-319-31204-0_9Published: 15 March 2016\n                            Publisher Name: Springer, Cham\n                                Print ISBN: 978-3-319-31203-3\n                                Online ISBN: 978-3-319-31204-0eBook Packages: Computer ScienceComputer Science (R0)Share this paperAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboard\n                                Provided by the Springer Nature SharedIt content-sharing initiative\n                             Publish with usPolicies and ethics\n\n\n\n\n\n\n\n\n\n\nAccess this chapter\n\n\nLog in via an institution\n\n\n\n\n\n\n\n\n\nSubscribe and save\n\n\n\n\n\nSpringer+ Basic\n\n\n      \u20ac32.70 /Month\n     \n\n\nGet 10 units per month\nDownload Article/Chapter or eBook\n1 Unit = 1 Article or 1 Chapter\nCancel anytime\n Subscribe now \n\n\n\n\nBuy Now\n\n\n\n\n\n\n\n\n Chapter\n      \n\n\n        EUR\u00a029.95\n       \n\n\n       Price includes VAT (France)\n      \n\n\n        \n\nAvailable as PDF\nRead on any device\nInstant download\nOwn it forever\n\nBuy Chapter \n       \n\n\n\n\n\n\n\n\n\n eBook\n      \n\n       EUR\u00a085.59\n      \n\n       Price includes VAT (France)\n      \n\n\n    \n\nAvailable as EPUB and PDF\nRead on any device\nInstant download\nOwn it forever\n\nBuy eBook \n       \n\n\n\n\n\n\n\n\n\n Softcover Book\n      \n\n       EUR\u00a0105.49\n      \n\n       Price includes VAT (France)\n      \n\n\n    \n\nCompact, lightweight edition\nDispatched in 3 to 5 business days\nFree shipping worldwide - see info\n\nBuy Softcover Book \n       \n\n\n\n\n\n\n\nTax calculation will be finalised at checkout\nPurchases are for personal use only\n\n\n\n\n\n\n\n\nInstitutional subscriptions\n                                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSearch\n\n\n\nSearch by keyword or author\n\n\n\n\n\n\nSearch\n\n\n\n\n\n\n\nNavigation\n\n\n\n                        Find a journal\n\t\t\t\t\t\t\t\t\t \n\n\n\n                        Publish with us\n\t\t\t\t\t\t\t\t\t \n\n\n\n                        Track your research\n\t\t\t\t\t\t\t\t\t \n\n\n\n\n\n\n\n\nDiscover content\n\nJournals A-Z\nBooks A-Z\n\n\n\nPublish with us\n\nJournal finder\nPublish your research\nOpen access publishing\n\n\n\nProducts and services\n\nOur products\nLibrarians\nSocieties\nPartners and advertisers\n\n\n\nOur imprints\n\nSpringer\nNature Portfolio\nBMC\nPalgrave Macmillan\nApress\n\n\n\n\n\n\n\n\nYour privacy choices/Manage cookies\n\n\nYour US state privacy rights\n\n\nAccessibility statement\n\n\nTerms and conditions\n\n\nPrivacy policy\n\n\nHelp and support\n\n\nCancel contracts here\n\n\n\n\n\n77.140.51.41\n\nNot affiliated\n\n\n\n\n\u00a9 2024 Springer Nature\n\n\n\n\n\n\n\n\n\n\n"}, {"url": "https://doi.org/10.1145%2F3495256", "content": "\n \nAutomating data science | Communications of the ACM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskip to main content\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvanced Search\n\nBrowse\n\nAbout\n\n\n\n\n\n                Sign in\n            \n\n\n\n                        Register\n                    \n\n\n\n\n\n\n\n\nAdvanced SearchJournalsMagazinesProceedingsBooksSIGsConferencesPeopleMore\nSearch ACM Digital LibrarySearchSearch\nAdvanced Search\n\n\n\nCommunications of the ACMMagazine HomeOnline First                                        Latest Issue\n\nArchiveAuthorsReviewersAboutCACM AffiliationsACM Award WinnersMore\n\n\n\n\n\n\n\n\n\n\nHomeMagazinesCommunications of the ACMVol. 65, No. 3Automating data science\n\n\n\n\n\n\nresearch-articlePublic Access\nShare on\nAutomating data scienceAuthors: Tijl De Bie, Luc De Raedt, Jos\u00e9 Hern\u00e1ndez-Orallo, Holger H. Hoos, Padhraic Smyth, Christopher K. I. WilliamsAuthors Info & ClaimsCommunications of the ACM, Volume 65, Issue 3Pages 76 - 87https://doi.org/10.1145/3495256Published: 23 February 2022 Publication History\n19citation19,660DownloadsMetricsTotal Citations19Total Downloads19,660Last 12 Months1,178Last 6 weeks119\n\nGet Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account\nAll formatsPDFContentsCommunications of the ACMVolume 65, Issue 3PREVIOUS ARTICLEA tale of three datasetsPreviousNEXT ARTICLETechnical perspective: How do experts learn new programming languages?NextAbstractReferences\n\n\n\nInformation & ContributorsBibliometrics & CitationsView OptionsReferencesMediaTablesShareAbstractGiven the complexity of data science projects and related demand for human expertise, automation has the potential to transform the data science process.References[1]Amershi, S. et al. Guidelines for human-AI interaction. In Proceedings of the 2019 CHI Conf. on Human Factors in Computing Systems, 2019, 1--13.Google Scholar[2]Bjorkman, A. et al. Plant functional trait change across a warming tundra biome. Nature 562, 7725 (2018), 57.Google Scholar[3]Blockeel, H., Calders, T., Fromont, \u00c9., Goethals, B., Prado, A., and Robardet, C. An inductive database system based on virtual mining views. Data Mining and Knowledge Discovery 24, 1 (2012), 247--287.Digital LibraryGoogle Scholar[4]Brazdil, P., Carrier, C., Soares, C., and Vilalta, R. Metalearning: Applications to Data Mining. Springer Science & Business Media, 2008.Google Scholar[5]Chapman, P. et al. CRISP-DM 1.0 Step-by-step data mining guide, 2000.Google Scholar[6]Chen, J., Jimenez-Ruiz, E., Horrocks, I., and Sutton, C. ColNet: Embedding the semantics of Web tables for column type prediction. In Proceedings of the 33rd AAAI Conf. on Artificial Intelligence, 2019.Digital LibraryGoogle Scholar[7]Dasu, T. and Johnson, T. Exploratory Data Mining and Data Cleaning. Wiley, 2003.CrossrefGoogle Scholar[8]De Bie, T. Subjective interestingness in exploratory data mining. In Proceedings of the Intern. Symp. Intelligent Data Analysis. Springer, 2013, 19--31.Digital LibraryGoogle Scholar[9]De Raedt, L., Kersting, K., Natarajan, S., and Poole, D. Statistical relational artificial intelligence: Logic, probability, and computation. Synthesis Lectures on Artificial Intelligence and Machine Learning 10, 2 (2016), 1--189.CrossrefGoogle Scholar[10]Donoho, D. 50 years of data science. J. Computational and Graphical Statistics 26, 4 (2017), 745--766.CrossrefGoogle Scholar[11]Elbattah, M. and Molloy, O. Analytics using machine learning-guided simulations with application to healthcare scenarios. Analytics and Knowledge Mgmt. Auerbach Publications, 2018, 277--324.Google Scholar[12]Feurer, M., Klein, A., Eggensperger, K., Springenberg, J., Blum, M., and Hutter, F. Efficient and robust automated machine learning. Advances in Neural Information Processing Systems 28, 2015, 2962--2970.Digital LibraryGoogle Scholar[13]Gale, W. Statistical applications of artificial intelligence and knowledge engineering. The Knowledge Engineering Rev. 2, 4 (1987), 227--247.CrossrefGoogle Scholar[14]Geng, L. and Hamilton, H. Interestingness measures for data mining: A survey. ACM Computing Surveys 38, 3 (2006), 9.Digital LibraryGoogle Scholar[15]Gordon, A., Graepel, T., Rolland, N., Russo, C., Borgstrom, J., and Guiver, J. Tabular: A schema driven probabilistic programming language. ACM SIGPLAN Notices 49, 1 (2014), 321--334.Digital LibraryGoogle Scholar[16]Guidotti, R., Monreale, A., Ruggieri, S., Turini, F., Giannotti, F., and Pedreschi, D. A survey of methods for explaining black box models. ACM Computing Surveys 51, 5 (2018). 93.Google Scholar[17]Guyon, I., et al. A brief review of the ChaLearn AutoML Challenge: Any-time any-dataset learning without human intervention. In Proceedings of the Workshop on Automatic Machine Learning 64 (2016), 21--30. F. Hutter, L. Kotthoff, and J. Vanschoren, Eds.Google Scholar[18]Heer, J., Hellerstein, J., and Kandel, S. Predictive interaction for data transformation. In Proceedings of Conf. on Innovative Data Systems Research, 2015.Google Scholar[19]Heer, J., Hellerstein, J., and Kandel, S. Data Wrangling. Encyclopedia of Big Data Technologies. S. Sakr and A. Zomaya, Eds. Springer, 2019.Google Scholar[20]Hern\u00e1ndez-Orallo, J., et al. Reframing in context: A systematic approach for model reuse in machine learning. AI Commun. 29, 5 (2016), 551--566.CrossrefGoogle Scholar[21]Hutter, F., Hoos, H., and Leyton-Brown, K. Sequential model-based optimization for general algorithm configuration. In Proceedings of the Intern. Conf. on Learning and Intelligent Optimization. Springer, 2011, 507--523.Digital LibraryGoogle Scholar[22]Hutter, F., Kotthoff, L., and Vanschoren, J., Eds. Automated Machine Learning---Methods, Systems, Challenges. Springer, 2019.Google Scholar[23]Keim, D., Andrienko, G., Fekete, J., G\u00f6rg, C., Kohlhammer, J., and Melan\u00e7on, G. Visual analytics: Definition, process, and challenges. Information Visualization. Springer, 2008, 154--175.Google Scholar[24]King, R., et al. Functional genomic hypothesis generation and experimentation by a robot scientist. Nature 427, 6971 (2004, 247.Google Scholar[25]Kotthoff, L., Thornton, C., Hoos, H., Hutter, F., and Leyton-Brown, K. Auto-WEKA 2.0: Automatic model selection and hyperparameter optimization in WEKA. J. Machine Learning Research 18, 1 (2017), 826--830.Google Scholar[26]Langley, P., Simon, H., Bradshaw, G., and Zytkow, J. Scientific Discovery: Computational Explorations of the Creative Processes. MIT Press, 1987.CrossrefGoogle Scholar[27]Le, V. and Gulwani, S. FlashExtract: A Framework for data extraction by examples. In Proceedings of the 35th ACM SIGPLAN Conf. on Programming Language Design and Implementation, 2014, 542--553.Digital LibraryGoogle Scholar[28]Liu, C., et al. Progressive neural architecture search. In Proceedings of the European Conf. on Computer Vision, 2018, 19--34.Digital LibraryGoogle Scholar[29]Lloyd, J., Duvenaud, D., Grosse, R., Tenenbaum, J., and Ghahramani, Z. Automatic construction and natural-language description of nonparametric regression models. In Proceedings of the 28th AAAI Conf. on Artificial Intelligence, 2014.CrossrefGoogle Scholar[30]Mansinghka, V., Tibbetts, R., Baxter, J., Shafto, P., and Eaves, B. BayesDB: A probabilistic programming system for querying the probable implications of data. 2015; arXiv:1512.05006.Google Scholar[31]Mart\u00ednez-Plumed, F. et al. CRISP-DM twenty years later: From data mining processes to data science trajectories. IEEE Trans. Knowledge and Data Engineering (2020), 1CrossrefGoogle Scholar[32]Nazabal, A., Williams, C., Colavizza, G., Smith, C., and Williams, A. Data engineering for data analytics: A classification of the issues, and case studies. 2020; arXiv:2004.12929.Google Scholar[33]Rakotoarison, H., Schoenauer, M., and Sebag, M. Automated machine learning with Monte-Carlo tree search. In Proceedings of the 28th Intern. Joint Conf. on Artificial Intelligence 7, (2019); https://doi.org/10.24963/ijcai.2019/457.CrossrefGoogle Scholar[34]Ratner, A., De Sa, C., Wu, S., Selsam, D., and R\u00e9, C. Data programming: Creating large training sets, quickly. In Proceedings of the 30th Intern. Conf. on Neural Information Processing Systems, 2016, 3574--3582.Google Scholar[35]Ruotsalo, T., Jacucci, G., Myllym\u00e4ki, P., and Kaski, S. Interactive intent modeling: Information discovery beyond search. Commun. ACM 58, 1 (Jan. 2014), 86--92.Google Scholar[36]Sculley, D. et al. Hidden technical debt in machine learning systems. Advances in Neural Info. Processing Systems 28, (2015), 2503--2511.Google Scholar[37]Serban, F., Vanschoren, J., Kietz, J., and Bernstein, A. A survey of intelligent assistants for data analysis. ACM Computing Surveys 45, 3 (2013), 1--35.Digital LibraryGoogle Scholar[38]St. Amant, R. and Cohen, P. Intelligent support for exploratory data analysis. J. Computational and Graphical Statistics 7, 4 (1998), 545--558.Google Scholar[39]Sutton, C., Hobson, T., Geddes, J., and Caruana, R. Data diff: Interpretable, executable summaries of changes in distributions for data wrangling. In Proceedings of the 24th ACM SIGKDD Conf. on Knowledge Discovery and Data Mining, 2018.Digital LibraryGoogle Scholar[40]Tao, F. and Qi, Q. Make more digital twins. Nature 573 (2019), 490--491.CrossrefGoogle Scholar[41]Thornton, C., Hutter, F., Hoos, H., and Leyton-Brown, K. Auto-WEKA: Combined selection and hyperparameter optimization of classification algorithms. In Proceedings of the 19th ACM SIGKDD Intern. Conf. on Knowledge Discovery and Data Mining, 2013, 847--855.Digital LibraryGoogle Scholar[42]Tukey, J. Exploratory Data Analysis. Pearson, 1977.Google Scholar[43]Tukey, J. and Wilk, M. Data analysis and statistics: An expository overview. In Proceedings of 1966 Fall Joint Computer Conf. (Nov. 7--10, 1966), 695--709.Digital LibraryGoogle Scholar[44]Vanschoren, J., Van Rijn, J., Bischl, B., and Torgo, L. OpenML: Networked science in machine learning. ACM SIGKDD Explorations Newsletter 15, 2 (2014), 49--60.Digital LibraryGoogle Scholar[45]Vartak, M., Rahman, S., Madden, S., Parameswaran, A., and Polyzotis, N. SeeDB: Efficient data-driven visualization recommendations to support visual analytics. In Proceedings of the Intern. Conf. on Very Large Data Bases 8 (2015), 2182.Google Scholar[46]Vartak, M., et al. ModelDB: A system for machine learning model management. In Proceedings of the ACM Workshop on Human-In-the-Loop Data Analytics, 2016, 14.Digital LibraryGoogle Scholar[47]Wang, D., et al. Human-AI collaboration in data science: Exploring data scientists' perceptions of automated AI. In Proceedings of the ACM Conf. on Human-Computer Interaction 3, 2019, 1--24.Digital LibraryGoogle Scholar[48]Wasay, A., Athanassoulis, M., and Idreos, S. Queriosity: Automated data exploration. In Proceedings of the 2015 IEEE Intern. Congress on Big Data, 716--719.Google Scholar[49]Wongsuphasawat, K., Moritz, D., Anand, A., Mackinlay, J., Howe, B., and Heer, J. Voyager: Exploratory analysis via faceted browsing of visualization recommendations. IEEE Trans. Visualization and Computer Graphics 22, 1 (2015), 649--658.Google Scholar[50]Wulder, M., Coops, N., Roy, D., White, J., and Hermosilla, T. Land cover 2.0. Intern. J. Remote Sensing 39, 12 (2018), 4254--4284.CrossrefGoogle Scholar[51]Zgraggen, E., Zhao, Z., Zeleznik, R., and Kraska, T. Investigating the effect of the multiple comparisons problem in visual analysis. In Proceedings of the 2018 CHI Conf. on Human Factors in Computing Systems, 1--12.Google Scholar\n\n\n\n\nCited ByView allAzevedo TSilva A(2024)Um Estudo sobre Ensino de Engenharia de Dados nas Universidades Brasileiras: Estado Atual e Perspectivas de MercadoAnais do IV Simp\u00f3sio Brasileiro de Educa\u00e7\u00e3o em Computa\u00e7\u00e3o (EDUCOMP 2024)10.5753/educomp.2024.237423(375-383)Online publication date: 22-Apr-2024https://doi.org/10.5753/educomp.2024.237423Chudasama YPurohit DRohde PGercke JVidal M(2024)InterpretME: A tool for interpretations of machine learning models over knowledge graphsSemantic Web10.3233/SW-233511(1-21)Online publication date: 5-Jan-2024https://doi.org/10.3233/SW-233511Tomczyk PBr\u00fcggemann PDoligalski T(2024)The Automation of Science? Possibilities and Boundaries of AI Applications for Conducting Systematic Literature ReviewsInternational Journal on Artificial Intelligence Tools10.1142/S021821302450023433:06Online publication date: 16-Oct-2024https://doi.org/10.1142/S0218213024500234Show More Cited By\n\n\n\n\n\nIndex Terms\nAutomating data scienceComputing methodologiesMachine learningInformation systemsInformation systems applicationsData miningTheory of computationLogicAutomated reasoning\n\n\n\n\n\n\n\nRecommendations\nAutomating the loading of business process data warehousesEDBT '09: Proceedings of the 12th International Conference on Extending Database Technology: Advances in Database Technology  \nBusiness processes drive the operations of an enterprise. In the past, the focus was primarily on business process design, modeling, and automation. Recently, enterprises have realized that they can benefit tremendously from analyzing the behavior of ...Read MoreTowards Automating Data NarrativesIUI '17: Proceedings of the 22nd International Conference on Intelligent User Interfaces  \nWe propose a new area of research on automating data narratives. Data narratives are containers of information about computationally generated research findings. They have three major components: 1) A record of events, that describe a new result through ...Read MoreDirty Data in the Newsroom: Comparing Data Preparation in Journalism and Data ScienceCHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems    The work involved in gathering, wrangling, cleaning, and otherwise preparing data for analysis is often the most time consuming and tedious aspect of data work. Although many studies describe data preparation within the context of data science workflows,...Read More\n\n\n\n\n\n\n\n\n\n\nComments\nPlease enable JavaScript to view thecomments powered by Disqus.\n\n\n\n\nInformation & ContributorsInformationPublished In\nCommunications of the ACM\u00a0 Volume 65, Issue 3March 2022102  pagesISSN:0001-0782EISSN:1557-7317DOI:10.1145/3522546Editor: Andrew A. ChienAssociation for Computing Machinery, New York, NYIssue\u2019s Table of Contents\nCopyright \u00a9 2022 ACM.Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from [email\u00a0protected]PublisherAssociation for Computing MachineryNew York, NY, United StatesPublication HistoryPublished: 23 February 2022Published in\u00a0CACM\u00a0Volume 65, Issue 3PermissionsRequest permissions for this article.Request PermissionsCheck for updatesQualifiersResearch-articlePopularRefereedFunding SourcesEU project H2020US National Science FoundationFLINASA awardFlemish GovernmentINDITEX Sustainability Seed FundEuropean Research CouncilGeneralitat ValencianaH2020 - ICT48US National Institutes of HealthSpanish MINECOEPSRC Centre for Doctoral Training in Medical ImagingContributors\n\n\n\nOther MetricsView Article MetricsBibliometrics & CitationsBibliometrics\n\n                Article Metrics\n            \n19Total CitationsView Citations19,660Total DownloadsDownloads (Last 12 months)1,178Downloads (Last 6 weeks)119Reflects downloads up to 16 Nov 2024\nOther MetricsView Author MetricsCitations\nCited ByView allAzevedo TSilva A(2024)Um Estudo sobre Ensino de Engenharia de Dados nas Universidades Brasileiras: Estado Atual e Perspectivas de MercadoAnais do IV Simp\u00f3sio Brasileiro de Educa\u00e7\u00e3o em Computa\u00e7\u00e3o (EDUCOMP 2024)10.5753/educomp.2024.237423(375-383)Online publication date: 22-Apr-2024https://doi.org/10.5753/educomp.2024.237423Chudasama YPurohit DRohde PGercke JVidal M(2024)InterpretME: A tool for interpretations of machine learning models over knowledge graphsSemantic Web10.3233/SW-233511(1-21)Online publication date: 5-Jan-2024https://doi.org/10.3233/SW-233511Tomczyk PBr\u00fcggemann PDoligalski T(2024)The Automation of Science? Possibilities and Boundaries of AI Applications for Conducting Systematic Literature ReviewsInternational Journal on Artificial Intelligence Tools10.1142/S021821302450023433:06Online publication date: 16-Oct-2024https://doi.org/10.1142/S0218213024500234Russo MChudasama YPurohit DSawischa SVidal M(2024)Employing Hybrid AI Systems to Trace and Document Bias in ML PipelinesIEEE Access10.1109/ACCESS.2024.342738812(96821-96847)Online publication date: 2024https://doi.org/10.1109/ACCESS.2024.3427388Carvalho JPimenta TSilverio ACarvalho MCarvalho J(2024)A New Data Science Model With Supervised Learning and its Application on Pesticide Poisoning Diagnosis in Rural WorkersIEEE Access10.1109/ACCESS.2024.337576412(40871-40882)Online publication date: 2024https://doi.org/10.1109/ACCESS.2024.3375764Hilliard AKazim ELedain S(2024)Are the robots taking over? On AI and perceived existential riskAI and Ethics10.1007/s43681-024-00600-9Online publication date: 15-Nov-2024https://doi.org/10.1007/s43681-024-00600-9Baratchi MWang CLimmer Svan Rijn JHoos HB\u00e4ck TOlhofer M(2024)Automated machine learning: past, present and futureArtificial Intelligence Review10.1007/s10462-024-10726-157:5Online publication date: 18-Apr-2024https://doi.org/10.1007/s10462-024-10726-1Chanson ALabroche NMarcel PPerlata VVassiliadis P(2024)Interestingness Measures for\u00a0Exploratory Data Analysis: a\u00a0SurveyNew Trends in Database and Information Systems10.1007/978-3-031-70421-5_2(14-24)Online publication date: 14-Nov-2024https://doi.org/10.1007/978-3-031-70421-5_2Mehr IMinetto ADovis F(2023)A Navigation Signals Monitoring, Analysis and Recording Tool: Application to Real-Time Interference Detection and ClassificationProceedings of the 36th International Technical Meeting of the Satellite Division of The Institute of Navigation (ION GNSS+ 2023)10.33012/2023.19391(3878-3887)Online publication date: 5-Oct-2023https://doi.org/10.33012/2023.19391Rogers JCrisan A(2023)Tracing and Visualizing Human-ML/AI Collaborative Processes through Artifacts of Data WorkProceedings of the 2023 CHI Conference on Human Factors in Computing Systems10.1145/3544548.3580819(1-22)Online publication date: 19-Apr-2023https://dl.acm.org/doi/10.1145/3544548.3580819Show More Cited By\nView OptionsView options PDFView or Download as a PDF file.PDF eReaderView online with eReader.eReader Digital EditionView this article in digital edition.Digital Edition Magazine SiteView this article on the magazine site (external)Magazine Site\nLogin optionsCheck if you have access through your login credentials or your institution to get full access on this article.Sign inFull AccessGet this Article\nMediaFiguresOtherTablesShareShareShare this Publication linkCopy LinkCopied!Copying failed.Share on social mediaXLinkedInRedditFacebookemailAffiliationsTijl De BieGhent University, BelgiumView ProfileLuc De RaedtKU Leuven, Belgium and \u00d6rebro University, SwedenView ProfileJos\u00e9 Hern\u00e1ndez-OralloUniversitat Polit\u00e8cnica de Val\u00e8ncia, SpainView ProfileHolger H. HoosLeiden University, The Netherlands and University of British Columbia in Vancouver, CanadaView ProfilePadhraic SmythUniversity of California, IrvineView ProfileChristopher K. I. WilliamsUniversity of Edinburgh, U.K and Alan Turing Institute, London, U.KView ProfileDownload PDF\n\n\n\n\n\nView Issue\u2019s Table of Contents\nExport CitationsSelect Citation formatBibTeXEndNoteACM RefPlease download or close your previous search result export first before starting a new bulk export.Preview is not available.By clicking download,a status dialog will open to start the export process. The process may takea few minutes but once it finishes a file will be downloadable from your browser. You may continue to browse the DL while the export process is in progress.DownloadDownload citationCopy citation\n\n\n\nFooter\n\n\n\n\n\n\n\n\nCategories\n\nJournals\nMagazines\nBooks\nProceedings\nSIGs\nConferences\nCollections\nPeople\n\n\n\n\nAbout\n\nAbout ACM Digital Library\nACM Digital Library Board\nSubscription Information\nAuthor Guidelines\nUsing ACM Digital Library\nAll Holdings within the ACM Digital Library\nACM Computing Classification System\nAccessibility Statement\n\n\n\n\nJoin\n\nJoin ACM\nJoin SIGs\nSubscribe to Publications\nInstitutions and Libraries\n\n\n\n\nConnect\n\nContact us via email\nACM on Facebook\nACM DL on X\nACM on Linkedin\n\nSend Feedback\nSubmit a Bug Report\n\n\n\n\n\n\n\n\nThe ACM Digital Library is published by the Association for Computing Machinery. Copyright \u00a9 2024 ACM, Inc.\n\nTerms of Usage\nPrivacy Policy\nCode of Ethics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYour Search Results Download Request We are preparing your search results for download ...We will inform you here when the file is ready.Download now!Your Search Results Download RequestYour file of search results citations is now ready.Download now!Your Search Results Download RequestYour search export query has expired. Please try again.\n\n\n\n\n\n\n\n\n"}, {"url": "https://arxiv.org/abs/2003.06505", "content": "\n\n\n [2003.06505] AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nSkip to main content\n\n\n\n\n\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\nDonate\n\n\n\n\n\n > stat > arXiv:2003.06505\n  \n\n\n\n\n\nHelp | Advanced Search\n\n\n\n\nAll fields\nTitle\nAuthor\nAbstract\nComments\nJournal reference\nACM classification\nMSC classification\nReport number\narXiv identifier\nDOI\nORCID\narXiv author ID\nHelp pages\nFull text\n\n\n\n\nSearch\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nopen search\n\n\n\n\n\n\nGO\n\n\n\nopen navigation menu\n\n\nquick links\n\nLogin\nHelp Pages\nAbout\n\n\n\n\n\n\n\n\n\n\n\n\nStatistics > Machine Learning\n\n\narXiv:2003.06505 (stat)\n    \n\n\n\n\n  [Submitted on 13 Mar 2020]\nTitle:AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data\nAuthors:Nick Erickson, Jonas Mueller, Alexander Shirkov, Hang Zhang, Pedro Larroy, Mu Li, Alexander Smola View a PDF of the paper titled AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data, by Nick Erickson and 6 other authors\nView PDF\n\nAbstract:We introduce AutoGluon-Tabular, an open-source AutoML framework that requires only a single line of Python to train highly accurate machine learning models on an unprocessed tabular dataset such as a CSV file. Unlike existing AutoML frameworks that primarily focus on model/hyperparameter selection, AutoGluon-Tabular succeeds by ensembling multiple models and stacking them in multiple layers. Experiments reveal that our multi-layer combination of many models offers better use of allocated training time than seeking out the best. A second contribution is an extensive evaluation of public and commercial AutoML platforms including TPOT, H2O, AutoWEKA, auto-sklearn, AutoGluon, and Google AutoML Tables. Tests on a suite of 50 classification and regression tasks from Kaggle and the OpenML AutoML Benchmark reveal that AutoGluon is faster, more robust, and much more accurate. We find that AutoGluon often even outperforms the best-in-hindsight combination of all of its competitors. In two popular Kaggle competitions, AutoGluon beat 99% of the participating data scientists after merely 4h of training on the raw data.\n    \n\n\n\nSubjects:\n\nMachine Learning (stat.ML); Machine Learning (cs.LG)\n\nCite as:\narXiv:2003.06505 [stat.ML]\n\n\n\u00a0\n(or \narXiv:2003.06505v1 [stat.ML] for this version)\n          \n\n\n\u00a0\n https://doi.org/10.48550/arXiv.2003.06505\n\n\nFocus to learn more\n\n\n\n                  arXiv-issued DOI via DataCite\n\n\n\n\n\n\n\nSubmission history From: Jonas Mueller [view email]       [v1]\n        Fri, 13 Mar 2020 23:10:39 UTC (428 KB)\n\n\n\n \n\nFull-text links:\nAccess Paper:\n\n\nView a PDF of the paper titled AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data, by Nick Erickson and 6 other authorsView PDFTeX SourceOther Formats\nview license\n\n \n    Current browse context: stat.ML\n\n\n<\u00a0prev\n\n\u00a0 | \u00a0 \nnext\u00a0>\n\n\nnew\n | \nrecent\n | 2020-03\n\n    Change to browse by:\n    \ncs\ncs.LG\nstat\n\n\n\n\nReferences & Citations\n\nNASA ADSGoogle Scholar\nSemantic Scholar\n\n\n\n\n\n 2 blog links (what is this?)\n        \n\n\na\nexport BibTeX citation\nLoading...\n\n\n\n\nBibTeX formatted citation\n\u00d7\n\n\nloading...\n\n\nData provided by: \n\n\n\n\nBookmark\n\n\n\n\n\n \n\n\n\n\nBibliographic Tools\n\nBibliographic and Citation Tools\n\n\n\n\n\n\nBibliographic Explorer Toggle\n\n\n\nBibliographic Explorer (What is the Explorer?)\n\n\n\n\n\n\n\nConnected Papers Toggle\n\n\n\nConnected Papers (What is Connected Papers?)\n\n\n\n\n\n\nLitmaps Toggle\n\n\n\nLitmaps (What is Litmaps?)\n\n\n\n\n\n\n\nscite.ai Toggle\n\n\n\nscite Smart Citations (What are Smart Citations?)\n\n\n\n\n\n\n\n\n\nCode, Data, Media\n\nCode, Data and Media Associated with this Article\n\n\n\n\n\n\nalphaXiv Toggle\n\n\n\nalphaXiv (What is alphaXiv?)\n\n\n\n\n\n\n\nLinks to Code Toggle\n\n\n\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\n\n\n\n\n\n\n\nDagsHub Toggle\n\n\n\nDagsHub (What is DagsHub?)\n\n\n\n\n\n\n\nGotitPub Toggle\n\n\n\nGotit.pub (What is GotitPub?)\n\n\n\n\n\n\n\nHuggingface Toggle\n\n\n\nHugging Face (What is Huggingface?)\n\n\n\n\n\n\n\nLinks to Code Toggle\n\n\n\nPapers with Code (What is Papers with Code?)\n\n\n\n\n\n\n\nScienceCast Toggle\n\n\n\nScienceCast (What is ScienceCast?)\n\n\n\n\n\n\n\n\n\n\n\n\n\nDemos\n\nDemos\n\n\n\n\n\n\nReplicate Toggle\n\n\n\nReplicate (What is Replicate?)\n\n\n\n\n\n\n\nSpaces Toggle\n\n\n\nHugging Face Spaces (What is Spaces?)\n\n\n\n\n\n\n\nSpaces Toggle\n\n\n\nTXYZ.AI (What is TXYZ.AI?)\n\n\n\n\n\n\n\n\nRelated Papers\n\nRecommenders and Search Tools\n\n\n\n\n\n\nLink to Influence Flower\n\n\n\nInfluence Flower (What are Influence Flowers?)\n\n\n\n\n\n\n\nCore recommender toggle\n\n\n\nCORE Recommender (What is CORE?)\n\n\n\n\n\nAuthor\nVenue\nInstitution\nTopic\n\n\n\n\n\n\n\n\n\n\n\n\n\n        About arXivLabs\n      \n\n\n\narXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n\n\n\n\n\n\n\n\n\n\nWhich authors of this paper are endorsers? |\n    Disable MathJax (What is MathJax?)\n    \n\n\n\n\n\n\n\n\n\n\n\n\nAbout\nHelp\n\n\n\n\n\ncontact arXivClick here to contact arXiv\n Contact\n\n\nsubscribe to arXiv mailingsClick here to subscribe\n Subscribe\n\n\n\n\n\n\n\n\n\n\n\nCopyright\nPrivacy Policy\n\n\n\n\nWeb Accessibility Assistance\n\n\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n\n\n\n\n\n \n\n\n\n\n\n\n"}, {"url": "https://library.oapen.org/handle/20.500.12657/23012", "content": "\n\n403 Forbidden\n\nForbidden\nYou don't have permission to access this resource.\n\n"}, {"url": "https://dx.doi.org/10.4135/9781526466426", "content": "Sage :: Request BlockedYour request has been blockedThis request has been identified as suspicious, if you think this is a mistake please contact us.Use 'suspicious activity' in the subject of your email and include the following information in your request:Time: Page URL: IP Address: Any additional information on actions attempted before seeing this page:"}, {"url": "https://metalearning.chalearn.org/", "content": "Meta Learning ChallengesSearch this siteSkip to main contentSkip to navigationMeta Learning ChallengesHomeMetaDL@neurips2021MetaLearning@AAAI2021Meta Learning ChallengesHomeMetaDL@neurips2021MetaLearning@AAAI2021MoreHomeMetaDL@neurips2021MetaLearning@AAAI2021MetaLearn 2022Machine learning has solved with success many mono-task problems, but at the expense of long wasteful training times. Meta-learning promises to leverage the experience gained on previous tasks to train models faster, with fewer examples, and possibly better performance. Approaches include learning from algorithm evaluations,  from task properties (or meta-features), and from prior models. Following the AutoDL 2019-2020 challenge series and past meta-learning challenges and benchmarks we have organized, including MetaDL@NeurIPS'21 (read our PAPER) we are organizing three competitions in 2022: 1st Round of Meta-learning from learning curves (ENDED will be presented at WCCI 2022).2nd Round of Meta-learning from learning curves (ENDED, accepted to AutoML-Conf 2022).Cross-domain meta-learning (ENDED, accepted to NeurIPS'22).Workshop (Meta-)Knowledge Transfer/Communication in Different Systems. Friday 23rd of Sept. 2022, Grenoble, France, associated with ECML/PKDD 2022Meta-Learning workshop @NeurIPS2022Upcoming presentations:NeurIPS'22Meta-Album (Thursday 1st of December): [PAPER][POSTER][WEBSITE]Cross-Domain MetaDL Competition (Tuesday 6th of December): [PAPER][POSTER][WEBSITE][RECORDED SESSION]Contact us, if you want to join the organizing team.Meta-Learning from Learning Curves 2 (AutoML-conf)Challenge Site (Ended)\u20ac1000 in prizes!The main goal of this competition is to push the state-of-the-art in meta-learning from learning curves, an important sub-problem in meta-learning. A learning curve evaluates an algorithm's incremental performance improvements, as a function of training time, number of iterations, and/or number of examples. Analysis of past ML challenges revealed that top-ranking methods often involve switching between algorithms during training. We are interested in meta-learning strategies that leverage information on partially trained algorithms, hence reducing the cost of training them to convergence. Furthermore, we want to study the potential benefit of learned policies, as opposed to applying hand-crafted black-box optimization methods. We offer pre-computed learning curves as a function of time, to facilitate benchmarking. Meta-learners must \u201cpay\u201d a cost emulating computational time for revealing their next values. Hence, meta-learners are expected to learn the exploration-exploitation trade-offs between exploiting an already tried good candidate algorithm and exploring new candidate algorithms. The first round of this competition was previously organized for WCCI 2022, please see the results on our website. In this new round, we propose an enlarged and more challenging meta-dataset. Having participated in the first round is NOT a prerequisite. The winners of the first round have open-sourced their code.TimelineMay 16, 2022: Public phase starts, starting kit available.May 23, 2022: Feedback phase starts, you can now make submissions.July 4, 2022: Final phase starts. No new submission: your last submission of the previous phase is tested on test data.July 11, 2022: Final phase ends.July 25, 2022: Results revealed at AutoML-conf.DataWe created a meta-dataset from the 30 datasets of the AutoML challenge, by running algorithms with different hyperparameter, from which we obtained learning curves both for the validation sets and the test sets. ProtocolDuring a development phase, participants submit agents to be meta-trained and meta-tested on all data, except the test learning curves of each task. During a final test phase, a scoring program computes the agent\u2019s performance on the test learning curves, based on pre-recorded agent suggestions. Furthermore, the ingestion program runs a hold-out procedure: in each split, we hold out 5/30 datasets for meta-testing, and use the rest for meta-training.EvaluationThe agent is evaluated by the Area under the agents\u2019 Learning Curve (ALC). The values will be averaged over all meta-test datasets and shown on the leaderboards. The final ranking will be made according to the average test ALC.Meta-Learning from Learning Curves challenge (1st round, terminated) Challenge SiteCongratulations to the winners of the 1st round [Technical Report]:1st place: MoRiHa [CODE][FACTSHEET]2nd place: neptune (500$) [CODE][FACTSHEET]3rd place: AIpert (300$) [CODE][FACTSHEET]4th place: automl-freiburg (200$) [CODE][FACTSHEET]5th place: automl-hannover [CODE][FACTSHEET] Cross-Domain MetaDL (NeurIPS'22)Challenge Site (Ended)\u20ac4000 in prizes!Congratulations to the winners [Technical Report]:The rows with yellow backgrounds indicate that not all team members fulfill the league requirements and therefore have less priority for prizes. This challenge comes with an amazing on-line tutorial guiding you step-by-step and a white paper describing the challenge and baseline results. It focuses on \u201ccross-domain meta-learning\u201d for few-shot image classification using a novel \u201cany-way\u201d and \u201cany-shot\u201d setting. The goal is to meta-learn a good model that can quickly learn tasks from a variety of domains, with any number of classes also called \u201cways\u201d (within the range 2-20) and any number of training examples per class also called \u201cshots\u201d (within the range 1-20). We carve such tasks from various \u201cmother datasets\u201d selected from diverse domains, such as healthcare, ecology, biology, manufacturing, and others. By using mother datasets from these practical domains, we aim to maximize the humanitarian and societal impact. The competition is with code submission, fully blind-tested on the CodaLab challenge platform. A single (final) submission will be evaluated during the final phase, using ten datasets previously unused by the meta-learning community. After the competition is over, it will remain active to be used as a long-lasting benchmark resource for research in this field. The scientific and technical motivations of this challenge include scalability, robustness to domain changes, and generalization ability to tasks (a.k.a. episodes) in different regimes (any-way any-shot).TimelineJun 15, 2022: Public phase starts, the starting kit and 10 public datasets will be released for the participants to start familiarizing themselves with the problem and test their solutions locally.Jul 1, 2022: Feedback phase starts, the CodaLab platform will start receiving submissions from the participants to provide them instant feedback of their solutions on 10 hidden datasets.Sep 1, 2022: Final phase starts, the last submission of each participant from the feedback phase is blind-tested on 10 new hidden datasets to rank the participants and select the winners.Oct 1 - 15, 2022: Notification of winners. The top ranking participants will be invited to co-author a group paper on the results and analysis of the challengeDataWe have extended the Meta-Album Benchmark (read our PREPRINT) we started putting together last year. It now consists of 30 datasets from 10 domains. They are all image classification datasets, uniformly formatted as 128x128 RGB images, carefully resized with anti-aliasing, cropped manually, and annotated with various meta-data, including super-classes. ProtocolDuring the feedback and final phases the submissions of the participants will be evaluated on 10 datasets from 10 domains. The few-shot learning problems are often referred as N-way K-shots problem. This name refers to episode configuration at meta-test time. The number of ways N denotes the number of classes in an episode that represents an image classification task. The number of shots K denotes the number of examples per class in the support (training) set. In this challenge, we focus on the any-way any-shot setting: Tasks at meta-test time are image classification problems with a number of classes varying from 2 to 20, with 1 to 20 labeled example per class. Thus, at meta-test time the participants' code might be tested in the following way:Test task 1: 5-way 1-shot task from dataset 3.Test task 2: 3-way 15-shots task from dataset 7.Test task 3: 12-way 4-shots task from dataset 1.etc.The ranking will be made by averaging performances over all meta-testing tasks in the final test phase, and taking the worst of 3 randomly seeded runs. Performance will be measured with balanced accuracy, normalized between 0 (random guess) and 1 (perfect prediction).Prize distributionTo encourage diverse participation, we will donate prizes in 5 leagues:Free-style league: Submit a solution obeying basic challenge rules (pre-trained models allowed).Meta-learning league: Submit a solution that meta-learns from scratch (no pre-training allowed).New-in-ML league: Be a participant who has less than 10 ML publications, none of which ever accepted to the main track of a major conference.Women league: Special league to encourage women, since they rarely enter challenges.Participant of a rarely represented country: Be a participant of a group that is not in the top 10 most represented countries of Kaggle challenge participants.In each league: 1st prize=400\u20ac, 2nd prize=250\u20ac, 3rd prize=150\u20ac. Entering multiple leagues is permitted. In addition, the top ranking participants will receive a certificate, and be invited to co-author a post-challenge analysis paper with the organizers, published in the NeurIPS proceedings of the competition track. Travel awards will also be distributed depending upon merit and needs to top ranking participants who want to attend NeurIPS in person, depending on availability.Lean more First challenge round (NeurIPS'21) including the code of the winners.Paper on the first round, explaining how they won (El Baz et al, 2022).Paper on Meta-Album and baseline results for THIS challenge (Ullah et al, 2022).Metalearning: Applications to Data Mining (Book, by Brazdil et al. (2008))Meta-learning: A survey (Book chapter, by Vanschoren (2019))Meta-learning in neural networks: A survey (Arxiv, Hospedales et al. (2020))A Survey of Deep Meta-Learning (Artificial Intelligence Review, Huisman et al. (2021))Sign up to our Google Group to get informed of future event, OR here:We are grateful to Microsoft and Google for generous cloud unit donations and to 4Paradigm for donating prizes. This project is also supported by ChaLearn and HUMANIA chair of AI grant ANR-19-CHIA-00222 of the Agence Nationale de la Recherche (France), and the EU TAILOR consortium. Researchers  and students from Universit\u00e9 Paris-Saclay, Universiteit Leiden, TU Eindhoven, Universidad de la Sabana and 4Paradigm have contributed. The challenge is hosted by Codalab (Universit\u00e9 Paris-Saclay).University Paris-Saclay (France)Leiden University (the Netherlands)Universidad de la Sabana (Colombia)Report abuseReport abuseThis site uses cookies from Google to deliver its services and to analyze traffic. Information about your use of this site is shared with Google. By using this site, you agree to its use of cookies.Learn moreGot it"}, {"url": "http://www.bizety.com/2020/06/16/open-source-automl-tools-autogluon-transmogrifai-auto-sklearn-and-nni/", "content": "\n\n\n\n\n\n\n\n\n\n\n\nOpen Source AutoML Tools: AutoGluon, TransmogrifAI, Auto-sklearn, and NNI - Bizety: Research & Consulting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\r\n\t\tSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nSearch for:\n\n\nSearch\n\n\n\n\n\n\n\n\nSearch\n\n\n \n\n\n\n\n \n\n\n\nAbout\n\nContact \n\n\n\n\n\n \n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\nMain Menu\n\n \n\n\n\n\n\n\n\n\n\n\n\nAbout\n\nContact \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpen Source AutoML Tools: AutoGluon, TransmogrifAI, Auto-sklearn, and NNI \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\t\t\t\t\t\t\t\t\t\tBizety Staff\t\t\t\t\t\n\n\n\n\n\n \n\nJune 16, 2020 \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCategories \n\n\n\n\nAnalysis\nCDN\nDevOps\nNetworking\nSecurity\nBig Data\nAI / ML\nWeb3\n \n\n Menu\n\n\nAnalysis\nCDN\nDevOps\nNetworking\nSecurity\nBig Data\nAI / ML\nWeb3\n \n\n\n\n\n\n\n\n\n\n\n\n\nOpen-source AutoML tools are rapidly becoming dominant in the entrepreneurial landscape. These solutions help enterprises implement and scale their ML and AI projects.\nAutoML open-source tools automate the entire life cycle of ideating, conceptualization, development, and deployment of predictive models. From data preparation through model training to validation as well as deployment, these tools do everything with almost zero human intervention.\nSince most of these tools may seem to be similar, not one tool will suit all use cases. So, one challenge is evaluating several platforms and identifying the best fit for your project.\nThis decision should be based on various considerations, such as ease-of-use, competitive differentiations, risk tolerance, integration with existing tools, regulatory compliance, and more.\nBelow, we\u2019re going to review the most popular open-source AutoML tools. With enough data at hand, choosing the right tool should become easier.\nAutoGluon\nIn January 2020, Amazon entered into the ultra-competitive world of AutoML with the release of AutoGluon. With this easy-to-use, open-source toolkit, ML-based application developers can extend AutoML with an emphasis on deep learning and real-world applications spanning text, image, or tabular data.\nAmazon\u2019s AutoGluon lets developers build prototype deep learning solutions in reduced time, improve bespoke data pipelines and models, and enable automatic hyperparameter tuning.\nPresently, AutoGluon creates models for object detection, image classification, supervised learning, text classification with tabular datasets.\n\nsource: Amazon\nAutoGluon-Tabular\u2019s approach to AutoML\nEngineers have been applying statistical procedures to tabular data for decades, either to gather summary statistics or to build predictive models. Using the right approach, AutoML can help in areas such as sales forecasting, demand and supply prediction, fraud detection, and generating product recommendations based on user preferences.\nWith AutoGluon-Tabular, users can access the best practices employed by seasoned data scientists through a user-friendly API. AutoGluon-Tabular provides the following benefits:\n\nRobustness: Enables users to work with raw data without any data manipulation or feature engineering.\nSimplicity: Enables users to train and deploy classification and regression models with minimal coding.\nFault-tolerance: Enables users to resume training after interruptions occur, inspecting all intermediate steps in the process.\nPredictable-timing: Helps users obtain the ideal model under a specified time constraint.\n\nIn summary, AutoGloun-Tabular saves time by automating time-consuming manual processes \u2013 handling missing data, data splitting, manual feature transformations, algorithm selection, model selection, and repeating the process as data changes.\nNeural Architecture Search\nOne most important AutoML features in AutoGluon is called neural architecture search. These tools optimize the weights, structure, and hyperparameters of an ML model\u2019s algorithmic \u201cneurons\u201d to ensure the accuracy, speed, and efficiency of neural nets in performing data-driven inferences. Neural Architecture Search allows AI developers to automate the optimization of models for high-performance inferencing on various hardware platforms.\nAutoGluon automatically generates a high-performance ML model from Python code. It taps into available reinforcement learning (RL) algorithms and computes resources to search for the best-fit neural-network architecture for the target environment.\nEnsembles and multi-layer stacking\nWith AutoGluon, you don\u2019t need stacking and ensembling skills. AutoGluon-Tabular automatically does it for you by introducing a novel multi-layer stack ensemble.\n\nAutoGluon white paper\nHere\u2019s how this model works:\n\nBase layer: Trains individual base models, such as Random Forests, CatBoost boosted trees, LightGBM boosted trees, Extremely Randomized trees, etc.\nConcat layer: Base layer\u2019s output is concatenated with the input features.\nStacker layer: Trains multiple stacker models on the concat layer output. This layer re-uses the exact same models in the base layer. Stacker models can look at the input dataset because input features are concatenated with the output of the base layer.\nWeighting layer: Implements an ensemble selection approach in which stacker models are introduced into a new ensemble.\n\nAutoGluon-Tabular performs k-fold cross-validation to ensure that every learner can see the entire dataset.\nTransmogrifAI\nTransmogrif AI is an end-to-end AutoML toolkit for structured data written in Scala and runs on Apache Spark.\nIt was developed to accelerate machine learning developer productivity through AutoML and uses an API to enforces compile-time type-modularity and safety. Through automation, Transmogrif AI achieves high accuracy with a 100x reduction in time.\nSpecifically, TransmogrifAI utilizes AutoML in five areas of an ML workflow:\n\nFeature Inference: Extracts features from a given dataset.\nTransmogrification: Converting features into numeric values.\nFeature Validation: Reducing dimensions and identifying potential bias, etc.\nModel Selection: Conducts searches across thousands of potential models.\nHyperparameter Optimization: Hyperparameter configuration tuning\n\n\nSource: Linkedin\nVectorizers and Transmogrification\nThis stage automates the feature engineering step in the ML pipeline. The TransmogrifAI transmogrifier (shortcut .transmogrify()) applies default transformation on a sequence of features based on feature types. Finally, it combines these transformed features into a single vector.\nval features = Seq(email, phone, age, subject, zip code).transmogrify()\nFeature engineering can be done at the single feature level in combination with automatic type-specific transformations. The .vectorize(\u2026.) method with each feature type transforms the feature into a feature vector with some input parameters.\nNLP \u2013 NER Detection\nFeature engineering uses this stage to detect NERs in a sentence. It includes the following steps:\n\nToken Generation:\n\nNameEntityRecognizer is a class named as NameEntityType text recognizer. This recognizer helps encapsulate OpenNLPAnalyzer.\nOnce the text is tokenized, you have to initialize the NamedEntity Tagger.\n\nExtract Person Tags\n\nExtract by passing following values to nerTagger instance defined above:\nval personEntities = tokens.map { tokenInput => nerTagger.tag(tokenInput.value, Language.English, Seq(NameEntityType.Person)).tokenTags }\n\nExtract Date: Use the following code to extract Date from the tokenValue using NameEntityType.Date.\n\nval dateEntities = tokens.map { tokenInput => nerTagger.tag(tokenInput.value, Language.English, Seq(NameEntityType.Date)).tokenTags }\n\nExtract Organization: Extract organization using NameEntityType.Organization.\n\nAuto-sklearn\nAuto-sklearn is an open-source AutoML tool implemented in python. Built around the scikit-learn library, Auto-sklearn contains a machine learning pipeline that takes care of categorical features, missing values, rescaling the data, and sparse and dense data.\nThe AutoML tool includes a total of 110 hyperparameters, 15 ML algorithms, and 14 preprocessing methods, arranged as shown in this figure:\n\nsource: University of Freiburg\nAuto-sklearn toolkit features a database of previous optimization runs on OpenML\u2019s 140 diverse datasets. For every new dataset, this tool first identifies similar datasets and begins from the saved best settings. The second improvement to the tool is automatically constructed ensembles that make it construct ensembles from the models trained at the time of the Bayesian optimization.\nAuto-sklearn Installation\nUsers can install Auto-sklearn via a simple pip command:\npip install auto-sklearn\nIf you are using Ubuntu, you will need a SWIG and C++11 building environment.\nsudo apt-get install build-essential swig\nTo install via Anaconda:\nconda install gxx_linux-64 gcc_linux-64 swig\nAuto-Sklearn Implementation\nAuto-Sklearn implementation requires uses to get a few imports:\nAutosklearn.classification to load the classifier later\nsklearn.model_selection for selecting model\nsklearn.datasets for dataset loading\nimport sklearn.metrics for model performance measuring\nMemory and Time Limits\nOne important feature of auto-sklearn is limiting memory and time resources that are used by the scikit-learn algorithms. This stops evaluations to make progress in a particular amount of time, especially for large datasets on which algorithms take several hours to make a machine swap.\nThe resource limit is a tradeoff between the number of models to be tested and optimization time. Auto-sklearn alleviates the need for manual hyperparameter tuning, though users still have to set memory and time limits.\nA memory limit of 3-6GB is sufficient for most datasets. As for a good time limit of one day, 30 minutes for a single run are enough.\nParallel Computation\nAuto-sklearn allows parallel execution via a shared file system. The SMAC algorithm in this model shares the training data by writing it to disk with every iteration. When the iteration begins, SMAC loads all new data points.\nIn the default mode, the AutoML toolkit uses two cores. The first core is used for building a model, while the second one is used for building an ensemble whenever a new machine learning model finishes training.\nMoreover, based on the installation of numpy and scikit-learn, the model building process may use some of all cores. It is unintended by auto-sklearn and numpy installed from pypi as a binary wheel.\nNNI\nIn 2017, Microsoft released an open-source AutoML toolkit on GitHub, called \u2018Neural Network Intelligence (NNI)\u2019. The toolkit helps users perform efficient neural architecture search and hyperparameter tuning.\nMicrosoft says, \u201cthe tool runs trial jobs generated by tuning algorithms to search for the best neutral architectures and hyper-parameters at local or remote servers, cloud, or other environments.\n\nMicrosoft\nYou can use NNI toolkit if you have to support AutomL in your existing ML infrastructure, or you want to implement and compare your own new AutoML algorithms with existing ones. NNI toolkit also works excellent when you try different versions of AutoML algorithms.\nNNI provides users with the capacity to run multiple instances in parallel to find the best parameter combinations. This feature is useful in various ways, like finding the best database configuration, finding the best hyperparameters for deep learning models, etc. It also provides algorithm toolkits for deep learning and ML, especially neural architecture search (NAS) algorithms, feature engineering algorithms, and model compression algorithms.\nNNI Experiment\nAn NNI experiment refers to the task of finding out a model\u2019s best hyperparameters and finding out the best neural network architecture. The experiment involves trials and advanced AutoML algorithms.\nIn an experiment, the tuner generates configurations using the search space. These configurations are submitted to training platforms, including training clusters, a local machine, or remote machines. As the performances are reported to tuner, new configurations are generated for further processing.\nEach NNI experiment consists of three steps:\nStep 1: Define Search Space: Tuner samples parameters or architecture according to the search space, which is defined as a JSON file.\nStep 2: Update model codes: An NNI trial is an individual attempt at applying a configuration to a model.\nStep 3: Define Experiment: Users need a config file when creating an NNI experiment. The file exists in YAML format and it is provided to nnictl.\n\nsource: NNI\nGeneral NAS Framework\nThis NAS framework allows users to quickly specify candidate neural architectures for a single layer. NNI toolkit finds the right candidate automatically. Contrarily, the NAS framework serves another type of user with a simple interface for implementing new NAS algorithms.\nNNI supports many one-shot NAS algorithms including DARTS and ENAS through NNI trial SDK. You can use these algorithms without performing an NNI experiment. Simply, import an algorithm in your trial code and run it. You can tune the hyperparameters or run multiple instances by choosing a tuner and commence an NNI experiment.\nYou can also run NAS in a classic mode where each candidate architecture operates as an independent trial job. Users start an NNI experiment and then select a tuner for NAS.\nAutomatic Feature Engineering\nAutomatic feature engineering helps users to find the best features as per their needs. Since NNI trial SDK supports it, you do not have to create an NNI experiment for using this feature. You can directly import a built-in auto-feature-engineering algorithm in your trial code and run it.\nThese algorithms feature a bunch of hyperparameters that you can automatically tune leveraging hyperparameter tuning of NNI.\nModel Compression\nNNI model compression includes quantization algorithms and pruning algorithms. Provided through NNI trial SDK, these algorithms can be directly used in trial code without an NNI experiment.\nUsers get different types of hyperparameters, including the hyperparameters in input configuration to a compression algorithm. Here, NNI hyperparameter tuning helps in finding the best-compressed model automatically.\nSummary\nAs discussed, these open-source AutoML tools work equally well. However, each has its own set of features and potential applications. Although this is not an in-depth analysis, it should help by providing highlights on the different tools.\nThe basic premise of AutoML is to automate repetitive manual tasks, such as hyperparameter tuning and creation of pipelines. It allows data scientists to spend more time on practical scenarios rather than running repetitive tasks manually all over again. The open-source AutoML tools allow data scientists to accelerate ML development by implementing efficient machine learning.\nWhether the success of AutoML depends on its progress and usage in the machine learning field, it is a crucial part of machine learning in the future.\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\nBizety LLC\u00a9 2022 Disclaimer. Privacy Policy\nAll product names, logos, and brands are the property of their respective owners.\nWe do not endorse, solicit, or recommend the buying or selling of financial instruments.\n \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n Scroll to Top\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}, {"url": "https://proceedings.neurips.cc/paper_files/paper/2015/file/11d0e6287202fced83f79975ec59a3a6-Paper.pdf", "content": null}]}